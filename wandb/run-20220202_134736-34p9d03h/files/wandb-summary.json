{"Algorithm": {}, "train_loss": 0.013207469135522842, "Episodes": {}, "TrainReward": -1452.683055, "l": 200.0, "t": 206.129567, "TestReward": -1348.1688801199198, "_runtime": 225, "_timestamp": 1643806281, "_step": 6250}