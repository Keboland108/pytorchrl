Sequential(
  (0): Linear(in_features=4, out_features=500, bias=True)
  (1): ReLU()
  (2): Linear(in_features=500, out_features=500, bias=True)
  (3): ReLU()
  (4): DeterministicMB(
    (output): Linear(in_features=500, out_features=3, bias=True)
  )
)
Training model from scratch
Training model from scratch
Collecting initial samples...
Created CWorker with worker_index 0
Created GWorker with worker_index 0
Update 1, num samples collected 5250, FPS 293
  Algorithm: train_loss 1.1801
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 2, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.5552
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 3, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.7484
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 4, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 5, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.1381
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 6, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0837
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 7, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0740
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 8, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4964
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 9, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.3068
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 10, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.7016
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 11, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0713
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 12, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.2425
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 13, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0486
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 14, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 15, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 16, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4058
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 17, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0357
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 18, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.8099
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 19, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0393
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 20, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.4490
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 21, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 22, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.4817
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 23, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.4789
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 24, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.4249
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 25, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 26, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.3388
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 27, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 28, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 29, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.2192
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 30, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.6804
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 31, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.3098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 32, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0307
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 33, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 34, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 35, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 36, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.1842
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 37, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 38, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 39, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.2939
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 40, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.1380
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 41, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.4882
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 42, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 43, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.6098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 44, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0199
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 45, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 46, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 47, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.3028
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 48, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0333
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 49, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 50, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.5275
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 51, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 52, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 53, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 54, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0650
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 55, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.3261
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 56, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 57, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.2241
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 58, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.2591
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 59, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 60, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.6010
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 61, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.1997
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 62, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.2726
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 63, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 64, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.3735
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 65, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.3839
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 66, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 67, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 68, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 69, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 70, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.4211
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 71, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.5785
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 72, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4586
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 73, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 74, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 75, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0222
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 76, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.5661
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 77, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 78, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 79, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 80, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 81, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.6656
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 82, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4470
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 83, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.1997
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 84, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 85, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.2537
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 86, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.2079
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 87, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 88, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.3350
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 89, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 90, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.4519
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 91, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.2366
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 92, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.2710
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 93, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 94, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 95, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.6390
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 96, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 97, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.9037
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 98, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 99, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 100, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 101, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 102, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 103, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 104, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.3686
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 105, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 106, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 107, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 108, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.4680
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 109, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.4952
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 110, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 111, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 112, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.3634
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 113, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.2544
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 114, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.3504
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 115, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 116, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.4988
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 117, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.2401
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 118, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.3107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 119, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.4044
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 120, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 121, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 122, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 123, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 124, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.1522
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 125, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 126, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 127, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 128, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.6965
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 129, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.3835
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 130, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.1568
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 131, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.8003
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 132, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.4382
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 133, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 134, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 135, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.3807
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 136, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 137, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 138, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 139, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.5411
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 140, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.2512
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 141, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.4116
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 142, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 143, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1942
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 144, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1748
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 145, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 146, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 147, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 148, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.2276
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 149, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.2216
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 150, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.5543
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 151, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 152, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.4529
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 153, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.3629
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 154, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 155, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.2658
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 156, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1823
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 157, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 158, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.3254
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 159, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.6002
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 160, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1927
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 161, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 162, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.1582
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 163, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 164, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.2756
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 165, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.2894
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 166, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.3438
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 167, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 168, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 169, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.4473
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 170, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.3303
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 171, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 172, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 173, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 174, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 175, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 176, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.2334
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 177, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.3810
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 178, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.2899
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 179, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.2462
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 180, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 181, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 182, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.5269
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 183, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.2464
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 184, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.5717
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 185, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1264
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 186, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 187, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 188, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.2552
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 189, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.4350
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 190, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 191, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 192, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.8110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 193, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 194, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.3971
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 195, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 196, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 197, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 198, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 199, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 200, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 201, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 202, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 203, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.9062
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 204, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1579
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 205, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.3926
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 206, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.3299
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 207, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.4435
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 208, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.4493
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 209, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.2519
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 210, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 211, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1796
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 212, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 213, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.7843
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 214, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 215, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 216, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 217, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.3982
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 218, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 219, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 220, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 221, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.5634
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 222, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.4098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 223, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 224, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.3549
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 225, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.5186
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 226, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 227, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.4266
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 228, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 229, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 230, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 231, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.7076
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 232, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.5716
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 233, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 234, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 235, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 236, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 237, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 238, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.5538
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 239, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.3395
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 240, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.2910
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 241, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 242, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 243, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4067
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 244, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.1793
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 245, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4570
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 246, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 247, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.7765
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 248, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 249, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4444
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 250, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 251, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.3601
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 252, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 253, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 254, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.3608
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 255, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.1558
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 256, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.2878
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 257, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.3470
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 258, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.1625
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 259, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 260, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 261, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.4057
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 262, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 263, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 264, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.3597
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 265, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.4368
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 266, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.4385
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 267, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 268, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.2837
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 269, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.3897
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 270, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 271, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.2626
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 272, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.4131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 273, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 274, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 275, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.1160
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 276, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 277, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 278, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.2234
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 279, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 280, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 281, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 282, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.8634
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 283, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0562
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 284, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.2851
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 285, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.3212
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 286, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.3935
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 287, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.1958
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 288, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.1843
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 289, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.8001
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 290, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 291, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.4741
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 292, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.3290
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 293, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.3534
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 294, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 295, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 296, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.2384
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 297, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.3222
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 298, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.3978
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 299, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 300, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.2845
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 301, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 302, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 303, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.2049
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 304, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 305, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.5990
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 306, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 307, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 308, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 309, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 310, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.3844
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 311, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.3216
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 312, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 313, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.3771
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 314, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.2737
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 315, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.4548
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 316, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 317, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 318, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.2431
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 319, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 320, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 321, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.2714
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 322, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 323, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.3892
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 324, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 325, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.5404
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 326, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 327, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 328, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.1594
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 329, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.6679
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 330, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.2592
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 331, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.1542
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 332, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.3746
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 333, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.6586
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 334, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 335, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 336, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.8743
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 337, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 338, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2239
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 339, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 340, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.4355
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 341, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.1722
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 342, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.1623
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 343, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.4325
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 344, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2200
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 345, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2574
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 346, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 347, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 348, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.3146
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 349, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 350, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2339
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 351, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 352, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2913
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 353, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 354, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 355, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 356, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.2353
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 357, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.3666
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 358, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.2684
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 359, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 360, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.4797
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 361, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 362, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 363, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.2523
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 364, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 365, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.6864
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 366, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.8584
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 367, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.1533
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 368, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.3409
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 369, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 370, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 371, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.1578
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 372, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 373, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.1666
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 374, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 375, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 376, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 377, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3867
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 378, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 379, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3082
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 380, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3810
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 381, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 382, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 383, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3795
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 384, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 385, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3763
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 386, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.8583
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 387, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2345
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 388, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 389, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 390, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 391, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2399
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 392, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.5611
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 393, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 394, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 395, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1540
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 396, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2952
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 397, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.3594
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 398, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 399, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 400, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2469
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 401, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 402, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2036
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 403, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 404, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.2634
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 405, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 406, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.3745
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 407, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1449
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 408, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.3279
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 409, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1890
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 410, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1139
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 411, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.2915
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 412, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.5755
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 413, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 414, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.6705
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 415, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.3766
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 416, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.4025
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 417, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 418, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.2205
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 419, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 420, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 421, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 422, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 423, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.2240
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 424, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 425, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.5575
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 426, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.3279
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 427, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 428, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 429, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 430, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.2905
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 431, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.2220
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 432, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.5571
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 433, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.3317
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 434, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.4367
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 435, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.3614
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 436, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 437, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 438, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2027
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 439, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2511
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 440, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 441, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 442, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 443, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 444, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.3733
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 445, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 446, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.3450
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 447, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2348
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 448, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2764
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 449, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.8291
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 450, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.1736
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 451, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.6729
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 452, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2889
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 453, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2215
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 454, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.3410
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 455, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2419
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 456, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 457, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 458, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 459, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 460, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 461, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.3871
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 462, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 463, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.3507
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 464, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.6219
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 465, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.2437
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 466, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.7249
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 467, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.2439
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 468, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 469, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.5278
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 470, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.2705
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 471, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.4074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 472, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.3455
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 473, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0533
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 474, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 475, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 476, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 477, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.2291
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 478, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 479, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 480, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.2062
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 481, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 482, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 483, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 484, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 485, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 486, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.2844
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 487, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 488, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.3215
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 489, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.6456
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 490, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1271
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 491, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.4334
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 492, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.3985
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 493, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.2441
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 494, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.6338
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 495, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 496, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.2901
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 497, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 498, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 499, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 500, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.3219
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 501, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.4615
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 502, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 503, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 504, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 505, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 506, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.2394
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 507, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 508, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 509, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.3550
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 510, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.2514
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 511, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 512, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.1266
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 513, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.2790
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 514, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.3906
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 515, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.8027
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 516, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.5466
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 517, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 518, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0240
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 519, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 520, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 521, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 522, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 523, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.4788
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 524, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.4639
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 525, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.3460
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 526, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 527, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 528, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.5140
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 529, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4553
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 530, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.3065
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 531, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.2769
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 532, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.3370
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 533, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1701
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 534, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.3075
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 535, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 536, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.3217
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 537, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 538, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.2090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 539, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 540, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4287
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 541, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4228
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 542, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 543, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.2401
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 544, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2271
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 545, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.3853
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 546, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 547, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.3937
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 548, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 549, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 550, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 551, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 552, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.5379
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 553, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 554, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2958
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 555, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 556, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.3807
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 557, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2703
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 558, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 559, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 560, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 561, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 562, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.6074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 563, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.2408
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 564, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.5703
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 565, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 566, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 567, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.3130
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 568, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.2153
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 569, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 570, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.3060
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 571, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 572, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 573, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 574, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.3106
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 575, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 576, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.3937
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 577, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 578, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 579, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.4788
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 580, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.6392
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 581, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1054
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 582, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0588
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 583, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.4609
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 584, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 585, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 586, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.2029
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 587, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.4345
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 588, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 589, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 590, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 591, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1655
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 592, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 593, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 594, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 595, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 596, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.2186
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 597, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 598, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.7164
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 599, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 600, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 601, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.3047
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 602, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2377
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 603, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.6294
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 604, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2474
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 605, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.5323
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 606, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2196
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 607, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 608, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 609, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 610, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 611, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.3511
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 612, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.4807
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 613, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.4207
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 614, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 615, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.4956
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 616, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 617, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.2480
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 618, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.1833
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 619, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.3042
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 620, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 621, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.1482
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 622, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.4505
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 623, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.3903
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 624, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 625, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 626, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 627, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 628, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 629, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.3041
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 630, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.4242
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 631, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.1802
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 632, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 633, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.5497
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 634, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 635, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.5073
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 636, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.3656
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 637, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.2246
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 638, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.2598
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 639, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.4691
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 640, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.3489
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 641, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 642, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 643, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 644, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.1169
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 645, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 646, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.4226
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 647, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 648, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 649, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.6234
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 650, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 651, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.4003
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 652, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.1049
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 653, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 654, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.6484
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 655, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 656, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2330
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 657, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3947
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 658, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.4047
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 659, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2391
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 660, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.5190
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 661, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3009
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 662, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.1674
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 663, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2174
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 664, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2463
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 665, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.4044
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 666, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2874
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 667, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3603
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 668, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 669, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 670, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 671, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 672, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 673, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1887
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 674, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.5279
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 675, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 676, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 677, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 678, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.2696
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 679, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 680, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 681, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 682, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.4105
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 683, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.3621
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 684, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1655
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 685, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.6062
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 686, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.5495
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 687, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1877
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 688, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.2495
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 689, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4153
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 690, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 691, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 692, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 693, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.2425
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 694, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.2532
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 695, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 696, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4521
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 697, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.2467
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 698, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4039
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 699, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 700, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 701, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 702, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.5479
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 703, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.1773
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 704, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.2371
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 705, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 706, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.1443
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 707, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.5351
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 708, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.1242
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 709, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 710, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 711, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.2048
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 712, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.3846
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 713, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.3397
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 714, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.5579
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 715, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.6795
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 716, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 717, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 718, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.3787
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 719, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 720, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 721, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 722, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.2060
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 723, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 724, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 725, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 726, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 727, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.5125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 728, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3542
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 729, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 730, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 731, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3969
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 732, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3822
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 733, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.1733
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 734, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.2380
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 735, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 736, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.4455
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 737, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 738, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 739, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3378
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 740, num samples collected 5250, FPS 247
  Algorithm: train_loss 0.3631
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 741, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 742, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2834
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 743, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 744, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.3727
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 745, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2484
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 746, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.3961
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 747, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.3889
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 748, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 749, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 750, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2839
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 751, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 752, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 753, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 754, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2371
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 755, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.5513
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 756, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.4103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 757, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.3574
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 758, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 759, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.3316
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 760, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 761, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.2333
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 762, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 763, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1647
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 764, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 765, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1463
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 766, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 767, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1711
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 768, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 769, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 770, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.4109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 771, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.4523
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 772, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.5929
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 773, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.3844
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 774, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.4302
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 775, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 776, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 777, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 778, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 779, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.5824
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 780, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 781, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.3558
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 782, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 783, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 784, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 785, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.3957
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 786, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.6327
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 787, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 788, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0605
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 789, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.1544
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 790, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 791, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 792, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 793, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.3938
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 794, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 795, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 796, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.3706
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 797, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.4485
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 798, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2079
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 799, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 800, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2344
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 801, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 802, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.3208
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 803, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.3301
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 804, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.5216
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 805, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1756
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 806, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.5615
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 807, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 808, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 809, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.2418
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 810, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 811, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1647
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 812, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.2345
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 813, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.5017
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 814, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 815, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.2833
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 816, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1919
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 817, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.2854
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 818, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.4983
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 819, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 820, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 821, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 822, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.5327
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 823, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.3808
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 824, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.2873
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 825, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.2321
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 826, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.3878
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 827, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 828, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.2034
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 829, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 830, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.6408
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 831, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 832, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.4202
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 833, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 834, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 835, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 836, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 837, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 838, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.1630
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 839, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.3596
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 840, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 841, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2484
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 842, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 843, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 844, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.3092
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 845, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.4395
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 846, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.1611
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 847, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.8674
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 848, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.3759
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 849, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 850, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 851, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 852, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2383
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 853, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.4072
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 854, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 855, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 856, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 857, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.5355
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 858, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 859, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.2855
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 860, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 861, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 862, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.4201
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 863, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 864, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.3789
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 865, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.7736
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 866, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 867, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 868, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 869, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.3858
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 870, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 871, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.4406
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 872, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 873, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 874, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 875, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.2884
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 876, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 877, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.2395
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 878, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 879, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.5704
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 880, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 881, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.3596
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 882, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 883, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 884, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 885, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 886, num samples collected 5250, FPS 237
  Algorithm: train_loss 1.2576
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 887, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 888, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 889, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 890, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 891, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 892, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.3448
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 893, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 894, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 895, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 896, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.3266
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 897, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 898, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 899, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.6135
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 900, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 901, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 902, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 903, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.8970
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 904, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.6328
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 905, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2075
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 906, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1995
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 907, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 908, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2833
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 909, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 910, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.3539
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 911, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1778
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 912, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 913, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 914, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.4382
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 915, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.4870
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 916, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 917, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5837
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 918, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2691
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 919, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 920, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 921, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2449
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 922, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2650
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 923, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 924, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 925, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 926, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 927, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 928, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 929, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5130
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 930, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2357
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 931, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5633
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 932, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 933, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 934, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5203
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 935, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 936, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 937, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 938, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 939, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.2974
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 940, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 941, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.6098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 942, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 943, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.3471
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 944, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.7335
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 945, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.3258
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 946, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 947, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 948, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.4297
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 949, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 950, num samples collected 5250, FPS 231
  Algorithm: train_loss 1.0091
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 951, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.4192
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 952, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.2355
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 953, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 954, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 955, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.2056
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 956, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 957, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 958, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 959, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.4542
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 960, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 961, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.3317
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 962, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.3830
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 963, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 964, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1019
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 965, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.4078
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 966, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 967, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1614
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 968, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.5365
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 969, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.4336
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 970, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 971, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2380
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 972, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 973, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2263
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 974, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 975, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 976, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 977, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 978, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 979, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.9471
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 980, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 981, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 982, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1473
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 983, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 984, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.3977
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 985, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 986, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.3813
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 987, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 988, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2403
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 989, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.6157
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 990, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.2305
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 991, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 992, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 993, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 994, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 995, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3777
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 996, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 997, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.4359
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 998, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 999, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1000, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1001, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1002, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1686
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1003, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.7101
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1004, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3129
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1005, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3582
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1006, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3495
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1007, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1008, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.4084
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1009, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1010, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1011, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.1267
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1012, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.3946
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1013, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1014, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.4288
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1015, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.1054
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1016, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.2331
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1017, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.2825
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1018, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1019, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.5447
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1020, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1021, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.3491
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1022, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.2008
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1023, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.8224
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1024, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1025, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.2062
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1026, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.4408
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1027, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1028, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1029, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1030, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.1420
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1031, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1032, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1033, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.3205
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1034, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1035, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1036, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.1711
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1037, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1038, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.2390
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1039, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.3030
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1040, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.6890
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1041, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.4349
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1042, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1043, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1044, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.2516
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1045, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1046, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1047, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.5428
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1048, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1049, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.5960
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1050, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1051, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1052, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.2441
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1053, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1054, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.6029
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1055, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1056, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.2094
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1057, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1220
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1058, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1583
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1059, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1060, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.6467
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1061, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1062, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1063, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1064, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1601
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1065, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.4810
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1066, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.4227
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1067, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.2851
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1068, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.3595
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1069, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1070, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1071, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.3326
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1072, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1073, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.3027
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1074, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.1606
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1075, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.3136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1076, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.4089
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1077, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1078, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1079, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1080, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1081, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.7636
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1082, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1083, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1084, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1085, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.3104
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1086, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1087, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1088, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.2593
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1089, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.4812
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1090, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1091, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.2341
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1092, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1093, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1094, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.3500
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1095, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1096, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1097, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.2362
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1098, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.5654
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1099, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1728
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1100, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.3575
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1101, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1102, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.4715
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1103, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.6256
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1104, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1105, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1106, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1107, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.2001
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1108, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1109, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1110, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.2993
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1111, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1112, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.3166
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1113, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1114, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1711
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1115, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1116, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1117, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1118, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.7107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1119, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1120, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1121, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1122, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1013
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1123, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1124, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.6126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1125, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.2863
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1126, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1426
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1127, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1990
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1128, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1129, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.9544
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1130, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.2491
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1131, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.3825
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1132, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1133, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.3889
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1134, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0937
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1135, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.2374
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1136, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.4633
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1137, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1138, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.6037
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1139, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1140, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.6258
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1141, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1142, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1143, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1144, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1145, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1146, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.3257
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1147, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1148, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.4640
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1149, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1150, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1151, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1563
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1152, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.2777
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1153, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.6478
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1154, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1155, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.4915
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1156, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.3562
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1157, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.3654
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1158, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.6706
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1159, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1160, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1161, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.2313
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1162, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1163, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1164, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1165, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1166, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.3327
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1167, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1168, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1169, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.4924
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1170, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1171, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.2531
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1172, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1173, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1174, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2955
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1175, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2380
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1176, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1177, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2422
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1178, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.3993
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1179, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1180, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1181, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1182, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1183, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.3487
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1184, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.5808
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1185, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1186, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1187, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1188, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2814
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1189, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.3599
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1190, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2950
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1191, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.5013
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1192, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1193, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1194, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.4382
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1195, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1196, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1197, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1198, num samples collected 5250, FPS 213
  Algorithm: train_loss 0.1701
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1199, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2788
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1200, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1201, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.3312
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1202, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1203, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.6429
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1204, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.6076
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1205, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1206, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2295
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1207, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1208, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1209, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1210, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2069
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1211, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1212, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.3502
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1213, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2080
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1214, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1215, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.4733
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1216, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1217, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.1496
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1218, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.4767
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1219, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.4601
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1220, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1221, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2284
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1222, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.3000
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1223, num samples collected 5250, FPS 212
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1224, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1225, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.4246
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1226, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1227, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.4712
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1228, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.5797
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1229, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1230, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1231, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1232, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.3429
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1233, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1234, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.3313
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1235, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.2021
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1236, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.4109
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1237, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.2760
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1238, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1239, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.3263
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1240, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.4665
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1241, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1242, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.3654
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1243, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.1661
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1244, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.5920
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1245, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.2379
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1246, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1247, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.2865
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1248, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.2378
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1249, num samples collected 5250, FPS 211
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1250, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1251, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.3777
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1252, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.6696
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1253, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1254, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1255, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1256, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.3890
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1257, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.3871
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1258, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.1063
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1259, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1260, num samples collected 5250, FPS 210
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1494.2783, l 200.0000, t 104.1133, TestReward -1417.3659
Update 1261, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1262, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3805
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1263, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1264, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1265, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1982
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1266, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1449
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1267, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2389
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1268, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2267
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1269, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1270, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1271, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1272, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1273, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1274, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1275, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1276, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1277, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2048
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1278, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5019
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1279, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6695
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1280, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1281, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6774
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1282, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.7166
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1283, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4875
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1284, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5289
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1285, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3324
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1286, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1287, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5157
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1288, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1289, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1290, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1291, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1292, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2375
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1293, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1294, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3582
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1295, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1296, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2563
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1297, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1298, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3818
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1299, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1300, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1301, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1302, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2435
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1303, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1304, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1305, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2301
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1306, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1307, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5971
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1308, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5328
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1309, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5656
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1310, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1311, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1312, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1313, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3355
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1314, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1967
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1315, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1316, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1317, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1928
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1318, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3355
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1319, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1320, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1321, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4745
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1322, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1323, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1324, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1325, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5289
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1326, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1327, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1328, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1329, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5724
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1330, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1551
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1331, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3283
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1332, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2585
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1333, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3316
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1334, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1335, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1336, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1337, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.6862
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1338, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3465
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1339, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0242
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1340, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3698
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1341, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4007
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1342, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1817
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1343, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1344, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1345, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1346, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1347, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2438
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1348, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1349, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4279
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1350, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1351, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2549
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1352, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2365
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1353, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1354, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2309
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1355, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1158
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1356, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1357, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1358, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4580
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1359, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3434
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1360, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1361, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1999
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1362, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1363, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5612
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1364, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2059
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1365, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1366, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4063
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1367, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1368, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1369, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.3142
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1370, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2955
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1371, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1582
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1372, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1373, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2839
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1374, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1375, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1376, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1377, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1378, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1253
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1379, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3861
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1380, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.7848
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1381, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3540
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1382, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1383, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1073
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1384, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1385, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1386, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1387, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1388, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1389, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5982
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1390, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4374
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1391, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1392, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1393, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1394, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5695
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1395, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3900
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1396, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1397, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2506
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1398, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5272
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1399, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1400, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1401, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1402, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1403, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1404, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1405, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1406, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1407, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1408, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1409, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3931
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1410, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1411, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1269
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1412, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3581
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1413, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1414, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2925
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1415, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3021
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1416, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1417, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3600
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1418, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1419, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1420, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1421, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1422, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3797
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1423, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1424, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4893
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1425, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1426, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2247
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1427, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1428, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1429, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2327
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1430, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2321
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1431, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3300
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1432, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1433, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1434, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1435, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3817
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1436, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.7514
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1437, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1438, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5025
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1439, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2034
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1440, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2486
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1441, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3687
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1442, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1443, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2241
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1444, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4753
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1445, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1446, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3587
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1447, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1448, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3987
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1449, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1450, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1451, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1452, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2490
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1453, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1503
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1454, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1455, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1455
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1456, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.7510
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1457, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1458, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1459, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2259
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1460, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2484
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1461, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6110
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1462, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6159
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1463, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3985
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1464, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1465, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3609
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1466, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2027
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1467, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4374
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1468, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1469, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2942
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1470, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1471, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4703
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1472, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1541
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1473, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1416
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1474, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1475, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1476, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1477, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2676
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1478, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1479, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1480, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1481, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1482, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2342
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1483, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1484, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1485, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1486, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1487, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1488, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1489, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1873
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1490, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1491, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2973
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1492, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2461
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1493, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4721
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1494, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.5567
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1495, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.5558
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1496, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1497, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1794
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1498, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1499, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2188
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1500, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6090
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1501, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1502, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2501
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1503, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1504, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1505, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1713
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1506, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1507, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2395
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1508, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1509, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1510, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4006
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1511, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1512, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1513, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1514, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3992
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1515, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4895
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1516, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1517, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1518, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3049
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1519, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.5901
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1520, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1521, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1522, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1523, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1524, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1525, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1526, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1527, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1437
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1528, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1529, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2644
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1530, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3853
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1531, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2475
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1532, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1533, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1534, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3195
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1535, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1536, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2383
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1537, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1538, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.7784
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1539, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1523
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1540, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1541, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2017
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1542, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3402
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1543, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1115
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1544, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1545, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1546, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1547, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1548, num samples collected 5500, FPS 123
  Algorithm: train_loss 1.0349
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1549, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1550, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1551, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1552, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1553, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1004
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1554, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1555, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1556, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1557, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1558, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3894
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1559, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5577
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1560, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1561, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1562, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1768
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1563, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.4476
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1564, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1565, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1566, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2375
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1567, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6355
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1568, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1569, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5365
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1570, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1571, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1572, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1573, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2756
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1574, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1575, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1576, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1577, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1578, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1579, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1580, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1581, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1583
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1582, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1583, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3695
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1584, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.8898
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1585, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2292
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1586, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1587, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1588, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1589, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1590, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1591, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1592, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2928
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1593, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1594, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1595, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2008
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1596, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1597, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3817
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1598, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5099
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1599, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1600, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1601, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1319
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1602, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1520
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1603, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1604, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.4848
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1605, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1606, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1607, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3886
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1608, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.9375
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1609, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1610, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3372
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1611, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1612, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2945
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1613, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3851
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1614, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3914
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1615, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2518
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1616, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3343
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1617, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1618, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3291
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1619, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1620, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1621, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3313
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1622, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1623, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2505
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1624, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1625, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3789
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1626, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1627, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2821
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1628, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1629, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2668
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1630, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2048
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1631, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2244
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1632, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1633, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2443
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1634, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3181
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1635, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4028
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1636, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1637, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1638, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1639, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1640, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2706
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1641, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1642, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5854
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1643, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1644, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1645, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2309
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1646, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2412
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1647, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1648, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5808
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1649, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1650, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5744
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1651, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1652, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2766
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1653, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1654, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1655, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1656, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1657, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1658, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2065
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1659, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3680
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1660, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2328
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1661, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3479
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1662, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3314
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1663, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3452
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1664, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2587
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1665, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2480
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1666, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2236
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1667, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3700
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1668, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1669, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1077
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1670, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1671, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5589
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1672, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1673, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1674, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1675, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1676, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1677, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3894
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1678, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3626
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1679, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1680, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1681, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3687
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1682, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1606
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1683, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1684, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4066
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1685, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4611
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1686, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1687, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1688, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4833
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1689, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1690, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1691, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5185
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1692, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.3706
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1693, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5816
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1694, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1695, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1696, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4090
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1697, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1698, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5017
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1699, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1700, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1701, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2203
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1702, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2940
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1703, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1704, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5966
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1705, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1133
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1706, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2515
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1707, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1708, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3588
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1709, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3354
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1710, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1711, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1712, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2761
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1713, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1714, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1715, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1716, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1717, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1718, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1426
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1719, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3026
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1720, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1035
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1721, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1722, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1723, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1724, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6622
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1725, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3821
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1726, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5354
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1727, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1728, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1411
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1729, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5960
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1730, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1731, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2044
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1732, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1736
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1733, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1734, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1735, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2465
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1736, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1737, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4035
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1738, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2340
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1739, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3429
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1740, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1741, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1742, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1743, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1744, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1745, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1746, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3555
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1747, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1748, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1724
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1749, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5999
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1750, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1636
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1751, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6000
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1752, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1753, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4265
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1754, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1755, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1640
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1756, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1757, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1758, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1759, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2233
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1760, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3172
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1761, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1698
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1762, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1763, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3038
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1764, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1765, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2975
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1766, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1767, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1768, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1769, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1770, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3572
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1771, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1772, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2820
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1773, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3207
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1774, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6028
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1775, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3592
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1776, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1777, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2049
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1778, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1779, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1780, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1781, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1782, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4021
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1783, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5546
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1784, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1785, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3168
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1786, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3439
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1787, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1788, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1789, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4853
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1790, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1791, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1792, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1793, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2262
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1794, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2528
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1795, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3945
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1796, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2743
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1797, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1798, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3605
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1799, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1800, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1801, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1802, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5362
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1803, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5545
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1804, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1805, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1806, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1807, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6254
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1808, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1809, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1677
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1810, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3414
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1811, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1812, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4388
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1813, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1814, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1815, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2339
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1816, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1817, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1818, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4324
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1819, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1820, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1821, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1822, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1823, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1824, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1825, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1826, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1827, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2873
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1828, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4307
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1829, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.8094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1830, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.8287
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1831, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5550
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1832, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1833, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1834, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1835, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1836, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1837, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0488
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1838, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3706
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1839, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1933
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1840, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2580
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1841, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1988
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1842, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1462
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1843, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2302
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1844, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4998
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1845, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1846, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1847, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1848, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1849, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.8240
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1850, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3630
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1851, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1852, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1853, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1854, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1855, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4675
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1856, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1857, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1858, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1859, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4477
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1860, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4970
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1861, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1862, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3813
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1863, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1864, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3454
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1865, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2296
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1866, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1867, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1868, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4402
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1869, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2333
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1870, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1871, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1872, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1873, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1973
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1874, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1875, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1876, num samples collected 5500, FPS 119
  Algorithm: train_loss 1.0039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1877, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1878, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1879, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1880, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2683
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1881, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2546
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1882, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1883, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1884, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1885, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2127
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1886, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1887, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1888, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2077
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1889, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1890, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1891, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2145
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1892, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3491
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1893, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1894, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.9130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1895, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6833
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1896, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1897, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2700
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1898, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1899, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1900, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1901, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3308
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1902, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2312
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1903, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1904, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1905, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1906, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3558
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1907, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3513
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1908, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1909, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1910, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1911, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1912, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1392
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1913, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1914, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5550
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1915, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4153
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1916, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1917, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1918, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1919, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2446
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1920, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1921, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5066
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1922, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1923, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1935
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1924, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1925, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4569
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1926, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2371
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1927, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1928, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3623
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1929, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1852
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1930, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1931, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1932, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1933, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1934, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1935, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1646
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1936, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2495
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1937, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1938, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5564
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1939, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1940, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3587
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1941, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1942, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1943, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1944, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3903
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1945, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4074
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1946, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1947, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3986
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1948, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1949, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1950, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1425
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1951, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3350
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1952, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1953, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.7251
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1954, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1955, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1956, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1957, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1958, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1443
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1959, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2617
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1960, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1961, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2365
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1962, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1963, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2630
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1964, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.6912
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1965, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2364
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1966, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4874
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1967, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1968, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1969, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2999
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1970, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3655
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1971, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1972, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1973, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2735
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1974, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1758
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1975, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2389
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1976, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1977, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3815
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1978, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1672
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1979, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3558
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1980, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3116
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1981, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1654
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1982, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2370
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1983, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3735
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1984, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1985, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1471
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1986, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1987, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5897
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1988, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3690
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1989, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2232
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1990, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1991, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1992, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2218
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1993, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3150
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1994, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1995, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1429
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1996, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1997, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1998, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 1999, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4480
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2000, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2001, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2341
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2002, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.7307
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2003, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2144
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2004, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2005, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1019
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2006, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2007, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2008, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3346
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2009, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2010, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2464
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2011, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4646
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2012, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2013, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2014, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3258
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2015, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3332
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2016, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3662
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2017, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2018, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0593
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2019, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2020, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2021, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.7317
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2022, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2023, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1729
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2024, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2025, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2026, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2386
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2027, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2432
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2028, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2029, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5633
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2030, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2031, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3531
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2032, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2033, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4263
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2034, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2035, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2036, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2037, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3187
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2038, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1014
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2039, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3647
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2040, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2041, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3743
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2042, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2043, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2795
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2044, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2045, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2046, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2047, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3167
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2048, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2049, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.7112
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2050, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3522
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2051, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2052, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2053, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2586
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2054, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3175
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2055, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2056, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2057, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2498
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2058, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3167
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2059, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2060, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4625
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2061, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3809
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2062, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3648
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2063, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2064, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1001
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2065, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2066, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3449
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2067, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2068, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4866
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2069, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2070, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2071, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1539
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2072, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.6600
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2073, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3665
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2074, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2075, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2843
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2076, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1418
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2077, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3052
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2078, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3175
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2079, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3986
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2080, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2081, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2082, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2083, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1455
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2084, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2085, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2086, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2087, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4813
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2088, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4334
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2089, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2090, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4901
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2091, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2092, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3725
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2093, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3925
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2094, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2298
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2095, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2366
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2096, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2097, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2098, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2099, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1447
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2100, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3599
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2101, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2102, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3569
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2103, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2104, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2105, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2086
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2106, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1614
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2107, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3565
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2108, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4346
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2109, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2110, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2111, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2112, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2113, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4667
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2114, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2115, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2493
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2116, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2117, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6159
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2118, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2119, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2120, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2121, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2122, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2123, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2124, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1722
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2125, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3978
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2126, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2127, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4268
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2128, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2500
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2129, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3432
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2130, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2131, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4935
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2132, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3115
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2133, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1367
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2134, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1776
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2135, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2136, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2137, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2316
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2138, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2139, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2140, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6922
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2141, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4889
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2142, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4268
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2143, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3401
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2144, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2145, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3758
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2146, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3676
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2147, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2148, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1282
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2149, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2150, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2151, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1516
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2152, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2528
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2153, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2857
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2154, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2155, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3750
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2156, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2157, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2158, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2159, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2160, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1674
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2161, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3014
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2162, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2163, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3851
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2164, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2165, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1416
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2166, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1259
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2167, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2168, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5483
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2169, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2170, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2171, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2172, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3367
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2173, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2174, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4631
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2175, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3680
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2176, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1636
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2177, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2178, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2830
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2179, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2180, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2181, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2182, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2183, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6278
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2184, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2185, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6607
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2186, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3542
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2187, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2385
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2188, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2189, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2190, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2191, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3466
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2192, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2193, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2194, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3970
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2195, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2196, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3674
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2197, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4210
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2198, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2199, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2200, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2201, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2202, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4053
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2203, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2204, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2205, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2206, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2207, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1905
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2208, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2209, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1052
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2210, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2211, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2212, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2213, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2214, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1720
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2215, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2727
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2216, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.9614
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2217, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1159
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2218, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2752
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2219, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2220, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2221, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1918
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2222, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2299
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2223, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5265
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2224, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2353
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2225, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2226, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.8844
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2227, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1870
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2228, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2229, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2230, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1478
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2231, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1276
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2232, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7409
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2233, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2234, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1722
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2235, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2835
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2236, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.6643
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2237, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3488
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2238, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2239, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2899
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2240, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2241, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2242, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3239
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2243, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2501
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2244, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2750
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2245, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2246, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3271
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2247, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2248, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2249, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2250, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.6387
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2251, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2252, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2253, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2254, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2255, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3071
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2256, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2257, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2258, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2590
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2259, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2989
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2260, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3434
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2261, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.9447
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2262, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2263, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2264, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4011
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2265, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2266, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2267, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2268, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2269, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4442
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2270, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2271, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2272, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2273, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2202
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2274, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2275, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2785
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2276, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2505
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2277, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3733
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2278, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2279, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3213
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2280, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3464
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2281, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3327
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2282, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3959
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2283, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2284, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2285, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2286, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2167
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2287, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2288, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1244
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2289, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2290, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6188
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2291, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2398
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2292, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2293, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2260
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2294, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2295, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2296, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1315
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2297, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2298, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2299, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2300, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5843
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2301, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2302, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2303, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2304, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2305, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2306, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3587
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2307, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6681
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2308, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2492
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2309, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2979
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2310, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5391
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2311, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2312, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2313, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2850
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2314, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6886
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2315, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2316, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2317, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2318, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2319, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2320, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2321, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2322, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2323, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1864
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2324, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2325, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1436
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2326, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2327, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4332
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2328, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2329, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2330, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2331, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4032
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2332, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6110
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2333, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3897
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2334, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.7030
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2335, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3574
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2336, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2613
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2337, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2338, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3322
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2339, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3678
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2340, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2341, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2342, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3382
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2343, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2344, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2345, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2348
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2346, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4358
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2347, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4130
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2348, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2349, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2350, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2186
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2351, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2773
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2352, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1157
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2353, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2354, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2355, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2356, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2357, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2358, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2359, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.7575
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2360, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2361, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3413
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2362, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2363, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3679
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2364, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2365, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2366, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2367, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.5293
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2368, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2369, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.8432
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2370, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.6188
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2371, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2372, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2373, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2374, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2375, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3679
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2376, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2377, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2378, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2379, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3627
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2380, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2381, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2382, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3270
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2383, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2384, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.7832
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2385, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2386, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2387, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2310
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2388, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3731
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2389, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2390, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4834
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2391, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2033
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2392, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1558
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2393, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2394, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2395, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2396, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2397, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3915
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2398, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2399, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2400, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2401, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4363
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2402, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1962
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2403, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2404, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2405, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2406, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2407, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2408, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2409, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2410, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4404
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2411, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2412, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2221
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2413, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3560
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2414, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1843
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2415, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4961
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2416, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2417, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2418, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2419, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2241
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2420, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3470
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2421, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2422, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3060
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2423, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1707
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2424, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2425, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2426, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.5658
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2427, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2428, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4290
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2429, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3564
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2430, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2431, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2531
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2432, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2433, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2434, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2378
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2435, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2500
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2436, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1238
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2437, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2438, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3258
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2439, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2440, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4606
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2441, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3583
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2442, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1004
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2443, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3635
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2444, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2445, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2446, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2447, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2448, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2449, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2450, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2451, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2452, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2453, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.5510
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2454, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3083
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2455, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2456, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2489
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2457, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1265
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2458, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1621
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2459, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.5932
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2460, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4219
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2461, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2173
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2462, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.6113
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2463, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2464, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2465, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2781
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2466, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2467, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2468, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2469, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3346
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2470, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2471, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2273
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2472, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1607
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2473, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2474, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.7623
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2475, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2476, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2056
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2477, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2478, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1550
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2479, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2732
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2480, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.3478
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2481, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2050
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2482, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2483, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2484, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2485, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2486, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2487, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2471
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2488, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2489, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2490, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1331
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2491, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3878
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2492, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3039
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2493, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2041
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2494, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.5096
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2495, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.6488
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2496, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2497, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2498, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2573
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2499, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2500, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2501, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2502, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1482
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2503, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3159
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2504, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4228
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2505, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2506, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4463
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2507, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2508, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2509, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4228
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2510, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.5436
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2511, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2512, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2513, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2514, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4134
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2515, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2516, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.7210
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2517, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.6208
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2518, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2519, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2520, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2521, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2522, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2523, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2361
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2524, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1848
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2525, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.2805
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2526, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2527, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2528, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3883
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2529, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3680
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2530, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2531, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2532, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2533, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4696
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2534, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2535, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3621
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2536, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4051
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2537, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4095
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2538, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.5522
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2539, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2540, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2541, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2542, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3705
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2543, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4157
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2544, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2545, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.3440
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2546, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2547, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.1231
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2548, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2549, num samples collected 5500, FPS 111
  Algorithm: train_loss 0.4208
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2550, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.3533
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2551, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.3379
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2552, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2553, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2554, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1541
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2555, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2556, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.2966
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2557, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2558, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2559, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.3306
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2560, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2561, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2562, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.2848
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2563, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2564, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2565, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2566, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.3866
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2567, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2568, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.2825
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2569, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.2549
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2570, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.7972
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2571, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1933
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2572, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0498
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2573, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2574, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.6564
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2575, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2576, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.4880
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2577, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2578, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.3946
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2579, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2580, num samples collected 5500, FPS 110
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -1366.4946, l 200.0000, t 128.0673, TestReward -1396.8020
Update 2581, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2582, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.7829
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2583, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1276
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2584, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2585, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2586, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2587, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2588, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2589, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2590, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4389
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2591, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1537
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2592, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1603
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2593, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2594, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2595, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2890
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2596, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2597, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2077
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2598, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4542
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2599, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2600, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2601, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1966
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2602, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4232
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2603, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2604, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2605, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2606, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3868
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2607, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2608, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2609, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3861
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2610, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1081
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2611, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3039
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2612, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2896
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2613, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2614, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4870
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2615, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2446
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2616, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2605
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2617, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2340
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2618, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2619, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2620, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1887
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2621, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2622, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5432
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2623, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2624, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2625, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2626, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3097
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2627, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2628, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2629, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2630, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1863
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2631, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3772
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2632, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4540
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2633, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4714
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2634, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4332
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2635, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2636, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2637, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3544
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2638, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2258
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2639, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2640, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2641, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2642, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4206
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2643, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2644, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2635
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2645, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2646, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6221
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2647, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2648, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2649, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2650, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2651, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3982
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2652, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6144
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2653, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2654, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2655, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2656, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1376
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2657, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5327
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2658, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2659, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2660, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1881
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2661, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2330
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2662, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3260
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2663, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2832
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2664, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3087
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2665, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4138
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2666, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2667, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2668, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0203
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2669, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2670, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2671, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2672, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2673, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2674, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2675, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1711
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2676, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2312
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2677, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1301
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2678, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2679, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6169
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2680, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2681, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2682, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1596
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2683, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2684, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3916
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2685, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2492
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2686, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2687, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1246
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2688, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1485
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2689, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2801
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2690, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2691, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3593
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2692, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2693, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5881
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2694, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2695, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.8177
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2696, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2697, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2016
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2698, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2699, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2700, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2701, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3696
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2702, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4457
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2703, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2704, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2705, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2706, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3283
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2707, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0455
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2708, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2709, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2710, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2711, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1185
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2712, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2713, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7569
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2714, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2715, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5450
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2716, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2669
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2717, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2718, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2719, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2720, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2721, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2722, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1648
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2723, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1662
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2724, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2725, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2726, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1006
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2727, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6561
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2728, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7213
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2729, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2730, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3742
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2731, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2732, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2353
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2733, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2734, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2735, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3645
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2736, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2737, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2738, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2607
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2739, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4603
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2740, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2741, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2742, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2743, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2744, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2679
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2745, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2746, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2417
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2747, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2748, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2749, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2477
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2750, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2751, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2752, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3673
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2753, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2754, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2755, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5160
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2756, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2757, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3745
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2758, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2759, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1008
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2760, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2761, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3541
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2762, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2763, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2764, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7502
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2765, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2376
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2766, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4697
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2767, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2768, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2769, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2770, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2551
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2771, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2772, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2499
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2773, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4151
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2774, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6257
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2775, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2776, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2777, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2778, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2408
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2779, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2780, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1698
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2781, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2782, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4408
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2783, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2784, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6476
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2785, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2786, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2787, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2788, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2227
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2789, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3318
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2790, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2197
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2791, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2792, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7737
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2793, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2577
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2794, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1502
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2795, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2796, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2797, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2798, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1661
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2799, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2800, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2140
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2801, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2802, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2803, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2697
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2804, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2805, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2908
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2806, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2807, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3650
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2808, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5461
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2809, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2810, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2619
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2811, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2812, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2813, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2814, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2815, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2232
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2816, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2817, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2455
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2818, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5150
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2819, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2820, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2821, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3460
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2822, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6578
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2823, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2057
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2824, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2825, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2826, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2827, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2828, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3013
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2829, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5215
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2830, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2786
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2831, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2832, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6003
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2833, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2834, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2835, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2836, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2837, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2838, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2839, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2840, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2841, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6046
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2842, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2849
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2843, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1942
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2844, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2845, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2846, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3584
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2847, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2351
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2848, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2849, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2850, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7156
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2851, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2852, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2175
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2853, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2854, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3581
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2855, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6754
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2856, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2857, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2858, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2859, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2992
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2860, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0469
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2861, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2862, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4578
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2863, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1172
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2864, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4398
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2865, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3803
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2866, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2867, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5122
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2868, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2869, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2870, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2453
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2871, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6472
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2872, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2873, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3210
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2874, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2875, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2876, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2877, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2878, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2879, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3415
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2880, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1645
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2881, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3510
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2882, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2883, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2884, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2885, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4716
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2886, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2772
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2887, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3424
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2888, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2889, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3084
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2890, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2891, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2892, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2579
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2893, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2894, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2895, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4014
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2896, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2897, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2970
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2898, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2899, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4396
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2900, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2901, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1839
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2902, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2903, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2904, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4058
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2905, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2906, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1666
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2907, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6130
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2908, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3307
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2909, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2910, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2983
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2911, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2912, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2913, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3811
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2914, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3800
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2915, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1661
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2916, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2917, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2918, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4069
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2919, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2853
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2920, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2921, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1785
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2922, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2923, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2758
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2924, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2925, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2406
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2926, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2927, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2307
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2928, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2929, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2396
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2930, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2931, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2932, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2933, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1326
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2934, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2935, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.8477
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2936, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2937, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2938, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3367
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2939, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2940, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5001
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2941, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4466
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2942, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2323
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2943, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2944, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2945, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2565
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2946, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2947, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2948, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6914
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2949, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2950, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2951, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1522
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2952, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2953, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2954, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2955, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2200
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2956, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6605
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2957, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6500
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2958, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3540
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2959, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1004
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2960, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2961, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2962, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2963, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6497
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2964, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2965, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1440
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2966, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2943
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2967, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2968, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2652
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2969, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2970, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6755
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2971, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2972, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2973, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1007
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2974, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2975, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2976, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2977, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5071
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2978, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5446
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2979, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2980, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2981, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4542
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2982, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4447
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2983, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4525
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2984, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1614
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2985, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2986, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2987, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6558
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2988, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2989, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2990, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2991, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4145
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2992, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1624
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2993, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2994, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2995, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2256
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2996, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2997, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2998, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2628
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 2999, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5567
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3000, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2198
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3001, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3002, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3003, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2469
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3004, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3005, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6181
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3006, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3390
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3007, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3008, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4898
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3009, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2538
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3010, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3179
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3011, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3012, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1917
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3013, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3014, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3015, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3016, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3017, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3018, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2396
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3019, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3020, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3021, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3022, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3023, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5047
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3024, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3390
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3025, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3026, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7647
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3027, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3028, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4172
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3029, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3030, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3031, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3032, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3033, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3034, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3035, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2317
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3036, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3037, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5338
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3038, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3039, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3880
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3040, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4286
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3041, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.8503
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3042, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3043, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3044, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3045, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3046, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1973
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3047, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2328
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3048, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7055
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3049, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3050, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3051, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2523
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3052, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3028
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3053, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5306
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3054, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3055, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3056, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3057, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3058, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5440
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3059, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3060, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3061, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3062, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3063, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3064, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3924
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3065, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3066, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3067, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2172
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3068, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1603
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3069, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3070, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1498
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3071, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3072, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3073, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3074, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3075, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3076, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3077, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4524
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3078, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.8408
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3079, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3275
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3080, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1919
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3081, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2517
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3082, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3297
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3083, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3084, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3085, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3086, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.9140
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3087, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3088, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3089, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3090, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3372
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3091, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3092, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3093, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3152
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3094, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2004
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3095, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3096, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4525
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3097, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3098, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3099, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1208
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3100, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3101, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3102, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3103, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3104, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3018
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3105, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3106, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5870
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3107, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5774
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3108, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3109, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3110, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3111, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3112, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3113, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3114, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5212
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3115, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3116, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3541
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3117, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3118, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0470
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3119, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2724
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3120, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3121, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3122, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4345
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3123, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3124, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3125, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3203
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3126, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3127, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2019
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3128, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2221
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3129, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3130, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3131, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7191
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3132, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3133, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5974
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3134, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0992
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3135, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3136, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3137, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4140
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3138, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3645
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3139, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3140, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3141, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3142, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3143, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3144, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3145, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3146, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3147, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1412
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3148, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3533
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3149, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3150, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3323
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3151, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3152, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3153, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3154, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3155, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3156, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3157, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3875
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3158, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3159, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.8253
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3160, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3161, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3162, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2855
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3163, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3164, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5135
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3165, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1244
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3166, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3167, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3168, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3169, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3170, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2049
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3171, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3172, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6301
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3173, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3174, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3175, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3176, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2913
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3177, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3178, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4020
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3179, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3180, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7356
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3181, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3182, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3183, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3685
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3184, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3185, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3186, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5054
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3187, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3188, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2769
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3189, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2400
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3190, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3191, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3192, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3471
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3193, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3194, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1543
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3195, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3312
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3196, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3197, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6025
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3198, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3199, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1588
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3200, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2431
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3201, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3202, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3203, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3741
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3204, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3205, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3206, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2907
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3207, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3208, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3209, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3305
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3210, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3211, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4454
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3212, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3213, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3214, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3650
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3215, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3216, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2517
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3217, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4416
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3218, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4858
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3219, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3220, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3221, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7179
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3222, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3223, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3224, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5664
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3225, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0969
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3226, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3227, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3228, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3229, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3230, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3231, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3232, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3233, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3234, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7028
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3235, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1371
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3236, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3237, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4209
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3238, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3239, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3240, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5879
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3241, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4461
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3242, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3243, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4154
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3244, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1681
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3245, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3246, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3919
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3247, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3248, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3249, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3585
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3250, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3094
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3251, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4482
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3252, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2388
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3253, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3254, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4884
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3255, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1636
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3256, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3257, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3258, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3517
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3259, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3260, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3261, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4898
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3262, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5267
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3263, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1852
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3264, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2715
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3265, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3266, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2410
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3267, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3268, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3269, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2519
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3270, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3271, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1535
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3272, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3273, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3274, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5853
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3275, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3276, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3242
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3277, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3278, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3279, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4351
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3280, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3460
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3281, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3282, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3283, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3239
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3284, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3358
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3285, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3286, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3287, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4254
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3288, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3289, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3290, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3291, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3884
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3292, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2877
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3293, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2366
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3294, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2054
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3295, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4496
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3296, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0227
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3297, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3298, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3299, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3300, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3301, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3593
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3302, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1648
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3303, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3304, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3305, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2968
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3306, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3307, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5749
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3308, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3309, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3310, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3311, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1100
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3312, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3313, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6016
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3314, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3315, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3316, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3317, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4660
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3318, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3319, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2895
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3320, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3380
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3321, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1863
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3322, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3323, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3324, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3333
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3325, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3326, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2761
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3327, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3328, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3329, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4454
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3330, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5861
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3331, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4421
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3332, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3333, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3334, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3335, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2595
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3336, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2195
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3337, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3338, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2452
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3339, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3445
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3340, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3807
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3341, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7536
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3342, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3343, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3344, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3345, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1962
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3346, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2807
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3347, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3348, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3349, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3090
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3350, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3351, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2475
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3352, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3353, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1209
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3354, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3355, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2345
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3356, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0997
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3357, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3358, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5847
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3359, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3162
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3360, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3361, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3307
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3362, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3363, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3364, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3365, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3366, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0981
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3367, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4159
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3368, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3369, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4479
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3370, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6382
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3371, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3372, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0947
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3373, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3374, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2811
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3375, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3376, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1554
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3377, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3378, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1481
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3379, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3038
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3380, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5959
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3381, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3382, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3383, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3384, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3385, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3386, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5913
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3387, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3388, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0827
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3389, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2695
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3390, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3391, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4452
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3392, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2371
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3393, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3394, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3395, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4510
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3396, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1817
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3397, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3785
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3398, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3779
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3399, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7432
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3400, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3401, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3616
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3402, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3403, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3404, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3405, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0255
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3406, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2751
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3407, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3408, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2076
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3409, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3410, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2871
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3411, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3412, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2897
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3413, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3414, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3415, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3211
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3416, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4017
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3417, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3418, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3419, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3420, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3328
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3421, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3422, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3220
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3423, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2982
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3424, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3983
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3425, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3984
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3426, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3427, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3428, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3429, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4863
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3430, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2551
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3431, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3432, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3433, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0976
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3434, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4002
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3435, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1645
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3436, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3406
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3437, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3438, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3439, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3440, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1925
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3441, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3442, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1713
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3443, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3498
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3444, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3445, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3446, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2793
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3447, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3448, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.7134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3449, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3450, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4301
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3451, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3881
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3452, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2349
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3453, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3454, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3455, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5054
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3456, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1601
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3457, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1162
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3458, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3459, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3460, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6369
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3461, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1491
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3462, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3463, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3464, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3619
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3465, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3466, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2017
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3467, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2478
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3468, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3469, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4276
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3470, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3471, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3472, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3473, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3474, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6285
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3475, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1707
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3476, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3477, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4043
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3478, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4026
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3479, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6866
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3480, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3153
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3481, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3926
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3482, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3483, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3484, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0936
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3485, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0263
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3486, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3487, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1504
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3488, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3489, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3490, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3491, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3492, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1548
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3493, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2823
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3494, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3495, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3277
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3496, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6379
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3497, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2579
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3498, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3499, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2448
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3500, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3501, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3608
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3502, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5541
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3503, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3504, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.7011
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3505, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3506, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3507, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0979
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3508, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3509, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1029
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3510, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3429
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3511, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3512, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3513, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4996
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3514, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3515, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3516, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3715
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3517, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3518, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3519, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5588
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3520, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3521, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3522, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1225
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3523, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3524, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2328
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3525, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3526, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3527, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3528, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3223
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3529, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3809
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3530, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3531, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3532, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4111
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3533, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3534, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3535, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3536, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2073
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3537, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3538, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3256
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3539, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3540, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3541, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3542, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2776
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3543, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3544, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3226
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3545, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3546, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6923
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3547, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2491
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3548, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3549, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4658
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3550, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3551, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4720
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3552, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4017
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3553, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3554, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3555, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4857
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3556, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0468
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3557, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2373
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3558, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3559, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3560, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3561, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3562, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1010
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3563, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3818
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3564, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3565, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4648
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3566, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3567, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3568, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2888
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3569, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3038
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3570, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3571, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3572, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3573, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3574, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3575, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3576, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3577, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3761
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3578, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2495
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3579, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3580, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3484
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3581, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2755
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3582, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3963
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3583, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0891
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3584, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7165
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3585, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2316
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3586, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3504
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3587, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3588, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3589, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3590, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3728
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3591, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1640
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3592, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3593, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2071
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3594, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5868
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3595, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4391
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3596, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3597, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1316
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3598, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1627
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3599, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2590
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3600, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3601, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3602, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3603, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2408
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3604, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3605, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3606, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3607, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1622
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3608, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3609, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3610, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3611, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6936
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3612, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5811
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3613, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3614, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3615, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9525
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3616, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3617, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3983
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3618, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2516
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3619, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3620, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3621, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0918
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3622, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3623, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4208
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3624, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3625, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4692
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3626, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0958
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3627, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3628, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2414
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3629, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3630, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3631, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3632, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1232
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3633, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3634, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3944
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3635, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3636, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3637, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4913
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3638, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3639, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3640, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3641, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2736
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3642, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3643, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4559
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3644, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3645, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1736
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3646, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3353
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3647, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3648, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3649, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4142
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3650, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3651, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3652, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3653, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3248
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3654, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3655, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2708
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3656, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3657, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3658, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4523
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3659, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3660, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3661, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7766
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3662, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3663, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3664, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3739
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3665, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3666, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3233
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3667, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3668, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7276
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3669, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3670, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3765
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3671, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3672, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3673, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3674, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3675, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2430
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3676, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3677, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2383
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3678, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3679, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9400
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3680, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4061
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3681, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3682, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3683, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3684, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3685, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4448
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3686, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3404
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3687, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3925
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3688, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4580
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3689, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3690, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3691, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6221
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3692, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3693, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3694, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2696
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3695, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3696, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3697, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3698, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4764
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3699, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3700, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3701, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3702, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2317
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3703, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3704, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1724
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3705, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1611
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3706, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3703
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3707, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3708, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6264
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3709, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3311
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3710, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3711, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4542
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3712, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0464
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3713, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3714, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3715, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3716, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3717, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1265
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3718, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5090
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3719, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3720, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4023
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3721, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3722, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3723, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3724, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1175
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3725, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3726, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3727, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1429
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3728, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1684
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3729, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5424
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3730, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3731, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3732, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3378
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3733, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2747
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3734, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4027
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3735, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1463
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3736, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3737, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3738, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.6398
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3739, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3028
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3740, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4732
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3741, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3742, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3743, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3744, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3745, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3983
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3746, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2316
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3747, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2673
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3748, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3749, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3750, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2713
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3751, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3752, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1484
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3753, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3754, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3755, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3756, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3757, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3758, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.9386
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3759, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4011
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3760, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1603
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3761, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3762, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4927
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3763, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3764, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3765, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5468
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3766, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3767, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3768, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3769, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3770, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3771, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2292
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3772, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3773, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1006
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3774, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3153
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3775, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3776, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3777, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5003
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3778, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3779, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3489
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3780, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3781, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3782, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1395
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3783, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3965
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3784, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0797
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3785, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1843
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3786, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3787, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3982
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3788, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3789, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3790, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3679
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3791, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3792, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3793, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0468
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3794, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3795, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3579
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3796, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5237
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3797, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4374
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3798, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3799, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2575
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3800, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3801, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3802, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3803, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4892
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3804, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3805, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2536
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3806, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3807, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4209
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3808, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3809, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3308
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3810, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3811, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3812, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5659
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3813, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3814, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2396
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3815, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5736
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3816, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3817, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3818, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4337
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3819, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2143
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3820, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3821, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1543
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3822, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2037
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3823, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4232
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3824, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.6534
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3825, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3826, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3827, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3828, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1588
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3829, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2294
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3830, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3831, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3832, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2785
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3833, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3896
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3834, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3835, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1159
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3836, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3837, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3838, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3839, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0992
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3840, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5005
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3841, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3842, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4332
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3843, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3551
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3844, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4246
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3845, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0862
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3846, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3847, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3848, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3849, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3850, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3851, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3852, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5042
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3853, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.8036
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3854, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3855, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3856, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3857, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3858, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3859, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3860, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3531
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3861, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0871
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3862, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0947
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3863, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3864, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3566
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3865, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5644
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3866, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4412
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3867, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1511
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3868, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3869, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1554
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3870, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3871, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2835
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3872, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0704
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3873, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3874, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4743
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3875, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0986
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3876, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.7339
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3877, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1471
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3878, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3879, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3880, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3881, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3882, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3268
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3883, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3884, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2233
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3885, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.3235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3886, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3887, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3888, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.5003
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3889, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3890, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3891, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3892, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.4904
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3893, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3894, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3895, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3896, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3897, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3898, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3899, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3900, num samples collected 5750, FPS 77
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3901, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.5424
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3902, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.6638
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3903, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3904, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.4612
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3905, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1694
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3906, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1554
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3907, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.6383
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3908, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2673
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3909, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3910, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3911, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3912, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3913, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0965
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3914, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3915, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3916, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3917, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3918, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2460
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3919, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.4108
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3920, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2467
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3921, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.5304
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3922, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1698
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3923, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3924, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3925, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1518
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3926, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3927, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3928, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3929, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2726
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3930, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.7215
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3931, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2418
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3932, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3933, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1066
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3934, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2188
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3935, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.4537
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3936, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3937, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.3398
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3938, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3939, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3940, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3941, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3942, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3943, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3944, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3945, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.3235
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3946, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3947, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3948, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.3504
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3949, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.3113
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3950, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.6255
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3951, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3952, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.2220
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3953, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3954, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.3278
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3955, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1009
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3956, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3957, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.7273
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3958, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3959, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3960, num samples collected 5750, FPS 76
  Algorithm: train_loss 0.6987
  Episodes: TrainReward -1350.4427, l 200.0000, t 151.7656, TestReward -1434.3100
Update 3961, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3962, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1267
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3963, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2493
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3964, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3202
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3965, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3365
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3966, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3967, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2336
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3968, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1816
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3969, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7324
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3970, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2272
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3971, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3972, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2764
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3973, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5387
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3974, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1935
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3975, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3976, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3977, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3978, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3979, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3990
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3980, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3981, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3982, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2427
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3983, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6141
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3984, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3985, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3986, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3261
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3987, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5708
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3988, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3989, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3990, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0875
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3991, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4022
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3992, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3466
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3993, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3264
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3994, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3995, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3283
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3996, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3997, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3998, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2531
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 3999, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1194
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4000, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2416
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4001, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3549
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4002, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4003, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6262
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4004, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4005, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1756
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4006, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1422
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4007, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4008, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4009, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4010, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4011, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4012, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3699
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4013, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8217
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4014, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0797
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4015, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4016, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4017, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3007
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4018, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0925
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4019, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4020, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1776
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4021, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4022, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4023, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3525
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4024, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2518
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4025, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4026, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3563
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4027, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3030
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4028, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4029, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4030, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2792
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4031, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4032, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4033, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4034, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3682
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4035, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2072
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4036, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3293
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4037, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0793
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4038, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4039, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4040, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5460
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4041, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4373
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4042, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4043, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3873
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4044, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4045, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4046, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4047, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3881
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4048, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3451
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4049, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3609
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4050, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2720
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4051, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4052, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4053, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4054, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4055, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4056, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5167
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4057, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4058, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5958
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4059, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0619
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4060, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4061, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1499
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4062, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4063, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3570
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4064, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4829
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4065, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4029
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4066, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4067, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1975
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4068, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4069, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4070, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4071, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4279
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4072, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4073, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4074, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2444
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4075, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5889
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4076, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4311
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4077, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4078, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4079, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4080, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5090
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4081, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4082, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4083, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4084, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4085, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2384
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4086, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2942
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4087, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3795
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4088, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4089, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4090, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4091, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7052
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4092, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3562
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4093, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4539
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4094, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4095, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2652
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4096, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4097, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4098, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5274
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4099, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1194
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4100, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1648
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4101, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4102, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2969
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4103, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3351
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4104, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4105, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5795
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4106, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4107, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4108, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4109, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4110, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4111, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7241
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4112, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4113, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1246
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4114, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4115, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4116, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4117, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4118, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1971
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4119, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4120, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4121, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5519
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4122, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4608
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4123, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4124, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4125, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5523
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4126, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1772
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4127, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4128, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8228
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4129, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4130, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5624
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4131, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4132, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3755
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4133, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1694
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4134, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2416
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4135, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4136, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8009
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4137, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4584
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4138, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4139, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4140, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3653
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4141, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2672
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4142, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4143, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4144, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2845
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4145, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1034
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4146, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4147, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4148, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4149, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0672
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4150, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5410
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4151, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4152, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3628
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4153, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4154, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4003
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4155, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4156, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2325
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4157, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4158, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4159, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4394
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4160, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1500
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4161, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4162, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4163, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4164, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1282
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4165, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5790
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4166, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4167, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4168, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4169, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3289
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4170, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3287
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4171, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4172, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4183
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4173, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1583
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4174, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4175, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3742
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4176, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4177, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4178, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0870
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4179, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1578
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4180, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2632
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4181, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3834
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4182, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3777
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4183, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4184, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4185, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3146
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4186, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2741
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4187, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3967
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4188, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4189, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2862
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4190, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4191, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4192, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4193, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3660
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4194, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4195, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2510
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4196, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4197, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4198, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2519
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4199, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4200, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4821
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4201, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5907
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4202, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4203, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2476
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4204, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4205, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4206, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4207, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4177
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4208, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4209, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2640
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4210, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4211, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5190
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4212, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4213, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2425
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4214, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4215, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3550
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4216, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4045
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4217, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1552
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4218, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1729
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4219, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2953
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4220, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3292
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4221, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4222, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4223, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4224, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4225, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2389
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4226, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4227, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2398
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4228, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2797
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4229, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4230, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4837
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4231, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2991
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4232, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4233, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4234, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2894
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4235, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4236, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4237, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4238, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0328
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4239, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0599
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4240, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3328
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4241, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4242, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4243, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4244, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2941
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4245, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7170
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4246, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4247, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2722
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4248, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4249, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2038
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4250, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5358
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4251, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2617
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4252, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4371
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4253, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4254, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4255, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0888
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4256, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4257, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3330
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4258, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4259, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2942
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4260, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3826
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4261, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2380
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4262, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4263, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4264, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4265, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4266, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4267, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1739
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4268, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4269, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4270, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4539
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4271, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5286
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4272, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4273, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4274, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3355
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4275, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1617
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4276, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8059
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4277, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4278, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4279, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4280, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4281, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4282, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4283, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8374
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4284, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4285, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4286, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4287, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3293
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4288, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4289, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4290, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4237
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4291, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4292, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4293, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4621
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4294, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4295, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0834
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4296, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4297, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4298, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2935
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4299, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4300, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4301, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4302, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2057
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4303, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3862
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4304, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4305, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4983
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4306, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2953
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4307, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2905
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4308, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5220
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4309, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4310, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3263
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4311, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3064
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4312, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1009
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4313, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4895
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4314, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2709
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4315, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4316, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4317, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0851
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4318, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1720
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4319, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4320, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4321, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4322, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4323, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4203
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4324, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2358
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4325, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2289
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4326, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4327, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4328, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2821
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4329, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4330, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4331, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4332, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0966
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4333, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4334, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1725
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4335, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4336, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4337, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4338, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8386
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4339, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0808
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4340, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4341, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2466
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4342, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1486
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4343, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4344, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4345, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4346, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4347, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3019
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4348, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4349, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4308
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4350, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4927
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4351, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4352, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3232
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4353, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4354, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3468
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4355, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2403
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4356, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4357, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1434
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4358, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4359, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4360, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0884
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4361, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3179
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4362, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4363, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1933
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4364, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0609
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4365, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4425
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4366, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3405
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4367, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4368, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4369, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4370, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4371, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4372, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2699
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4373, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4374, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3829
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4375, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4376, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5619
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4377, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6089
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4378, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4379, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1601
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4380, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4381, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1254
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4382, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3823
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4383, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4384, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4385, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4898
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4386, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4387, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4388, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2554
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4389, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4390, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4391, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5273
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4392, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6339
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4393, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4394, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4395, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4396, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4397, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4398, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4399, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7640
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4400, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1460
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4401, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2339
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4402, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2125
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4403, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4404, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4405, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4852
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4406, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4407, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4408, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4409, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4410, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4411, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4720
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4412, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3898
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4413, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4414, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4415, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3558
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4416, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4417, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4418, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4419, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4420, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4421, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4422, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4423, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1582
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4424, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1354
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4425, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1988
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4426, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4427, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5974
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4428, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3076
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4429, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2355
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4430, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3499
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4431, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2351
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4432, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4433, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4434, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4435, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4436, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3238
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4437, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5836
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4438, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4439, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2933
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4440, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.6210
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4441, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3636
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4442, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4443, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4444, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4848
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4445, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2137
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4446, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3546
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4447, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5451
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4448, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4449, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2838
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4450, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3981
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4451, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4452, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4453, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4454, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4455, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4456, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4457, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4458, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3304
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4459, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4460, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1177
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4461, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4462, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4463, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3213
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4464, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4465, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4466, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5054
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4467, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4468, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6732
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4469, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4470, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4471, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4472, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5515
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4473, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4474, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0777
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4475, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4476, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4267
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4477, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4478, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4479, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4480, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4481, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4482, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4483, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4484, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4485, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4486, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4487, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3385
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4488, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0228
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4489, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4490, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2014
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4491, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4492, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4493, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3635
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4494, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4495, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4496, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4497, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4498, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4499, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4500, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4501, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5675
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4502, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4503, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2323
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4504, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5219
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4505, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4506, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0854
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4507, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4508, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2348
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4509, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5386
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4510, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4511, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2871
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4512, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6309
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4513, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2831
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4514, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3456
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4515, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4516, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0466
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4517, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3969
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4518, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2724
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4519, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4520, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4660
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4521, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2803
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4522, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6576
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4523, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4524, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4525, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4526, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4388
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4527, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4528, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3462
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4529, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4530, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2468
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4531, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4532, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4533, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4534, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4535, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3086
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4536, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1701
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4537, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4724
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4538, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2768
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4539, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0860
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4540, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4541, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4542, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6636
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4543, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4544, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4545, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4546, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4547, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4228
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4548, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4549, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1157
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4550, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3671
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4551, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4552, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3735
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4553, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4554, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1458
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4555, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4556, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4557, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4558, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3380
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4559, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3716
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4560, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4561, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4562, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4563, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4564, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5167
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4565, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4566, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4567, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0992
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4568, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4569, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1303
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4570, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1799
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4571, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4572, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4573, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4574, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0571
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4575, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4576, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4577, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0840
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4578, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4579, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2774
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4580, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8168
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4581, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3835
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4582, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2387
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4583, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1573
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4584, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4585, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4586, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3608
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4587, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4588, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1473
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4589, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9622
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4590, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4591, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2335
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4592, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4593, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4594, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4595, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2520
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4596, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1529
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4597, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3630
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4598, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4599, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4600, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1987
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4601, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4602, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.7350
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4603, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4328
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4604, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4605, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4606, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4607, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4608, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4609, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3531
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4610, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1862
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4611, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2874
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4612, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4613, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3051
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4614, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3334
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4615, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4616, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2569
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4617, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4618, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4619, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4620, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4621, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4622, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3238
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4623, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4624, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2615
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4625, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4626, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1556
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4627, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4794
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4628, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4629, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4630, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0785
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4631, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0272
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4632, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3821
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4633, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4634, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4635, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1432
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4636, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4637, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2576
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4638, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1995
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4639, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4276
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4640, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4641, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6363
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4642, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4643, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1596
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4644, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.7292
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4645, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2017
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4646, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5491
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4647, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4648, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4649, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4650, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4651, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2603
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4652, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0607
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4653, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4654, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4655, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1776
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4656, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4657, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4658, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4659, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5843
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4660, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4188
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4661, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2242
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4662, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4663, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4664, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4665, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4666, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3370
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4667, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4668, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4669, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4670, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4671, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0929
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4672, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4673, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4674, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5977
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4675, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4676, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1669
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4677, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3474
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4678, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4623
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4679, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4680, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4681, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4682, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4683, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4684, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2924
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4685, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4686, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4687, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4688, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4689, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2292
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4690, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4691, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5152
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4692, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2940
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4693, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1433
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4694, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3257
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4695, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2065
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4696, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4697, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0448
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4698, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4699, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2493
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4700, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4701, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4673
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4702, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8338
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4703, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0930
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4704, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4705, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4706, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4707, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4550
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4708, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4709, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4710, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4711, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2272
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4712, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0409
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4713, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4714, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4715, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1707
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4716, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9336
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4717, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4718, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4719, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2830
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4720, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4721, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2307
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4722, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1540
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4723, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1837
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4724, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2560
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4725, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3337
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4726, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2427
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4727, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2767
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4728, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4729, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0918
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4730, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2564
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4731, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3527
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4732, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6132
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4733, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4734, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1232
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4735, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4736, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3081
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4737, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3810
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4738, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3677
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4739, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2803
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4740, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3259
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4741, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4742, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4743, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4744, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4745, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4746, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2533
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4747, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4748, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4749, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1000
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4750, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4751, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4752, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3200
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4753, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4754, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4755, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2435
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4756, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4757, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4758, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4759, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2828
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4760, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6656
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4761, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4762, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.7399
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4763, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3484
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4764, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4765, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4766, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4767, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3372
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4768, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3276
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4769, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1199
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4770, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3634
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4771, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1545
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4772, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4773, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5164
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4774, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4775, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3349
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4776, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4777, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4778, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4779, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3096
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4780, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4781, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6017
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4782, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1298
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4783, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2824
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4784, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3051
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4785, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4786, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1448
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4787, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4788, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4247
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4789, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0789
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4790, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2195
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4791, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4885
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4792, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4793, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1596
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4794, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4795, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3369
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4796, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.7299
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4797, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0942
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4798, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4799, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4800, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0866
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4801, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1412
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4802, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1642
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4803, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4804, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4500
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4805, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3833
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4806, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4109
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4807, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4808, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4809, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4810, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4811, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4812, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8069
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4813, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2486
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4814, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1240
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4815, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4816, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4817, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4818, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5521
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4819, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4820, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4821, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4822, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4823, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2050
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4824, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2669
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4825, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4826, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4572
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4827, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4828, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1617
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4829, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3430
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4830, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2816
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4831, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4832, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4833, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0954
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4834, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2495
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4835, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4836, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4599
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4837, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4838, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1633
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4839, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1183
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4840, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2444
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4841, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4842, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2843
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4843, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4844, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4845, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1538
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4846, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1028
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4847, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4848, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4849, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0943
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4850, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4676
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4851, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2984
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4852, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4853, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3050
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4854, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2688
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4855, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1571
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4856, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4857, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3301
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4858, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3602
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4859, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1517
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4860, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4861, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4862, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4863, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4864, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4865, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1990
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4866, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0924
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4867, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3840
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4868, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4869, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2480
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4870, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3648
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4871, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2320
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4872, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4873, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2744
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4874, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3282
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4875, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4876, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2678
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4877, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4878, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4879, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4880, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1116
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4881, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3501
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4882, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4883, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2778
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4884, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2671
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4885, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4595
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4886, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5046
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4887, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4888, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4889, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4890, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3951
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4891, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4892, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2528
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4893, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4894, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3337
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4895, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1718
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4896, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4897, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1661
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4898, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4899, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4900, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1607
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4901, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4902, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4903, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4904, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3302
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4905, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1411
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4906, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5048
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4907, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3638
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4908, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4909, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4910, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4911, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4912, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3396
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4913, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1438
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4914, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1576
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4915, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4127
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4916, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4272
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4917, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3081
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4918, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4919, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3051
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4920, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4921, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4338
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4922, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4725
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4923, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4924, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0228
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4925, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0906
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4926, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4927, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4928, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0785
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4929, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0416
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4930, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5823
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4931, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1481
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4932, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4933, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5854
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4934, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4935, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4936, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4937, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2790
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4938, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4939, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4940, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3963
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4941, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4942, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1192
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4943, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4646
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4944, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4945, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4946, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4947, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2682
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4948, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2543
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4949, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4819
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4950, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4951, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4532
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4952, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4953, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3337
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4954, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1768
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4955, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2545
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4956, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3468
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4957, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4958, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4355
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4959, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4960, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5709
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4961, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4962, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2765
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4963, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4964, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3636
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4965, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0972
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4966, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4967, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4968, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4969, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1498
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4970, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4971, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5407
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4972, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3666
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4973, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4974, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4975, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0228
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4976, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4977, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4978, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3639
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4979, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1647
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4980, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4981, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4982, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4983, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4866
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4984, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4985, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4526
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4986, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2164
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4987, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5993
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4988, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3646
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4989, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4990, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3903
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4991, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4992, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4993, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4994, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3372
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4995, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4996, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1509
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4997, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3870
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4998, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 4999, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5000, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3316
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5001, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5002, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4484
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5003, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5004, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5005, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1610
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5006, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5007, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5008, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5009, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3016
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5010, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5011, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5012, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2183
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5013, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.7739
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5014, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5015, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5738
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5016, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5017, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5018, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6431
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5019, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4515
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5020, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5021, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3103
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5022, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5023, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3019
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5024, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5025, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5026, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3978
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5027, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5028, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1530
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5029, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5030, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3291
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5031, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3865
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5032, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5033, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2359
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5034, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3721
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5035, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5036, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5037, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5038, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5039, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5040, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5041, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3917
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5042, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5043, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2961
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5044, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1423
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5045, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3252
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5046, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1952
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5047, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5048, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5049, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2923
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5050, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5051, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1262
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5052, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0936
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5053, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5054, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2741
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5055, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5056, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5057, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2386
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5058, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2461
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5059, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4445
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5060, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1187
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5061, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5062, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5063, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5064, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5616
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5065, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5066, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2369
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5067, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5068, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5069, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2812
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5070, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3509
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5071, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5072, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2310
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5073, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4103
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5074, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5075, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5076, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3749
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5077, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2014
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5078, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5079, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4811
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5080, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3057
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5081, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2296
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5082, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2202
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5083, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3891
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5084, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0400
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5085, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5086, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5087, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5088, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5089, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5090, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2205
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5091, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3812
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5092, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2886
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5093, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4528
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5094, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1207
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5095, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5096, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5875
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5097, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5098, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1696
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5099, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5100, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5101, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5102, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5103, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5104, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4006
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5105, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5106, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1559
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5107, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5108, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3318
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5109, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3369
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5110, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5111, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5112, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5113, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5114, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4085
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5115, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5116, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5117, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5118, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5119, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4605
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5120, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5121, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4284
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5122, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3905
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5123, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2646
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5124, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5454
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5125, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5126, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5127, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5128, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5129, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2065
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5130, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2302
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5131, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4340
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5132, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4667
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5133, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5134, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4507
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5135, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5136, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5137, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.8766
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5138, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3030
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5139, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5140, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5141, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5708
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5142, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0918
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5143, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5144, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5145, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5146, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4757
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5147, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0764
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5148, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5149, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5150, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3210
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5151, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5152, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0417
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5153, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5154, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0945
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5155, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5156, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5157, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5158, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1331
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5159, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3229
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5160, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5161, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5162, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5163, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3088
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5164, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1473
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5165, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5166, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5167, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5913
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5168, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5169, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0881
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5170, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5171, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5172, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5427
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5173, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3334
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5174, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5175, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5176, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1530
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5177, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5178, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5380
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5179, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5180, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0852
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5181, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5182, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6142
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5183, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5184, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5185, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5186, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2961
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5187, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5188, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3068
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5189, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5190, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5191, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5192, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2788
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5193, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5194, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5195, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5196, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2865
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5197, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2307
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5198, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4410
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5199, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3461
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5200, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5201, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5202, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1239
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5203, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5204, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2489
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5205, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5928
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5206, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5207, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1481
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5208, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5209, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5210, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2624
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5211, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3244
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5212, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5478
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5213, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5214, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5215, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2242
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5216, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3467
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5217, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5218, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3624
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5219, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5220, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.6185
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5221, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5222, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2417
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5223, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5224, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0906
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5225, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3599
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5226, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5227, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5228, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5229, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5230, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5231, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3623
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5232, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5233, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5234, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5235, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2330
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5236, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5237, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5238, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5239, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5240, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3131
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5241, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2859
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5242, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5243, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2813
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5244, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5245, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5246, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5247, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2174
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5248, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5249, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5250, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1528
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5251, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.6697
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5252, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.6330
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5253, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3631
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5254, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5255, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4572
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5256, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5257, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0798
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5258, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.9373
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5259, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5260, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5261, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5262, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5263, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1591
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5264, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5265, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1226
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5266, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2967
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5267, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2323
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5268, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3138
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5269, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4062
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5270, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5271, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1645
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5272, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1433
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5273, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4698
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5274, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0354
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5275, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5276, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5277, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5278, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.7732
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5279, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5280, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5281, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.7697
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5282, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5283, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2227
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5284, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5285, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4596
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5286, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1646
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5287, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2064
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5288, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3011
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5289, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1881
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5290, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5291, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3718
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5292, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5293, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2384
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5294, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0324
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5295, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5296, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5297, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5298, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5299, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5300, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3719
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5301, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5302, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5303, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5304, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2980
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5305, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5306, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5307, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1197
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5308, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5309, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5310, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1713
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5311, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5312, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1551
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5313, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5314, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3220
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5315, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5316, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5317, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2917
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5318, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5319, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5320, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0443
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5321, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4696
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5322, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5323, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2401
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5324, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5246
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5325, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3164
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5326, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2379
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5327, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3494
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5328, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5329, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5330, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.7750
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5331, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2326
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5332, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4030
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5333, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4906
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5334, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5335, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5336, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.5562
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5337, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2960
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5338, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5339, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5340, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5341, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3955
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5342, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5343, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2550
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5344, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3326
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5345, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5346, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5347, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5348, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5349, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5350, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5351, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5352, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5353, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2636
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5354, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5355, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2224
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5356, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5357, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4568
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5358, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3828
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5359, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1407
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5360, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5361, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4702
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5362, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1382
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5363, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5364, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2236
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5365, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5366, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5367, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4390
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5368, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2454
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5369, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1512
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5370, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5371, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.3041
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5372, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.4650
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5373, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2239
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5374, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5375, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5376, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5377, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1643
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5378, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5379, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5380, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5381, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1489
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5382, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5383, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5384, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5385, num samples collected 6000, FPS 59
  Algorithm: train_loss 0.2844
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5386, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.3148
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5387, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5388, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.1486
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5389, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.3595
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5390, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.2321
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5391, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5392, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5393, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.4808
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5394, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5395, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.3972
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5396, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.5063
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5397, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5398, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5399, num samples collected 6000, FPS 58
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5400, num samples collected 6000, FPS 58
  Algorithm: train_loss 1.0922
  Episodes: TrainReward -1434.3336, l 200.0000, t 178.0906, TestReward -1384.3068
Update 5401, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5402, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5403, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2862
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5404, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3510
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5405, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4414
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5406, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5407, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5408, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5409, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5410, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1592
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5411, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5412, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3851
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5413, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3152
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5414, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4013
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5415, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5416, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5417, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3260
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5418, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5419, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2153
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5420, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4536
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5421, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5422, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5423, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1528
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5424, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5522
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5425, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2791
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5426, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2336
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5427, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2444
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5428, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2681
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5429, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1341
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5430, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5431, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5432, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5433, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3509
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5434, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4831
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5435, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1200
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5436, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5437, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5438, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5439, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5440, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5441, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0812
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5442, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5443, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1530
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5444, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5445, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0326
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5446, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2175
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5447, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2740
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5448, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5449, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9125
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5450, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5451, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1448
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5452, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5453, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0829
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5454, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5455, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4918
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5456, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1621
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5457, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3120
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5458, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5459, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4800
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5460, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1830
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5461, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5462, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5463, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5464, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3654
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5465, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5466, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5467, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5468, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2413
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5469, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2712
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5470, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5471, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2734
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5472, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5473, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4822
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5474, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5475, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5476, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5477, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4761
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5478, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4410
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5479, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5480, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2675
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5481, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5482, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2051
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5483, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2857
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5484, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5599
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5485, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5486, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5487, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5488, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5489, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5490, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5491, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5492, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4026
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5493, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5878
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5494, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5495, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5496, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0927
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5497, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0353
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5498, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5499, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4237
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5500, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5501, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3481
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5502, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5503, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5504, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5505, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5506, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5507, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5508, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5509, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2222
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5510, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5511, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3470
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5512, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5513, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3728
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5514, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5515, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3757
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5516, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5517, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5518, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0275
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5519, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5742
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5520, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1623
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5521, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3103
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5522, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5523, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3838
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5524, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3571
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5525, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5612
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5526, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2744
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5527, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5965
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5528, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4607
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5529, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1514
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5530, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5531, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1221
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5532, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5533, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5534, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5512
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5535, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5536, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5537, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5538, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5539, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2275
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5540, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2784
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5541, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3616
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5542, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5543, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5544, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5545, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4830
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5546, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0791
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5547, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2881
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5548, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3712
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5549, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0887
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5550, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5551, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3383
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5552, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5553, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3592
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5554, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2760
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5555, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0760
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5556, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5557, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5558, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5559, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1373
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5560, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8122
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5561, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5562, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5563, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5564, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4857
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5565, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2798
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5566, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5567, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5568, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5569, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5570, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5571, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0410
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5572, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5573, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1189
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5574, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2865
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5575, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5527
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5576, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2458
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5577, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5578, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5446
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5579, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1414
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5580, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1779
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5581, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5582, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5583, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1622
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5584, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3126
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5585, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5586, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5587, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4473
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5588, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1186
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5589, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5590, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2536
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5591, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5592, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5593, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5594, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5595, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4702
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5596, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1105
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5597, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5598, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5599, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2998
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5600, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5601, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3331
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5602, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8437
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5603, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1171
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5604, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5605, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5606, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5607, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5608, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5609, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8789
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5610, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5611, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0590
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5612, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4629
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5613, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5614, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5615, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5616, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2566
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5617, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5618, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5619, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5620, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2394
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5621, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2478
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5622, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5623, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2512
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5624, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2034
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5625, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5626, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5788
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5627, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2668
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5628, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3292
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5629, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5630, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0833
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5631, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6030
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5632, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5633, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1980
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5634, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5635, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5636, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3237
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5637, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2903
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5638, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0333
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5639, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5640, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5641, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5642, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5643, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5644, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5645, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5542
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5646, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2804
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5647, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2172
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5648, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5649, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3030
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5650, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5651, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2565
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5652, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3555
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5653, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2966
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5654, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2757
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5655, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5656, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5657, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5658, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5659, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0859
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5660, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3292
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5661, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1471
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5662, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4511
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5663, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5664, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5665, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3936
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5666, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3024
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5667, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2927
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5668, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4577
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5669, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1738
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5670, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5671, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5672, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5673, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5674, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2371
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5675, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2595
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5676, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5677, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5678, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6429
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5679, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3142
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5680, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3232
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5681, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5682, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1451
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5683, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3217
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5684, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6057
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5685, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2256
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5686, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0915
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5687, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1388
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5688, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4636
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5689, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5690, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5691, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5692, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1447
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5693, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5694, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1168
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5695, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1539
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5696, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5697, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5698, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5145
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5699, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0952
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5700, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5701, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3552
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5702, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0975
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5703, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4136
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5704, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5705, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5706, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5707, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5708, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3335
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5709, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3601
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5710, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5711, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3998
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5712, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5713, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5714, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5715, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5716, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2756
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5717, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3076
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5718, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2264
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5719, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5720, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5721, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5722, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9794
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5723, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5724, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5725, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5726, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3342
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5727, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5728, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2631
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5729, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5730, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5731, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5732, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5733, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5734, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5735, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2946
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5736, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4167
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5737, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5738, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5171
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5739, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5740, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1506
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5741, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5742, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5743, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1881
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5744, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7823
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5745, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5746, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5747, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3850
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5748, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5749, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3647
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5750, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8640
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5751, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5752, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5753, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5493
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5754, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3422
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5755, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0912
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5756, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1975
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5757, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5758, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5759, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5760, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5761, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2709
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5762, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2792
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5763, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4007
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5764, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5765, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0275
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5766, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5767, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0775
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5768, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5333
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5769, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5557
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5770, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3664
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5771, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5772, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5773, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3359
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5774, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3725
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5775, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5776, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4129
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5777, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4391
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5778, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3087
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5779, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5780, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5781, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2829
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5782, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3680
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5783, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5784, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3791
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5785, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5786, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0824
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5787, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2452
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5788, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2458
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5789, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5790, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1246
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5791, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1410
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5792, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5360
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5793, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5794, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1536
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5795, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5796, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5797, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5798, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0213
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5799, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5800, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.5162
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5801, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3369
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5802, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2628
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5803, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3548
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5804, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5805, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4418
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5806, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5807, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5808, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5062
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5809, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5810, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5811, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2997
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5812, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5813, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4864
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5814, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5815, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5816, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5817, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5818, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4027
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5819, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5820, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6185
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5821, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1537
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5822, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3148
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5823, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5824, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5825, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5826, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3314
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5827, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2501
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5828, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5829, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5830, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2500
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5831, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3722
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5832, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5833, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5834, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2710
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5835, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0983
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5836, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0307
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5837, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5838, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4254
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5839, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5840, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5841, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5127
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5842, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4279
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5843, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2173
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5844, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5845, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2105
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5846, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5847, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5848, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3835
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5849, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5850, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2627
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5851, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1168
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5852, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5853, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5854, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1496
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5855, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2524
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5856, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1801
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5857, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6474
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5858, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2252
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5859, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4634
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5860, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2423
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5861, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1496
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5862, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5863, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1345
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5864, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5865, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5866, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3231
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5867, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5868, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5869, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3539
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5870, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2358
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5871, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5872, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3189
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5873, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1544
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
Update 5874, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1452.6831, l 200.0000, t 206.1296, TestReward -1348.1689
