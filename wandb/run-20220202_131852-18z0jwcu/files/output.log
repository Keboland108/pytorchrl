Sequential(
  (0): Linear(in_features=4, out_features=500, bias=True)
  (1): ReLU()
  (2): Linear(in_features=500, out_features=500, bias=True)
  (3): ReLU()
  (4): DeterministicMB(
    (output): Linear(in_features=500, out_features=3, bias=True)
  )
)
Training model from scratch
Training model from scratch
Collecting initial samples...
Created CWorker with worker_index 0
Created GWorker with worker_index 0
Update 1, num samples collected 5250, FPS 317
  Algorithm: train_loss 0.8482
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 2, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.4732
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 3, num samples collected 5250, FPS 316
  Algorithm: train_loss 1.4197
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 4, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.1824
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 5, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.2789
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 6, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.6188
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 7, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 8, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.5972
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 9, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.0981
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 10, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.0776
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 11, num samples collected 5250, FPS 316
  Algorithm: train_loss 0.3715
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 12, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.0838
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 13, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.4459
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 14, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.1645
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 15, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.6193
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 16, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 17, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 18, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.8589
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 19, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.5419
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 20, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.5779
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 21, num samples collected 5250, FPS 315
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 22, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.2438
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 23, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.0685
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 24, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.6378
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 25, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.5789
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 26, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 27, num samples collected 5250, FPS 314
  Algorithm: train_loss 1.1108
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 28, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.1507
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 29, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.3620
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 30, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.8263
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 31, num samples collected 5250, FPS 314
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 32, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 33, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.8161
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 34, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 35, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 36, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.1809
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 37, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.6061
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 38, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.5401
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 39, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.1089
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 40, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 41, num samples collected 5250, FPS 313
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 42, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 43, num samples collected 5250, FPS 312
  Algorithm: train_loss 1.1509
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 44, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.4075
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 45, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 46, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 47, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.9312
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 48, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 49, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.2282
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 50, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.6866
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 51, num samples collected 5250, FPS 312
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 52, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 53, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.4235
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 54, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.3457
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 55, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.0589
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 56, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.2271
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 57, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.3139
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 58, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 59, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.0450
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 60, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.6641
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 61, num samples collected 5250, FPS 311
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 62, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 63, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 64, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.1759
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 65, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.5835
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 66, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 67, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 68, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 69, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 70, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 71, num samples collected 5250, FPS 310
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 72, num samples collected 5250, FPS 309
  Algorithm: train_loss 1.0700
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 73, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.6298
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 74, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 75, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 76, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 77, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.5006
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 78, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.5532
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 79, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.6030
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 80, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 81, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 82, num samples collected 5250, FPS 309
  Algorithm: train_loss 0.1356
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 83, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.5348
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 84, num samples collected 5250, FPS 308
  Algorithm: train_loss 1.4592
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 85, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.2277
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 86, num samples collected 5250, FPS 308
  Algorithm: train_loss 1.0958
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 87, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 88, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.4031
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 89, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.6132
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 90, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.4871
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 91, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.8869
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 92, num samples collected 5250, FPS 308
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 93, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 94, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 95, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.2260
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 96, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 97, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0457
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 98, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 99, num samples collected 5250, FPS 307
  Algorithm: train_loss 1.0485
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 100, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 101, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 102, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0416
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 103, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 104, num samples collected 5250, FPS 307
  Algorithm: train_loss 0.0491
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 105, num samples collected 5250, FPS 306
  Algorithm: train_loss 1.0215
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 106, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 107, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.3409
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 108, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 109, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.4091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 110, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 111, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 112, num samples collected 5250, FPS 306
  Algorithm: train_loss 1.0603
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 113, num samples collected 5250, FPS 306
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 114, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 115, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 116, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.4485
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 117, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.3930
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 118, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.1630
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 119, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.5652
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 120, num samples collected 5250, FPS 305
  Algorithm: train_loss 1.0173
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 121, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.0973
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 122, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.3095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 123, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.6395
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 124, num samples collected 5250, FPS 305
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 125, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 126, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 127, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 128, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 129, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 130, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.8594
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 131, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.5112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 132, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 133, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.0839
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 134, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 135, num samples collected 5250, FPS 304
  Algorithm: train_loss 0.5711
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 136, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.2295
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 137, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.5921
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 138, num samples collected 5250, FPS 303
  Algorithm: train_loss 1.1134
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 139, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.5282
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 140, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.4736
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 141, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 142, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 143, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 144, num samples collected 5250, FPS 303
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 145, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.8085
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 146, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 147, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 148, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.4105
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 149, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 150, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0962
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 151, num samples collected 5250, FPS 302
  Algorithm: train_loss 1.5522
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 152, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 153, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.6544
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 154, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 155, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.6691
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 156, num samples collected 5250, FPS 302
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 157, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 158, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 159, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 160, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 161, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.4491
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 162, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 163, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.4935
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 164, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.2137
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 165, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.4080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 166, num samples collected 5250, FPS 301
  Algorithm: train_loss 0.1809
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 167, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 168, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 169, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 170, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.5619
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 171, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.8707
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 172, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.5578
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 173, num samples collected 5250, FPS 300
  Algorithm: train_loss 1.1594
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 174, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.0627
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 175, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.1772
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 176, num samples collected 5250, FPS 300
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 177, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.6755
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 178, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 179, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 180, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 181, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0553
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 182, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 183, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.6371
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 184, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 185, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0262
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 186, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 187, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 188, num samples collected 5250, FPS 299
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 189, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.8836
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 190, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.7143
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 191, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 192, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 193, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 194, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.3259
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 195, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.5504
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 196, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 197, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.3376
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 198, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 199, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.5746
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 200, num samples collected 5250, FPS 298
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 201, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.1292
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 202, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 203, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 204, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 205, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.8416
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 206, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.6545
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 207, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 208, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 209, num samples collected 5250, FPS 297
  Algorithm: train_loss 1.1567
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 210, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.2542
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 211, num samples collected 5250, FPS 297
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 212, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 213, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.4455
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 214, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.7345
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 215, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.4063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 216, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.8033
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 217, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.4013
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 218, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.1763
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 219, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.3361
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 220, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 221, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.4499
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 222, num samples collected 5250, FPS 296
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 223, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.5205
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 224, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0848
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 225, num samples collected 5250, FPS 295
  Algorithm: train_loss 1.1237
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 226, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 227, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 228, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 229, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 230, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.2615
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 231, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0719
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 232, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 233, num samples collected 5250, FPS 295
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 234, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.1411
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 235, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 236, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 237, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.4011
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 238, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.4023
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 239, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.5270
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 240, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 241, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.6368
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 242, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 243, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.6193
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 244, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.3867
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 245, num samples collected 5250, FPS 294
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 246, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.6254
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 247, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 248, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 249, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 250, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.6669
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 251, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.4475
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 252, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.9554
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 253, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 254, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.4003
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 255, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 256, num samples collected 5250, FPS 293
  Algorithm: train_loss 0.0501
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 257, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.2976
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 258, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 259, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 260, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.6937
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 261, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 262, num samples collected 5250, FPS 292
  Algorithm: train_loss 2.1066
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 263, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 264, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4869
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 265, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 266, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 267, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 268, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 269, num samples collected 5250, FPS 292
  Algorithm: train_loss 0.4592
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 270, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 271, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 272, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.5434
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 273, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 274, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 275, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 276, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.7169
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 277, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.5220
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 278, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.5165
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 279, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.3392
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 280, num samples collected 5250, FPS 291
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 281, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 282, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 283, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 284, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.4491
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 285, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.2996
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 286, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0856
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 287, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 288, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.1348
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 289, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 290, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 291, num samples collected 5250, FPS 290
  Algorithm: train_loss 1.6347
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 292, num samples collected 5250, FPS 290
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 293, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 294, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.1949
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 295, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0411
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 296, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.5115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 297, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.1611
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 298, num samples collected 5250, FPS 289
  Algorithm: train_loss 1.2138
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 299, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.3349
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 300, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.9112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 301, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 302, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 303, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 304, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 305, num samples collected 5250, FPS 289
  Algorithm: train_loss 0.4040
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 306, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 307, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 308, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0498
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 309, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.9337
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 310, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.3969
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 311, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 312, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 313, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.6478
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 314, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.1338
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 315, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 316, num samples collected 5250, FPS 288
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 317, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 318, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 319, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4962
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 320, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.2629
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 321, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0589
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 322, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 323, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.4988
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 324, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 325, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.7559
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 326, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.5734
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 327, num samples collected 5250, FPS 287
  Algorithm: train_loss 0.7908
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 328, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 329, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 330, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 331, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 332, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.6107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 333, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 334, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 335, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 336, num samples collected 5250, FPS 286
  Algorithm: train_loss 1.0302
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 337, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.4035
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 338, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 339, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 340, num samples collected 5250, FPS 286
  Algorithm: train_loss 0.7992
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 341, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0234
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 342, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.1450
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 343, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.5354
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 344, num samples collected 5250, FPS 285
  Algorithm: train_loss 1.5409
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 345, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.2161
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 346, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.4984
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 347, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 348, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.1742
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 349, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 350, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.6524
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 351, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 352, num samples collected 5250, FPS 285
  Algorithm: train_loss 0.3419
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 353, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0408
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 354, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 355, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.5586
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 356, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 357, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 358, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 359, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.5114
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 360, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 361, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 362, num samples collected 5250, FPS 284
  Algorithm: train_loss 1.1830
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 363, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 364, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 365, num samples collected 5250, FPS 284
  Algorithm: train_loss 0.6584
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 366, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.3953
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 367, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.5692
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 368, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.4721
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 369, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0556
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 370, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1358
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 371, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0263
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 372, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0527
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 373, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 374, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.6288
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 375, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.4496
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 376, num samples collected 5250, FPS 283
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 377, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 378, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.3083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 379, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 380, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 381, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.4935
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 382, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 383, num samples collected 5250, FPS 282
  Algorithm: train_loss 1.0298
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 384, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0466
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 385, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.5608
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 386, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 387, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 388, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 389, num samples collected 5250, FPS 282
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 390, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.8394
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 391, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.7671
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 392, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 393, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 394, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 395, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.5642
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 396, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.6641
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 397, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 398, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 399, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 400, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.4506
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 401, num samples collected 5250, FPS 281
  Algorithm: train_loss 0.4922
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 402, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 403, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.9530
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 404, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.5636
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 405, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 406, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 407, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 408, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.6171
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 409, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.3924
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 410, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 411, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1811
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 412, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.0536
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 413, num samples collected 5250, FPS 280
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 414, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.4276
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 415, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.5304
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 416, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 417, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.6749
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 418, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 419, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 420, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 421, num samples collected 5250, FPS 279
  Algorithm: train_loss 1.1355
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 422, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 423, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.1792
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 424, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.4621
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 425, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 426, num samples collected 5250, FPS 279
  Algorithm: train_loss 0.8425
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 427, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1378
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 428, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 429, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.6177
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 430, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 431, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 432, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.3914
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 433, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.5747
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 434, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.1330
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 435, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.4396
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 436, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 437, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 438, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.7567
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 439, num samples collected 5250, FPS 278
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 440, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0382
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 441, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 442, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 443, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.8725
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 444, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.4397
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 445, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 446, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.6202
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 447, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0562
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 448, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.3417
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 449, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 450, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.7672
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 451, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.5460
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 452, num samples collected 5250, FPS 277
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 453, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4348
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 454, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 455, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0255
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 456, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 457, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4592
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 458, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 459, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.2294
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 460, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 461, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.4057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 462, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 463, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 464, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.1696
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 465, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0951
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 466, num samples collected 5250, FPS 276
  Algorithm: train_loss 0.0858
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 467, num samples collected 5250, FPS 275
  Algorithm: train_loss 1.2808
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 468, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 469, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 470, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 471, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 472, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 473, num samples collected 5250, FPS 275
  Algorithm: train_loss 1.0743
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 474, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.8541
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 475, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0653
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 476, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0373
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 477, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.1571
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 478, num samples collected 5250, FPS 275
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 479, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 480, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.4952
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 481, num samples collected 5250, FPS 274
  Algorithm: train_loss 1.0326
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 482, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.1758
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 483, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 484, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.7975
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 485, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 486, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.4305
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 487, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.5625
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 488, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 489, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.6288
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 490, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.2113
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 491, num samples collected 5250, FPS 274
  Algorithm: train_loss 0.5220
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 492, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.3743
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 493, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 494, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.5595
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 495, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.4445
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 496, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.4418
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 497, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 498, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.6772
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 499, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 500, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 501, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.1780
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 502, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 503, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 504, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 505, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 506, num samples collected 5250, FPS 273
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 507, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 508, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 509, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 510, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.6195
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 511, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.6419
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 512, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.2978
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 513, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0515
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 514, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 515, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.9203
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 516, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 517, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 518, num samples collected 5250, FPS 272
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 519, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.4375
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 520, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 521, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.1553
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 522, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.6606
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 523, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 524, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.9608
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 525, num samples collected 5250, FPS 271
  Algorithm: train_loss 0.7623
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 526, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.1460
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 527, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.8522
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 528, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 529, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 530, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 531, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 532, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 533, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 534, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 535, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.0387
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 536, num samples collected 5250, FPS 270
  Algorithm: train_loss 0.9222
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 537, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0478
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 538, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.4001
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 539, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 540, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.4457
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 541, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.7392
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 542, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.1305
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 543, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.5117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 544, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0227
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 545, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.9067
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 546, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 547, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.5160
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 548, num samples collected 5250, FPS 269
  Algorithm: train_loss 0.3371
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 549, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 550, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 551, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 552, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 553, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.6065
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 554, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.6293
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 555, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3528
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 556, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.7598
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 557, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0949
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 558, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.4324
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 559, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 560, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.3946
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 561, num samples collected 5250, FPS 268
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 562, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 563, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 564, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1285
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 565, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.8877
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 566, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 567, num samples collected 5250, FPS 267
  Algorithm: train_loss 1.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 568, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.3934
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 569, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1432
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 570, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 571, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 572, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 573, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.4441
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 574, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.5294
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 575, num samples collected 5250, FPS 267
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 576, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 577, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 578, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.4477
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 579, num samples collected 5250, FPS 266
  Algorithm: train_loss 1.0363
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 580, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 581, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 582, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 583, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.0377
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 584, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 585, num samples collected 5250, FPS 266
  Algorithm: train_loss 1.2902
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 586, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.7107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 587, num samples collected 5250, FPS 266
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 588, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.7762
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 589, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.5810
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 590, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 591, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.4770
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 592, num samples collected 5250, FPS 265
  Algorithm: train_loss 1.2149
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 593, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 594, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 595, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 596, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 597, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 598, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 599, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.5657
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 600, num samples collected 5250, FPS 265
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 601, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0203
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 602, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 603, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.3340
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 604, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 605, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.9507
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 606, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2084
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 607, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.5073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 608, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.3915
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 609, num samples collected 5250, FPS 264
  Algorithm: train_loss 1.0159
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 610, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 611, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.4385
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 612, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 613, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.0225
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 614, num samples collected 5250, FPS 264
  Algorithm: train_loss 0.8741
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 615, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 616, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.5906
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 617, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.3883
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 618, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.8076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 619, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.5227
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 620, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.3888
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 621, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.9523
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 622, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 623, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0533
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 624, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 625, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.4858
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 626, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 627, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 628, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 629, num samples collected 5250, FPS 263
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 630, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 631, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0403
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 632, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.8370
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 633, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.6168
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 634, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 635, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 636, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.7580
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 637, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0444
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 638, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.8589
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 639, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.5539
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 640, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.4294
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 641, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 642, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 643, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.5233
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 644, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 645, num samples collected 5250, FPS 262
  Algorithm: train_loss 0.5159
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 646, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 647, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 648, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 649, num samples collected 5250, FPS 261
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 650, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 651, num samples collected 5250, FPS 260
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 652, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.3225
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 653, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4360
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 654, num samples collected 5250, FPS 259
  Algorithm: train_loss 1.0574
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 655, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1322
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 656, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4357
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 657, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.2773
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 658, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.8905
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 659, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 660, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.5289
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 661, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 662, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 663, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 664, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 665, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.4418
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 666, num samples collected 5250, FPS 259
  Algorithm: train_loss 0.5112
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 667, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 668, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1244
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 669, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 670, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2033
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 671, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 672, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 673, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.5772
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 674, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.1390
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 675, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.2773
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 676, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 677, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 678, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 679, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 680, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.6477
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 681, num samples collected 5250, FPS 258
  Algorithm: train_loss 0.4062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 682, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.4413
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 683, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 684, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.5141
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 685, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 686, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 687, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0203
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 688, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 689, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.1287
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 690, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.6682
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 691, num samples collected 5250, FPS 257
  Algorithm: train_loss 1.0261
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 692, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.2420
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 693, num samples collected 5250, FPS 257
  Algorithm: train_loss 1.6283
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 694, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.7193
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 695, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.3212
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 696, num samples collected 5250, FPS 257
  Algorithm: train_loss 0.5456
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 697, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 698, num samples collected 5250, FPS 256
  Algorithm: train_loss 1.0485
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 699, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 700, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.4837
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 701, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1647
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 702, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 703, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.2957
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 704, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 705, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.3968
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 706, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.4907
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 707, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 708, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 709, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 710, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.9490
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 711, num samples collected 5250, FPS 256
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 712, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2122
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 713, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 714, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2636
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 715, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 716, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 717, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.3176
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 718, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 719, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 720, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 721, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.6593
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 722, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.3238
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 723, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 724, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.5336
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 725, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.2770
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 726, num samples collected 5250, FPS 255
  Algorithm: train_loss 0.5182
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 727, num samples collected 5250, FPS 254
  Algorithm: train_loss 1.0486
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 728, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 729, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 730, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 731, num samples collected 5250, FPS 254
  Algorithm: train_loss 0.4432
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 732, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 733, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 734, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.6065
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 735, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.7640
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 736, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 737, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.1365
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 738, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.9292
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 739, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 740, num samples collected 5250, FPS 253
  Algorithm: train_loss 0.5177
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 741, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3975
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 742, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 743, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 744, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.7407
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 745, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3395
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 746, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 747, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.4794
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 748, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.3953
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 749, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 750, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0994
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 751, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.9853
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 752, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 753, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 754, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.5044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 755, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0481
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 756, num samples collected 5250, FPS 252
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 757, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 758, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 759, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.6404
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 760, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 761, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 762, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.6285
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 763, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 764, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.6335
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 765, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0380
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 766, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 767, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 768, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0382
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 769, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 770, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 771, num samples collected 5250, FPS 251
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 772, num samples collected 5250, FPS 251
  Algorithm: train_loss 1.2753
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 773, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4002
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 774, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.5117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 775, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4864
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 776, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.4466
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 777, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.8832
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 778, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 779, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 780, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 781, num samples collected 5250, FPS 250
  Algorithm: train_loss 1.1671
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 782, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 783, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.1034
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 784, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.3036
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 785, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.1640
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 786, num samples collected 5250, FPS 250
  Algorithm: train_loss 0.5144
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 787, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.4455
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 788, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 789, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.4253
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 790, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 791, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.7186
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 792, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.4340
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 793, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 794, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.1674
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 795, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 796, num samples collected 5250, FPS 249
  Algorithm: train_loss 0.9464
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 797, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.3265
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 798, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0877
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 799, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 800, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 801, num samples collected 5250, FPS 248
  Algorithm: train_loss 0.6042
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 802, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.2032
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 803, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 804, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.8123
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 805, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 806, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 807, num samples collected 5250, FPS 246
  Algorithm: train_loss 0.7758
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 808, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.6729
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 809, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.7435
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 810, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.2946
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 811, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 812, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.3954
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 813, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 814, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.1109
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 815, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.3243
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 816, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 817, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 818, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.9414
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 819, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 820, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 821, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.6317
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 822, num samples collected 5250, FPS 245
  Algorithm: train_loss 0.2041
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 823, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 824, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.2185
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 825, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 826, num samples collected 5250, FPS 244
  Algorithm: train_loss 1.2931
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 827, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.4508
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 828, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 829, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.3976
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 830, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 831, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0370
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 832, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.1357
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 833, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 834, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.8290
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 835, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 836, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 837, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.7053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 838, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.4056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 839, num samples collected 5250, FPS 244
  Algorithm: train_loss 0.4433
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 840, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 841, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 842, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0960
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 843, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.6793
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 844, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 845, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 846, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 847, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 848, num samples collected 5250, FPS 243
  Algorithm: train_loss 1.5447
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 849, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.2178
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 850, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.1238
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 851, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 852, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 853, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 854, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.9822
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 855, num samples collected 5250, FPS 243
  Algorithm: train_loss 0.8315
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 856, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 857, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1722
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 858, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 859, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.4077
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 860, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 861, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 862, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.7827
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 863, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.1386
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 864, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.5605
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 865, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.9888
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 866, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.2790
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 867, num samples collected 5250, FPS 242
  Algorithm: train_loss 1.2080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 868, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 869, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 870, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 871, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 872, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 873, num samples collected 5250, FPS 242
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 874, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.6782
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 875, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.5092
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 876, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 877, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 878, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 879, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 880, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.2470
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 881, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 882, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 883, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.7007
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 884, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.6245
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 885, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.4098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 886, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.4417
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 887, num samples collected 5250, FPS 241
  Algorithm: train_loss 1.3108
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 888, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 889, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 890, num samples collected 5250, FPS 241
  Algorithm: train_loss 0.1161
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 891, num samples collected 5250, FPS 240
  Algorithm: train_loss 0.4966
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 892, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 893, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 894, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 895, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.6681
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 896, num samples collected 5250, FPS 239
  Algorithm: train_loss 0.2935
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 897, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 898, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.4906
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 899, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0450
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 900, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 901, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 902, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0849
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 903, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 904, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 905, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 906, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.4721
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 907, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 908, num samples collected 5250, FPS 238
  Algorithm: train_loss 0.4798
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 909, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.1725
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 910, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 911, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 912, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.4752
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 913, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 914, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 915, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.5138
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 916, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 917, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 918, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.3192
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 919, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 920, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.1662
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 921, num samples collected 5250, FPS 237
  Algorithm: train_loss 1.2554
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 922, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 923, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0983
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 924, num samples collected 5250, FPS 237
  Algorithm: train_loss 1.0694
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 925, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 926, num samples collected 5250, FPS 237
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 927, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0403
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 928, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.4052
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 929, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.4942
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 930, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.4475
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 931, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 932, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 933, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.5965
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 934, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.8305
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 935, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.5114
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 936, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.6208
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 937, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 938, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.6113
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 939, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 940, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.1789
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 941, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0585
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 942, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 943, num samples collected 5250, FPS 236
  Algorithm: train_loss 0.5187
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 944, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 945, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 946, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.9986
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 947, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 948, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.2315
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 949, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0510
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 950, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 951, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.9454
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 952, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 953, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 954, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 955, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 956, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.5304
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 957, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 958, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 959, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 960, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 961, num samples collected 5250, FPS 235
  Algorithm: train_loss 0.6792
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 962, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5106
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 963, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.9651
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 964, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 965, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.8151
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 966, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 967, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 968, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.4629
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 969, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 970, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.5965
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 971, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.6020
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 972, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.6180
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 973, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0389
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 974, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 975, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 976, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0941
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 977, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 978, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.4972
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 979, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.2883
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 980, num samples collected 5250, FPS 234
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 981, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 982, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.3984
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 983, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.4441
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 984, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 985, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.9240
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 986, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0451
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 987, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.8653
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 988, num samples collected 5250, FPS 233
  Algorithm: train_loss 1.1002
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 989, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.2372
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 990, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.3859
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 991, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.4710
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 992, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.2965
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 993, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 994, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 995, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 996, num samples collected 5250, FPS 233
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 997, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 998, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.4840
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 999, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.8284
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1000, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1001, num samples collected 5250, FPS 232
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1002, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.5084
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1003, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1004, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1005, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1006, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1007, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1008, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.9258
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1009, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1010, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0380
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1011, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.5173
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1012, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1013, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.5051
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1014, num samples collected 5250, FPS 231
  Algorithm: train_loss 1.0383
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1015, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.3116
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1016, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.1720
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1017, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1018, num samples collected 5250, FPS 231
  Algorithm: train_loss 0.5749
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1019, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.7747
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1020, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1021, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.5305
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1022, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1023, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1024, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1265
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1025, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1406
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1026, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.6647
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1027, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1028, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1029, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.9966
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1030, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1031, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.8544
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1032, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1033, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.6098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1034, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.3973
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1035, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1036, num samples collected 5250, FPS 230
  Algorithm: train_loss 0.6515
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1037, num samples collected 5250, FPS 230
  Algorithm: train_loss 1.5192
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1038, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1039, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1040, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0531
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1041, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1042, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3042
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1043, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1044, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1248
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1045, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1046, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1047, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1048, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.9599
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1049, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1050, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1051, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1052, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1053, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.1994
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1054, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.4133
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1055, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.3918
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1056, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.5634
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1057, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.4786
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1058, num samples collected 5250, FPS 229
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1059, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1060, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.6248
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1061, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.4295
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1062, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1063, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1064, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1065, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0964
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1066, num samples collected 5250, FPS 228
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1067, num samples collected 5250, FPS 227
  Algorithm: train_loss 1.0309
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1068, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1069, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.4818
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1070, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.7305
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1071, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.3301
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1072, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.4651
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1073, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.8310
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1074, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1075, num samples collected 5250, FPS 227
  Algorithm: train_loss 0.4606
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1076, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.1345
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1077, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1078, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.4424
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1079, num samples collected 5250, FPS 226
  Algorithm: train_loss 1.1690
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1080, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0203
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1081, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1082, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1083, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1084, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1085, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.5514
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1086, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1087, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.1024
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1088, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1089, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.7552
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1090, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1091, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.2629
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1092, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1093, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1094, num samples collected 5250, FPS 226
  Algorithm: train_loss 0.5355
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1095, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.1674
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1096, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1097, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1098, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1099, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1100, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.7889
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1101, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.3102
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1102, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0355
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1103, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.6165
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1104, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.3908
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1105, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.4314
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1106, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1107, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1108, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1109, num samples collected 5250, FPS 225
  Algorithm: train_loss 1.1497
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1110, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.5138
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1111, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1112, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1113, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1114, num samples collected 5250, FPS 225
  Algorithm: train_loss 0.5734
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1115, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1116, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.5357
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1117, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1118, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1119, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.7000
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1120, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.0944
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1121, num samples collected 5250, FPS 224
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1122, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.9109
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1123, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1124, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.4361
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1125, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1126, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1127, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1128, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.3363
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1129, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.1241
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1130, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1131, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.6427
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1132, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0369
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1133, num samples collected 5250, FPS 223
  Algorithm: train_loss 1.0531
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1134, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1135, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1136, num samples collected 5250, FPS 223
  Algorithm: train_loss 0.3865
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1137, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1138, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.3049
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1139, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1140, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1141, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.9047
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1142, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1143, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.1536
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1144, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1145, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1146, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1147, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1148, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.1385
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1149, num samples collected 5250, FPS 222
  Algorithm: train_loss 1.3315
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1150, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1151, num samples collected 5250, FPS 222
  Algorithm: train_loss 1.2456
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1152, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1153, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0934
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1154, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1155, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.8635
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1156, num samples collected 5250, FPS 222
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1157, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1158, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.5074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1159, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.6810
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1160, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.4359
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1161, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.4743
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1162, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1163, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.4338
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1164, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1165, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.1709
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1166, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.5325
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1167, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.7224
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1168, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.4600
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1169, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0455
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1170, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0547
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1171, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.3910
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1172, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1173, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.8149
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1174, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1175, num samples collected 5250, FPS 221
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1176, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1177, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.1281
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1178, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.1231
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1179, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.3888
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1180, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.6677
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1181, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1182, num samples collected 5250, FPS 220
  Algorithm: train_loss 1.4714
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1183, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.3879
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1184, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1185, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.4677
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1186, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1187, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.3413
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1188, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.7709
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1189, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1190, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1191, num samples collected 5250, FPS 220
  Algorithm: train_loss 0.2607
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1192, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1193, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1194, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1195, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1196, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0368
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1197, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1198, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.2923
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1199, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1200, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1201, num samples collected 5250, FPS 219
  Algorithm: train_loss 0.4304
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1202, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.5611
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1203, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.4350
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1204, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0362
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1205, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.5141
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1206, num samples collected 5250, FPS 218
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1207, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.3973
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1208, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1209, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.3386
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1210, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.6587
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1211, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1212, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.4791
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1213, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.4408
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1214, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1215, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1216, num samples collected 5250, FPS 217
  Algorithm: train_loss 0.6255
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1217, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1218, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.7755
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1219, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1220, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1696
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1221, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.5235
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1222, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.4544
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1223, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1729
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1224, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0853
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1225, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1226, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1227, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1228, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.9275
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1229, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1230, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1231, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1232, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1246
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1233, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.5381
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1234, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.3052
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1235, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1236, num samples collected 5250, FPS 216
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1237, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1238, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.7885
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1239, num samples collected 5250, FPS 215
  Algorithm: train_loss 1.0104
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1240, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1241, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0407
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1242, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.6952
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1243, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.5515
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1244, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1245, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1246, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.5680
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1247, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1248, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1249, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.4416
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1250, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.7441
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1251, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1252, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.8137
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1253, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.5094
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1254, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1360
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1255, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1256, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1257, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1258, num samples collected 5250, FPS 215
  Algorithm: train_loss 0.5663
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1259, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1260, num samples collected 5250, FPS 214
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1589.1129, l 200.0000, t 102.3020, TestReward -1589.9528
Update 1261, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1262, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4459
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1263, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1789
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1264, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4793
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1265, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1266, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1267, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.6419
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1268, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.8930
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1269, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.3434
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1270, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1271, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1272, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1273, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1274, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1275, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.3418
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1276, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.5275
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1277, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.3146
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1278, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.5036
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1279, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1280, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.5139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1281, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4437
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1282, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1283, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0269
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1284, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1285, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.5102
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1286, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1287, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1528
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1288, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.8195
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1289, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4602
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1290, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.8974
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1291, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1292, num samples collected 5500, FPS 132
  Algorithm: train_loss 1.1223
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1293, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1294, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1295, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1296, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1297, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0461
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1298, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4483
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1299, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1300, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.4058
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1301, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1302, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1303, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.6582
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1304, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1305, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1306, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1307, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.0526
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1308, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.2042
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1309, num samples collected 5500, FPS 132
  Algorithm: train_loss 0.6191
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1310, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1311, num samples collected 5500, FPS 131
  Algorithm: train_loss 1.2448
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1312, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1313, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.5532
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1314, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1315, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0976
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1316, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1317, num samples collected 5500, FPS 131
  Algorithm: train_loss 1.7404
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1318, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.2300
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1319, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1320, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1321, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1322, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1323, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.3139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1324, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1325, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1326, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1327, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1328, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1329, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.3276
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1330, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.8161
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1331, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4492
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1332, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1333, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1334, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1335, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.6687
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1336, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1337, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4464
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1338, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4487
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1339, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.6335
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1340, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.5176
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1341, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1342, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.8139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1343, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0480
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1344, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1345, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1346, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1347, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1348, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1349, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1350, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1351, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0414
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1352, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.4527
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1353, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1354, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1355, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1356, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.8014
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1357, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1358, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1359, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.9150
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1360, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1361, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.3333
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1362, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.3991
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1363, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1364, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.5306
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1365, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.5198
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1366, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1367, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1368, num samples collected 5500, FPS 131
  Algorithm: train_loss 0.5677
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1369, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4405
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1370, num samples collected 5500, FPS 130
  Algorithm: train_loss 1.0653
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1371, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.6074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1372, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1373, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1374, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1343
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1375, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1376, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1377, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.8057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1378, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1379, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0478
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1380, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1381, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.8375
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1382, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.3999
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1383, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1384, num samples collected 5500, FPS 130
  Algorithm: train_loss 1.3047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1385, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1386, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.3145
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1387, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4594
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1388, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1389, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1766
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1390, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1418
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1391, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1392, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1393, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1394, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1395, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1396, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1458
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1397, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1398, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.2970
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1399, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.6325
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1400, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0481
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1401, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1381
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1402, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1403, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1404, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1405, num samples collected 5500, FPS 130
  Algorithm: train_loss 1.4554
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1406, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1353
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1407, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.8589
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1408, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.5169
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1409, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1669
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1410, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1411, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.5761
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1412, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1413, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4426
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1414, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1415, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4859
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1416, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1343
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1417, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1418, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4870
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1419, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1420, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.6382
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1421, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1422, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.4815
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1423, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.6970
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1424, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0875
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1425, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1426, num samples collected 5500, FPS 130
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1427, num samples collected 5500, FPS 130
  Algorithm: train_loss 1.1598
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1428, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.5659
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1429, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1430, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1431, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1432, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1433, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1025
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1434, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.7160
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1435, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1436, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1437, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1438, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1439, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1440, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1441, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1327
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1442, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0532
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1443, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.6037
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1444, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1445, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.6147
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1446, num samples collected 5500, FPS 129
  Algorithm: train_loss 1.0882
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1447, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1448, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.4443
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1449, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.6459
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1450, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1451, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1010
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1452, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1453, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.9556
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1454, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.2059
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1455, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1456, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0420
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1457, num samples collected 5500, FPS 129
  Algorithm: train_loss 1.0593
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1458, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1459, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.4821
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1460, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1461, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1462, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.5925
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1463, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1464, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1465, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1466, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.2129
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1467, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1468, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.7396
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1469, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.5267
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1470, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1471, num samples collected 5500, FPS 129
  Algorithm: train_loss 1.1319
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1472, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1473, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1474, num samples collected 5500, FPS 129
  Algorithm: train_loss 1.1347
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1475, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1476, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1477, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1478, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.3152
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1479, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1480, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1481, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.9309
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1482, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1483, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0973
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1484, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1485, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.0453
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1486, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.4021
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1487, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.6604
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1488, num samples collected 5500, FPS 129
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1489, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1490, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1491, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1492, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.7544
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1493, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1494, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.9088
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1495, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1496, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1497, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.8288
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1498, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.2694
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1499, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.9451
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1500, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1501, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0870
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1502, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1503, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1504, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1254
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1505, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0471
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1506, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1507, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.5455
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1508, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.4559
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1509, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.2954
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1510, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1025
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1511, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1512, num samples collected 5500, FPS 128
  Algorithm: train_loss 1.0998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1513, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0996
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1514, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.5192
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1515, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1516, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.5167
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1517, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0379
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1518, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1519, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.5076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1520, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1521, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.7878
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1522, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1523, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1524, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.8402
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1525, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.4426
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1526, num samples collected 5500, FPS 128
  Algorithm: train_loss 1.3285
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1527, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1528, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1529, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1025
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1530, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.2884
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1531, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1532, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.4023
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1533, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1534, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.4060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1535, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1536, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.5150
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1537, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1538, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1539, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1540, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1541, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1542, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.3736
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1543, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0361
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1544, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.6353
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1545, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.3421
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1546, num samples collected 5500, FPS 128
  Algorithm: train_loss 1.0867
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1547, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1548, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0453
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1549, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1550, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.4705
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1551, num samples collected 5500, FPS 128
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1552, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1553, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1554, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2995
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1555, num samples collected 5500, FPS 127
  Algorithm: train_loss 1.2010
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1556, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1448
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1557, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1558, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1559, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2890
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1560, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5182
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1561, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1562, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1563, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1564, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4444
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1565, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.8501
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1566, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4029
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1567, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1046
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1568, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1569, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.8645
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1570, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6555
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1571, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1572, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1573, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1390
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1574, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1575, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1576, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1577, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.8118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1578, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4540
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1579, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.7362
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1580, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1581, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1582, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.9340
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1583, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1584, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1515
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1585, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1586, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0455
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1587, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1588, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1589, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4549
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1590, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0895
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1591, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1362
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1592, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0501
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1593, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1594, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1595, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1596, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1597, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.4473
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1598, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.9073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1599, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1462
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1600, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3962
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1601, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1812
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1602, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1603, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3918
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1604, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6192
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1605, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.3977
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1606, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1024
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1607, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1608, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1609, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6808
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1610, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.7792
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1611, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1612, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1613, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1614, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.6283
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1615, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1616, num samples collected 5500, FPS 127
  Algorithm: train_loss 0.1494
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1617, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0556
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1618, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1619, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1620, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0391
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1621, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1622, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1623, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5462
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1624, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2232
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1625, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4599
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1626, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1627, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5728
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1628, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1629, num samples collected 5500, FPS 126
  Algorithm: train_loss 1.0186
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1630, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4021
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1631, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2848
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1632, num samples collected 5500, FPS 126
  Algorithm: train_loss 1.0314
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1633, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1634, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1635, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1636, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0399
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1637, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0246
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1638, num samples collected 5500, FPS 126
  Algorithm: train_loss 1.7658
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1639, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2716
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1640, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4674
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1641, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1642, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.8374
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1643, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2645
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1644, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.6678
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1645, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1772
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1646, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1647, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1648, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1489
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1649, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1650, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1651, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1652, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1653, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1654, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1655, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0772
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1656, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1657, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1658, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2646
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1659, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.4991
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1660, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1661, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1662, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1663, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1664, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1665, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.6664
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1666, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1667, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1668, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1669, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.6387
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1670, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.9376
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1671, num samples collected 5500, FPS 126
  Algorithm: train_loss 1.0302
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1672, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1673, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1674, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.5165
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1675, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.6773
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1676, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1677, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1678, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1679, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.8753
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1680, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1681, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1682, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1683, num samples collected 5500, FPS 126
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1684, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1336
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1685, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2891
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1686, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3995
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1687, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1688, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1689, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1690, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4475
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1691, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4363
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1692, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.7165
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1693, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0449
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1694, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0955
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1695, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4129
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1696, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1697, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6356
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1698, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.8744
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1699, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1700, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1701, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1471
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1702, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.5016
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1703, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1704, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1705, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1706, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0450
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1707, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3991
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1708, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0466
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1709, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2744
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1710, num samples collected 5500, FPS 125
  Algorithm: train_loss 1.2972
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1711, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1712, num samples collected 5500, FPS 125
  Algorithm: train_loss 1.0139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1713, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0553
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1714, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1715, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1716, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1717, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4771
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1718, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6100
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1719, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0704
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1720, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4028
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1721, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1722, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.8252
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1723, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1374
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1724, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1725, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1726, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.2185
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1727, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1728, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1729, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6292
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1730, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3995
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1731, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1732, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1733, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1734, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1735, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6431
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1736, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3924
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1737, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6396
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1738, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1739, num samples collected 5500, FPS 125
  Algorithm: train_loss 1.5447
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1740, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.6253
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1741, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1742, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1743, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4929
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1744, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1745, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.4022
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1746, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1747, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1748, num samples collected 5500, FPS 125
  Algorithm: train_loss 1.3310
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1749, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.0996
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1750, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1751, num samples collected 5500, FPS 125
  Algorithm: train_loss 0.3959
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1752, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1753, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4997
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1754, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1755, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0905
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1756, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1757, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1758, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4055
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1759, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1760, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6942
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1761, num samples collected 5500, FPS 124
  Algorithm: train_loss 1.0294
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1762, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.2969
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1763, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1764, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1765, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1766, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.8278
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1767, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1427
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1768, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.7257
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1769, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1770, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0628
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1771, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1772, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.8958
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1773, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1774, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1775, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3122
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1776, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1777, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6471
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1778, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6331
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1779, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1780, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.5714
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1781, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1782, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1783, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1784, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6818
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1785, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1786, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6236
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1787, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1788, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1789, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1790, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1322
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1791, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6038
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1792, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1793, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1794, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.7308
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1795, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1053
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1796, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1797, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4145
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1798, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4472
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1799, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1800, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.7209
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1801, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1802, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6355
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1803, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1804, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1805, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.8415
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1806, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.8964
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1807, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1808, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1809, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1810, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1811, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.5814
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1812, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.4712
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1813, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.8924
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1814, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1815, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3619
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1816, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1817, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1818, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.6064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1819, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1820, num samples collected 5500, FPS 124
  Algorithm: train_loss 0.3978
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1821, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2260
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1822, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1823, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1310
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1824, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6211
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1825, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1826, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2836
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1827, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1828, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.9553
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1829, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1830, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0470
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1831, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1832, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1001
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1833, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1834, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2888
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1835, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1836, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5407
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1837, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1838, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1839, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1840, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.9286
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1841, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3581
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1842, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1843, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6302
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1844, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5193
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1845, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1796
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1846, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2692
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1847, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1848, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.4860
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1849, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.9002
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1850, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.7002
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1851, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1852, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1853, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1854, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3574
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1855, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3157
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1856, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1857, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1858, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1859, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1860, num samples collected 5500, FPS 123
  Algorithm: train_loss 1.5344
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1861, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1301
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1862, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2674
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1863, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1864, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5962
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1865, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6587
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1866, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1867, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1868, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1869, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0707
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1870, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1871, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5649
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1872, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1873, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1874, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6039
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1875, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.4005
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1876, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.9862
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1877, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1878, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1879, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5186
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1880, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3950
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1881, num samples collected 5500, FPS 123
  Algorithm: train_loss 1.2550
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1882, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.2629
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1883, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1884, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.5305
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1885, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0478
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1886, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1887, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.6880
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1888, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.1303
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1889, num samples collected 5500, FPS 123
  Algorithm: train_loss 0.3932
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1890, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1524
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1891, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1892, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.5138
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1893, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1894, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1895, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4485
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1896, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1897, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1898, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1899, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.6817
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1900, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4416
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1901, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1902, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2213
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1903, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1904, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1905, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1906, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0399
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1907, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1908, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1909, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1910, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1301
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1911, num samples collected 5500, FPS 122
  Algorithm: train_loss 1.1264
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1912, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.6363
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1913, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1914, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1915, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4479
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1916, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1759
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1917, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.9413
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1918, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4446
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1919, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1920, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1921, num samples collected 5500, FPS 122
  Algorithm: train_loss 1.1197
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1922, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2908
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1923, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.2057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1924, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1925, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1926, num samples collected 5500, FPS 122
  Algorithm: train_loss 1.0263
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1927, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1928, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1929, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1930, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1931, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4947
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1932, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1933, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.4765
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1934, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1935, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.7531
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1936, num samples collected 5500, FPS 122
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1937, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1938, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2957
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1939, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6017
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1940, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1941, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1942, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1943, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.8757
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1944, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1945, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1946, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3962
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1947, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1948, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5316
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1949, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4422
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1950, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1951, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1952, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1953, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.8487
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1954, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1955, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1956, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4885
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1957, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3953
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1958, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0481
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1959, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.7381
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1960, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0433
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1961, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0973
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1962, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1963, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1964, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5707
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1965, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1966, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1967, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1968, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1969, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1970, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4940
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1971, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1972, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1343
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1973, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1974, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1975, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1976, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.4969
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1977, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3329
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1978, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1979, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0501
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1980, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.5153
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1981, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1982, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1983, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.6254
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1984, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.8936
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1985, num samples collected 5500, FPS 121
  Algorithm: train_loss 1.5023
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1986, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.3295
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1987, num samples collected 5500, FPS 121
  Algorithm: train_loss 1.0304
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1988, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1989, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1990, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2821
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1991, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1992, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.2438
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1993, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1994, num samples collected 5500, FPS 121
  Algorithm: train_loss 0.7872
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1995, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0536
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1996, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1997, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1998, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 1999, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1024
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2000, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1842
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2001, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4533
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2002, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1748
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2003, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.7964
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2004, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1323
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2005, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0457
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2006, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2007, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.9124
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2008, num samples collected 5500, FPS 120
  Algorithm: train_loss 1.2857
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2009, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2010, num samples collected 5500, FPS 120
  Algorithm: train_loss 1.1002
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2011, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.8245
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2012, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.7713
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2013, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2014, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2015, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0763
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2016, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2017, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2018, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2019, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2020, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2699
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2021, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6382
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2022, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2023, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3892
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2024, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6003
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2025, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4627
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2026, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2027, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2028, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2029, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2030, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2031, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4872
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2032, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2033, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2034, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2035, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2036, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.7056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2037, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2038, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2039, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2040, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2041, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6256
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2042, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2043, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6479
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2044, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5180
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2045, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2046, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2047, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2048, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2049, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2050, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2051, num samples collected 5500, FPS 120
  Algorithm: train_loss 1.3166
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2052, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5202
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2053, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6187
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2054, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.6779
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2055, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2056, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2057, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4478
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2058, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.3455
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2059, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2060, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5175
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2061, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.4224
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2062, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.2446
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2063, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2064, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2065, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2066, num samples collected 5500, FPS 120
  Algorithm: train_loss 0.5576
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2067, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.9539
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2068, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2069, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1356
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2070, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4337
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2071, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4079
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2072, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0471
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2073, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2074, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2075, num samples collected 5500, FPS 119
  Algorithm: train_loss 1.4094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2076, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6521
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2077, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2078, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2079, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.3696
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2080, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2081, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4860
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2082, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4943
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2083, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2084, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1639
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2085, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2086, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2087, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2088, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2089, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0264
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2090, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.9998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2091, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2092, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2185
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2093, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2094, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2095, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2096, num samples collected 5500, FPS 119
  Algorithm: train_loss 1.0442
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2097, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2098, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1011
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2099, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5245
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2100, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1454
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2101, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2102, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.7603
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2103, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2104, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4926
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2105, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2106, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5568
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2107, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5043
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2108, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5529
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2109, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2761
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2110, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0715
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2111, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4468
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2112, num samples collected 5500, FPS 119
  Algorithm: train_loss 1.0920
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2113, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2114, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2115, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2116, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1352
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2117, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1824
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2118, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2119, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2120, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2121, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2122, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2123, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.5240
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2124, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6831
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2125, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2126, num samples collected 5500, FPS 119
  Algorithm: train_loss 1.1635
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2127, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.4489
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2128, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2129, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6359
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2130, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.6810
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2131, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2132, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2133, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2134, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2135, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.1443
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2136, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.2076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2137, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.7332
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2138, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2139, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.0547
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2140, num samples collected 5500, FPS 119
  Algorithm: train_loss 0.9834
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2141, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2142, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2143, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2144, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0396
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2145, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.6331
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2146, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2147, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.8792
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2148, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.9630
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2149, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.6345
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2150, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2151, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2152, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2153, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2154, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1511
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2155, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2156, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2157, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4509
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2158, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2159, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4742
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2160, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2578
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2161, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5866
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2162, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2163, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2164, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4506
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2165, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2166, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5028
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2167, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4028
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2168, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2169, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1633
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2170, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0379
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2171, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5465
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2172, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1841
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2173, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.9013
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2174, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2175, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2176, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2177, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5013
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2178, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2179, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4348
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2180, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3382
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2181, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2182, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3397
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2183, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.7866
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2184, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2185, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.8413
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2186, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.8382
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2187, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.7675
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2188, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1075
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2189, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5408
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2190, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0302
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2191, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0606
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2192, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0568
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2193, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.4522
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2194, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2195, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0525
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2196, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3979
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2197, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2198, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2199, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2200, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2201, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2202, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2203, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.3073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2204, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.9775
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2205, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2206, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2207, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.5259
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2208, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2209, num samples collected 5500, FPS 118
  Algorithm: train_loss 1.1876
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2210, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2211, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2212, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.1845
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2213, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2374
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2214, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.2082
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2215, num samples collected 5500, FPS 118
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2216, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5834
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2217, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4535
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2218, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5719
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2219, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2220, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2221, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4522
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2222, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2223, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2224, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2604
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2225, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0836
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2226, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2227, num samples collected 5500, FPS 117
  Algorithm: train_loss 1.1407
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2228, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2229, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2273
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2230, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2231, num samples collected 5500, FPS 117
  Algorithm: train_loss 1.1942
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2232, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2233, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5213
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2234, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2235, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2236, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4476
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2237, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2238, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1450
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2239, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2240, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2241, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2242, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4715
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2243, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0586
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2244, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.6333
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2245, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2246, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4875
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2247, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.9871
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2248, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2249, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4708
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2250, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3510
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2251, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3909
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2252, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2253, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.6607
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2254, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5693
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2255, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2256, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.6188
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2257, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2258, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1672
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2259, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2260, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0543
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2261, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.8150
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2262, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2263, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2264, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2265, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2266, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2267, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.7246
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2268, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2269, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.9178
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2270, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2271, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0372
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2272, num samples collected 5500, FPS 117
  Algorithm: train_loss 1.0398
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2273, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.2406
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2274, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2275, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2276, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.5011
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2277, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.7844
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2278, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.3073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2279, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4032
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2280, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.0379
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2281, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2282, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.6539
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2283, num samples collected 5500, FPS 117
  Algorithm: train_loss 0.4901
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2284, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2285, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2286, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6887
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2287, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5218
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2288, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2289, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2290, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2291, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4661
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2292, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4589
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2293, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2294, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2295, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1323
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2296, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5369
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2297, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0986
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2298, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2299, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2300, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2301, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2302, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2303, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4636
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2304, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2305, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2306, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3116
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2307, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5733
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2308, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.7977
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2309, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6370
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2310, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2311, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5033
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2312, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0509
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2313, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4492
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2314, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1438
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2315, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3936
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2316, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3375
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2317, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2318, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2319, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2320, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5024
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2321, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6658
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2322, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2323, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.9307
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2324, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1306
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2325, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2326, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3447
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2327, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2328, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2329, num samples collected 5500, FPS 116
  Algorithm: train_loss 1.0313
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2330, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2331, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2332, num samples collected 5500, FPS 116
  Algorithm: train_loss 1.0269
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2333, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3971
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2334, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2335, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2336, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2337, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2338, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2339, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2340, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5507
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2341, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4457
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2342, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2343, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2344, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2345, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2346, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4649
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2347, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2890
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2348, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2349, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2350, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2351, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.6610
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2352, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.4167
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2353, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2354, num samples collected 5500, FPS 116
  Algorithm: train_loss 1.1326
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2355, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.5986
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2356, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2357, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.2707
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2358, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1035
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2359, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2360, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2361, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2362, num samples collected 5500, FPS 116
  Algorithm: train_loss 0.1681
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2363, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2364, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2365, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2366, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2367, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2199
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2368, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4491
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2369, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2370, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0798
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2371, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5037
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2372, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7007
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2373, num samples collected 5500, FPS 115
  Algorithm: train_loss 1.0604
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2374, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2375, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2376, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4869
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2377, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0407
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2378, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7896
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2379, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1366
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2380, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.8006
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2381, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4753
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2382, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2383, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5308
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2384, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2385, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2386, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2387, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2226
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2388, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2906
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2389, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.3920
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2390, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7264
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2391, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1684
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2392, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2393, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5958
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2394, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5370
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2395, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.6365
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2396, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2397, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.6255
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2398, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1014
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2399, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2400, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2401, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.9073
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2402, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1463
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2403, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2404, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2405, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2406, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1259
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2407, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5046
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2408, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7266
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2409, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7851
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2410, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.7802
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2411, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1013
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2412, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.6234
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2413, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2414, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2415, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4730
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2416, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2417, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.4000
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2418, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0979
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2419, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.5007
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2420, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2421, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2422, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2423, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2424, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2425, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2426, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2427, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2428, num samples collected 5500, FPS 115
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2429, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2430, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1004
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2431, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4550
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2432, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.8895
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2433, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2434, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2435, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2436, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2437, num samples collected 5500, FPS 114
  Algorithm: train_loss 1.1027
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2438, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2439, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1295
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2440, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2441, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.7598
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2442, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2443, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2444, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2445, num samples collected 5500, FPS 114
  Algorithm: train_loss 1.2080
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2446, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2447, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5871
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2448, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2449, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2450, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5656
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2451, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2452, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5569
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2453, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2454, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2455, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2488
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2456, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2457, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.8879
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2458, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2459, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2687
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2460, num samples collected 5500, FPS 114
  Algorithm: train_loss 1.3601
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2461, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3971
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2462, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1771
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2463, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2464, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2465, num samples collected 5500, FPS 114
  Algorithm: train_loss 1.0615
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2466, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0535
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2467, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2468, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0450
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2469, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2470, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2471, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2472, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.7951
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2473, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2474, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6204
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2475, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5807
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2476, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5111
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2477, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2478, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4919
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2479, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2480, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.2330
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2481, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.7060
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2482, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2483, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.4490
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2484, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3285
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2485, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2486, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2487, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1054
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2488, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2489, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.5212
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2490, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.1987
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2491, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2492, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3609
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2493, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2494, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6077
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2495, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3967
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2496, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2497, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.3071
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2498, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2499, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2500, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.6596
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2501, num samples collected 5500, FPS 114
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2502, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.7013
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2503, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.5782
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2504, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2505, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4464
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2506, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4723
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2507, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.6219
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2508, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1610
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2509, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3985
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2510, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2511, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2512, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2513, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2514, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4566
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2515, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.9029
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2516, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.9510
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2517, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0464
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2518, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2519, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4485
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2520, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2521, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2522, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3980
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2523, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0375
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2524, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.5901
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2525, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2526, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2527, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2528, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2529, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2530, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.6272
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2531, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4962
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2532, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2533, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.6802
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2534, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2535, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1031
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2536, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2537, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2538, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3979
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2539, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1397
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2540, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4317
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2541, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2542, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4500
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2543, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1436
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2544, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2545, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4742
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2546, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2547, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4995
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2548, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4026
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2549, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2550, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2551, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.7860
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2552, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0568
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2553, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2554, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.4505
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2555, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2556, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.5398
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2557, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.3184
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2558, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2559, num samples collected 5500, FPS 113
  Algorithm: train_loss 1.0142
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2560, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2561, num samples collected 5500, FPS 113
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2562, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2563, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.2385
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2564, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.7865
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2565, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2566, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.6047
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2567, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4855
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2568, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2569, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2570, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2571, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2572, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2573, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0394
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2574, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4519
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2575, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.6922
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2576, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2577, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2578, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2579, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2580, num samples collected 5500, FPS 112
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1337.8717, l 200.0000, t 125.7893, TestReward -1554.0094
Update 2581, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2582, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.7040
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2583, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2584, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2585, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2586, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4948
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2587, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2588, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.3536
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2589, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4039
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2590, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2591, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2592, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.5058
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2593, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0681
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2594, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.9356
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2595, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4280
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2596, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4118
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2597, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2598, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.7308
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2599, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.3308
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2600, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2601, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2098
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2602, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2603, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2604, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2605, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.6163
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2606, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2607, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.9418
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2608, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2609, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2610, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2611, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.6390
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2612, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1507
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2613, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2614, num samples collected 5750, FPS 87
  Algorithm: train_loss 1.0385
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2615, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2616, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.8463
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2617, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2237
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2618, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2619, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2355
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2620, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2621, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2622, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2623, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2624, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.6345
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2625, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2626, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2627, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.7022
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2628, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2629, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1756
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2630, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.6421
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2631, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2632, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.7478
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2633, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.5084
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2634, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2635, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2636, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2637, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4722
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2638, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4028
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2639, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2197
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2640, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2091
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2641, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.5116
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2642, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.1043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2643, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.4636
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2644, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2645, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2646, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.5380
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2647, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2648, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.2957
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2649, num samples collected 5750, FPS 87
  Algorithm: train_loss 0.0815
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2650, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2651, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2652, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2653, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2654, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2655, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0401
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2656, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4531
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2657, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3995
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2658, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2659, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2660, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5329
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2661, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.7495
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2662, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.7909
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2663, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2664, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2665, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2666, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4438
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2667, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4582
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2668, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2669, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.8464
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2670, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2671, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4534
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2672, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2673, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.8395
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2674, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2675, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2676, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2677, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5032
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2678, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5089
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2679, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2680, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1356
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2681, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2682, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2349
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2683, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2684, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2685, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2686, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6435
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2687, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.8231
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2688, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.7108
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2689, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2690, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2691, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.7413
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2692, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2693, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4642
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2694, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2695, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2214
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2696, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2697, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3026
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2698, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2699, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2700, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5254
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2701, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2702, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2703, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2704, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5026
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2705, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1339
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2706, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1512
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2707, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5656
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2708, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2709, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2710, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2711, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2712, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2713, num samples collected 5750, FPS 86
  Algorithm: train_loss 1.1787
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2714, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5558
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2715, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3420
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2716, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2717, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4910
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2718, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2719, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2720, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2721, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5122
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2722, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3398
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2723, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2724, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2666
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2725, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2726, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2727, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2728, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5933
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2729, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0547
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2730, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6304
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2731, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2732, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2733, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2489
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2734, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4103
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2735, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.8555
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2736, num samples collected 5750, FPS 86
  Algorithm: train_loss 1.0824
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2737, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2128
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2738, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.8060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2739, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2740, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2741, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2742, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2743, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2744, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2745, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2746, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2747, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2748, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5061
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2749, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5768
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2750, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2455
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2751, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6561
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2752, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0542
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2753, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2754, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4080
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2755, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2756, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2757, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2758, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6227
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2759, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3849
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2760, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2761, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6596
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2762, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5853
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2763, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2764, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.9783
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2765, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2766, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5866
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2767, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2768, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2769, num samples collected 5750, FPS 86
  Algorithm: train_loss 1.1680
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2770, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2771, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2772, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5833
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2773, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.4574
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2774, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.3961
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2775, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2776, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.7129
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2777, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2942
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2778, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2779, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1531
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2780, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2781, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2782, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2108
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2783, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.6950
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2784, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2785, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0378
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2786, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2787, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2788, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1516
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2789, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2790, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2791, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2792, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.5049
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2793, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0547
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2794, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2795, num samples collected 5750, FPS 86
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2796, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2797, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4038
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2798, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2799, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4850
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2800, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6276
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2801, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2802, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1811
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2803, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2804, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4026
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2805, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.3041
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2806, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.7775
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2807, num samples collected 5750, FPS 85
  Algorithm: train_loss 1.1957
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2808, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2809, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6395
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2810, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2811, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2812, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2813, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2814, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0491
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2815, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.8859
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2816, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4997
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2817, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2818, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.7243
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2819, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1366
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2820, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4582
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2821, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1366
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2822, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2823, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2824, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2825, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4580
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2826, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2827, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.8952
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2828, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2829, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2830, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2831, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5044
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2832, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.3312
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2833, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2834, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2578
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2835, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.3414
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2836, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2837, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2838, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2839, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0618
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2840, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1509
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2841, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2842, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2843, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6624
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2844, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0408
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2845, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6518
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2846, num samples collected 5750, FPS 85
  Algorithm: train_loss 1.0506
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2847, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4580
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2848, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2849, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2850, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2851, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2852, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4014
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2853, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2854, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.9469
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2855, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2856, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2857, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2858, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2859, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2860, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2861, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5018
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2862, num samples collected 5750, FPS 85
  Algorithm: train_loss 1.2074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2863, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0552
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2864, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2865, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1603
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2866, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2867, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2868, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6664
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2869, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2870, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2789
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2871, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.3698
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2872, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6693
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2873, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2874, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2875, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5361
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2876, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2877, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2878, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2879, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2880, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.7051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2881, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6005
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2882, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2883, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4535
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2884, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2885, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5449
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2886, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2887, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2888, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2889, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2890, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4973
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2891, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5099
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2892, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2205
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2893, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2894, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2895, num samples collected 5750, FPS 85
  Algorithm: train_loss 1.1001
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2896, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2897, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.8008
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2898, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0538
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2899, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2900, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1525
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2901, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2902, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2903, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2904, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2905, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4377
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2906, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4533
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2907, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1371
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2908, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2731
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2909, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6315
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2910, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2911, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.7348
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2912, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2913, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2195
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2914, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2306
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2915, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5212
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2916, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2917, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4636
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2918, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1728
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2919, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.8685
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2920, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2921, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2922, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2923, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.2278
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2924, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2925, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2926, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4499
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2927, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0520
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2928, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6018
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2929, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2930, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.9004
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2931, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0853
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2932, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2933, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.4536
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2934, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2935, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.3990
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2936, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2937, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2938, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2939, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.7736
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2940, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2941, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2942, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.1771
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2943, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.6456
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2944, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2945, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2946, num samples collected 5750, FPS 85
  Algorithm: train_loss 0.5209
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2947, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1809
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2948, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2949, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5942
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2950, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2951, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4422
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2952, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2953, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2954, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.9470
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2955, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2956, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0396
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2957, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2958, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1793
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2959, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.7854
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2960, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5345
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2961, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2962, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2963, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2964, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2965, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5371
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2966, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1308
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2967, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2968, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6853
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2969, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4712
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2970, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0284
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2971, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3628
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2972, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2973, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2974, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2975, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2976, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5002
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2977, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2614
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2978, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2979, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.9121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2980, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2981, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2982, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5894
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2983, num samples collected 5750, FPS 84
  Algorithm: train_loss 1.4536
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2984, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2985, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2811
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2986, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4944
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2987, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3405
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2988, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1778
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2989, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2990, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4586
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2991, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2992, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2993, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2305
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2994, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2995, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6419
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2996, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2997, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2998, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 2999, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4599
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3000, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5659
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3001, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3002, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3003, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.9625
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3004, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2162
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3005, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3006, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5091
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3007, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3008, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3009, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3010, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.8874
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3011, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3012, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5396
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3013, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0480
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3014, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5264
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3015, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3016, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3017, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3018, num samples collected 5750, FPS 84
  Algorithm: train_loss 1.3403
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3019, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6343
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3020, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3021, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3022, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3023, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3024, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6373
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3025, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2520
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3026, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3027, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4642
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3028, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3029, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3030, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0951
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3031, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3032, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3033, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3034, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3035, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3036, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2563
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3037, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.8094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3038, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4963
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3039, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3040, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3611
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3041, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0780
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3042, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3043, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3044, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2667
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3045, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3046, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1333
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3047, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.7765
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3048, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3049, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2711
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3050, num samples collected 5750, FPS 84
  Algorithm: train_loss 1.0317
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3051, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1162
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3052, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4586
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3053, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4523
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3054, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3055, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5186
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3056, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.9341
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3057, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3058, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3059, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1851
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3060, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3061, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3062, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3063, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3064, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1972
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3065, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3066, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1038
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3067, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3068, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3069, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4547
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3070, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3071, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3072, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3073, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3074, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3075, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3076, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5331
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3077, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5403
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3078, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3079, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3080, num samples collected 5750, FPS 84
  Algorithm: train_loss 1.4100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3081, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6231
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3082, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4664
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3083, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3084, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1550
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3085, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3086, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3907
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3087, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4498
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3088, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0596
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3089, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3090, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.4868
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3091, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6329
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3092, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3093, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.3214
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3094, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3095, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.6604
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3096, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.5089
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3097, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3098, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.2297
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3099, num samples collected 5750, FPS 84
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3100, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2029
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3101, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3102, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4696
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3103, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3104, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5886
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3105, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3106, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3107, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3108, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3109, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3110, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0496
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3111, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3112, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2095
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3113, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4514
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3114, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3115, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3116, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0227
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3117, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3118, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.8922
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3119, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3120, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1553
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3121, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4894
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3122, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3502
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3123, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3983
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3124, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3125, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3126, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3127, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4730
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3128, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6362
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3129, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3130, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3131, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3132, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.4648
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3133, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1326
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3134, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0775
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3135, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6163
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3136, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.1507
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3137, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3138, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3139, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3140, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3141, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3011
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3142, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3143, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3144, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2721
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3145, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3146, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3147, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.1059
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3148, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3149, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3150, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3326
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3151, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4102
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3152, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3153, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2469
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3154, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5460
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3155, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0954
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3156, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3157, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3158, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.8083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3159, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3160, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3161, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5019
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3162, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3163, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3164, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3165, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6360
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3166, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3167, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6321
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3168, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6725
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3169, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3170, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3171, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1718
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3172, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3173, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7001
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3174, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0988
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3175, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3176, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5038
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3177, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3178, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3179, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0987
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3180, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3181, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3182, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3183, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3184, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3185, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3186, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1819
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3187, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3188, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3189, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3190, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5511
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3191, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.9225
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3192, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6435
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3193, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6201
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3194, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3195, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3196, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3197, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5239
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3198, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7517
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3199, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3200, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4564
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3201, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.0923
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3202, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3203, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6902
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3204, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3205, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5875
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3206, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4533
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3207, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3208, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3209, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5014
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3210, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4866
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3211, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3212, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3213, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.0115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3214, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3215, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3216, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.7319
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3217, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.3537
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3218, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3219, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3220, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3221, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6398
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3222, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3223, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0448
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3224, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3225, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3226, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3227, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3228, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2934
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3229, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.2610
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3230, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4423
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3231, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4492
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3232, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3233, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4789
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3234, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5811
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3235, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3236, num samples collected 5750, FPS 83
  Algorithm: train_loss 1.5180
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3237, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3238, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1617
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3239, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4952
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3240, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6828
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3241, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3242, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.5641
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3243, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3244, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3245, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0517
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3246, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3247, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3248, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.4546
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3249, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3250, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3251, num samples collected 5750, FPS 83
  Algorithm: train_loss 0.6161
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3252, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3253, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0466
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3254, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3255, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6061
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3256, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3257, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3258, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3259, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3260, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4101
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3261, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3262, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5099
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3263, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.8549
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3264, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4011
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3265, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3266, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3267, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0854
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3268, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2168
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3269, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6734
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3270, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3271, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4048
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3272, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4511
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3273, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3274, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3275, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2305
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3276, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3277, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3960
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3278, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3279, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3280, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0382
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3281, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5001
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3282, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3283, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6426
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3284, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3285, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1341
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3286, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.9241
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3287, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3288, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5658
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3289, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3290, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4955
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3291, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3292, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3293, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3294, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3295, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3224
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3296, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3297, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0670
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3298, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3299, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1677
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3300, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3301, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4009
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3302, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5678
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3303, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1426
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3304, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3305, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3306, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3307, num samples collected 5750, FPS 82
  Algorithm: train_loss 1.0287
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3308, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3309, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6296
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3310, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1013
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3311, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3312, num samples collected 5750, FPS 82
  Algorithm: train_loss 1.2452
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3313, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3314, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3315, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3316, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3317, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4724
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3318, num samples collected 5750, FPS 82
  Algorithm: train_loss 1.0296
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3319, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4167
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3320, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3321, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3322, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7467
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3323, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.9411
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3324, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3325, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1033
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3326, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3327, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3328, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3329, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3330, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3331, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3332, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3333, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3334, num samples collected 5750, FPS 82
  Algorithm: train_loss 1.0346
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3335, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0752
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3336, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0961
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3337, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3338, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3339, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3629
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3340, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3341, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3342, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.9000
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3343, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3344, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7645
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3345, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3346, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3013
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3347, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3348, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3349, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4112
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3350, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.9435
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3351, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3352, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3353, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3354, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4614
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3355, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.3977
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3356, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2324
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3357, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0502
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3358, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3359, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3360, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6828
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3361, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6119
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3362, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3363, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3364, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3365, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1075
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3366, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1264
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3367, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7512
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3368, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0971
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3369, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3370, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5052
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3371, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3372, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4609
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3373, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.8919
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3374, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1494
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3375, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3376, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3377, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2637
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3378, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3379, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0234
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3380, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3381, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3382, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3383, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5688
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3384, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7912
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3385, num samples collected 5750, FPS 82
  Algorithm: train_loss 1.1903
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3386, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3387, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.6255
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3388, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4651
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3389, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5922
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3390, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3391, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3392, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.4008
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3393, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.7752
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3394, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.2260
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3395, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3396, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3397, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5428
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3398, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.9445
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3399, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3400, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3401, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.5834
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3402, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3403, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3404, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3405, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3406, num samples collected 5750, FPS 82
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3407, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0794
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3408, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3409, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1307
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3410, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3411, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3412, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6482
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3413, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4516
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3414, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3415, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1360
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3416, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3417, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3418, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3419, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1801
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3420, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0864
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3421, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5615
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3422, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6104
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3423, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3424, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7036
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3425, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3426, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3991
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3427, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2357
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3428, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6231
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3429, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3430, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.8573
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3431, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0293
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3432, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3433, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3985
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3434, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3435, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3436, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4570
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3437, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3438, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6349
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3439, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3440, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5004
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3441, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4915
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3442, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2812
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3443, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5404
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3444, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0404
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3445, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4986
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3446, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6932
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3447, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3448, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3302
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3449, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3450, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1490
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3451, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3452, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1299
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3453, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3454, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0760
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3455, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3456, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3457, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3458, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3382
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3459, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3460, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3461, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4646
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3462, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6552
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3463, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0396
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3464, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3465, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5751
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3466, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.7706
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3467, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5496
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3468, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4891
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3469, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0904
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3470, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3957
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3471, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2867
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3472, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5030
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3473, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3950
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3474, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3475, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3476, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0266
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3477, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3478, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3479, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3480, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6679
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3481, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3482, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4975
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3483, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3484, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1911
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3485, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3486, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2863
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3487, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3488, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3489, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3490, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3491, num samples collected 5750, FPS 81
  Algorithm: train_loss 1.1473
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3492, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4578
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3493, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1020
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3494, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4563
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3495, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6479
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3496, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.9517
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3497, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3498, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0427
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3499, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3500, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3501, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3502, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1212
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3503, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3504, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3505, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.6393
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3506, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0525
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3507, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3508, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3509, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1515
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3510, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3511, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1323
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3512, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1035
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3513, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3514, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3515, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3516, num samples collected 5750, FPS 81
  Algorithm: train_loss 1.4832
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3517, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4492
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3518, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1672
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3519, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.5052
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3520, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3521, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3522, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.9642
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3523, num samples collected 5750, FPS 81
  Algorithm: train_loss 1.4067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3524, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3525, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.8303
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3526, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1559
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3527, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.2753
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3528, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4967
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3529, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3530, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3531, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0414
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3532, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3533, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.3966
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3534, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.8423
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3535, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3536, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1133
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3537, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1330
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3538, num samples collected 5750, FPS 81
  Algorithm: train_loss 1.2766
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3539, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3540, num samples collected 5750, FPS 81
  Algorithm: train_loss 0.4650
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3541, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4668
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3542, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0586
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3543, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3544, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3545, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3546, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3547, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3548, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.9973
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3549, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3550, num samples collected 5750, FPS 80
  Algorithm: train_loss 1.0923
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3551, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0384
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3552, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3553, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3554, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3555, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7152
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3556, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5466
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3557, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1606
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3558, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3559, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5022
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3560, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3294
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3561, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3562, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3563, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3564, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4583
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3565, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4008
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3566, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3567, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3568, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3569, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2842
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3570, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3571, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3572, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3573, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3574, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3575, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3576, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7905
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3577, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2797
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3578, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1812
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3579, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6957
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3580, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4703
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3581, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3380
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3582, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2095
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3583, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.9866
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3584, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3585, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3586, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6436
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3587, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6601
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3588, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3589, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4166
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3590, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2828
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3591, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3592, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3593, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3594, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3595, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3596, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5584
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3597, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2275
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3598, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4905
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3599, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5518
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3600, num samples collected 5750, FPS 80
  Algorithm: train_loss 1.5900
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3601, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3602, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3603, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2969
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3604, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3605, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3606, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7855
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3607, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3608, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3609, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3610, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3611, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3612, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3613, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3614, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3615, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3616, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3617, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4021
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3618, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.3945
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3619, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5754
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3620, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7911
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3621, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3622, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3623, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3624, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3625, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6226
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3626, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3627, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3628, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3629, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2819
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3630, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3631, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2630
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3632, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4547
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3633, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3634, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0403
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3635, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5003
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3636, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7959
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3637, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6439
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3638, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3639, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6695
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3640, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1330
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3641, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3642, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3643, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7747
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3644, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3645, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3646, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1840
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3647, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3648, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4494
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3649, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3650, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3651, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3652, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.6249
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3653, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3654, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3655, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3656, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4014
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3657, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1260
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3658, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3659, num samples collected 5750, FPS 80
  Algorithm: train_loss 1.2163
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3660, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.9043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3661, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3662, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.5005
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3663, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3664, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.7615
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3665, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3666, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1538
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3667, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3668, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.1500
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3669, num samples collected 5750, FPS 80
  Algorithm: train_loss 1.6240
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3670, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3671, num samples collected 5750, FPS 80
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3672, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3673, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3674, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1347
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3675, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3676, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3677, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6337
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3678, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3679, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4588
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3680, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0396
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3681, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3047
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3682, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3683, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2050
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3684, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3685, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1792
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3686, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0987
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3687, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0987
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3688, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3689, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3690, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3691, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3692, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3693, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5042
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3694, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2634
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3695, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3696, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6510
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3697, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3698, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5615
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3699, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3700, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3701, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4555
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3702, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5367
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3703, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3704, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6238
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3705, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3706, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3707, num samples collected 5750, FPS 79
  Algorithm: train_loss 1.3684
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3708, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4488
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3709, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3710, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1869
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3711, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3712, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3713, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3714, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3715, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0266
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3716, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3717, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6502
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3718, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3719, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3720, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2956
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3721, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4616
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3722, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3723, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6876
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3724, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3725, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.7437
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3726, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5414
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3727, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3728, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1522
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3729, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.9560
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3730, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3731, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2813
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3732, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3733, num samples collected 5750, FPS 79
  Algorithm: train_loss 1.0077
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3734, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5559
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3735, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3736, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3737, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3738, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6688
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3739, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1388
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3740, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3741, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6197
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3742, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3743, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4831
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3744, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3745, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3515
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3746, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3990
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3747, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4820
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3748, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3749, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5426
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3750, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3751, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3752, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2122
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3753, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3754, num samples collected 5750, FPS 79
  Algorithm: train_loss 1.1586
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3755, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3756, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1608
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3757, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3758, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3759, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3960
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3760, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4509
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3761, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3762, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4516
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3763, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3764, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0819
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3765, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3766, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3767, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0975
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3768, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.7943
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3769, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5148
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3770, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.5969
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3771, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3772, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4539
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3773, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3774, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3775, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3776, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.2175
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3777, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1358
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3778, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6449
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3779, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1149
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3780, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3781, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3782, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3783, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.8791
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3784, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3785, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.3307
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3786, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3787, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3788, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3789, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.6842
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3790, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3791, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3792, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3793, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3794, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3795, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3796, num samples collected 5750, FPS 79
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3797, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.1082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3798, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9411
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3799, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3800, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0927
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3801, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3802, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3803, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4491
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3804, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3805, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4891
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3806, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2649
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3807, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4486
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3808, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9227
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3809, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3810, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.8828
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3811, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3812, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4077
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3813, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3024
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3814, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.0339
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3815, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3816, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1242
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3817, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0278
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3818, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3819, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3820, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1001
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3821, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1556
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3822, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3823, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5038
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3824, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3825, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3826, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3827, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6026
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3828, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3829, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3830, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.1601
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3831, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3832, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3833, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3834, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3835, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3836, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4570
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3837, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6698
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3838, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3839, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1806
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3840, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0875
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3841, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1410
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3842, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.8981
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3843, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4691
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3844, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2701
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3845, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3846, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1378
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3847, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3848, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5506
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3849, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3850, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4946
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3851, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1242
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3852, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1364
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3853, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3854, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6574
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3855, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7330
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3856, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6241
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3857, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3858, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0408
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3859, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3860, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3861, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.2778
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3862, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3863, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3864, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4591
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3865, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3866, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3867, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3868, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3869, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3870, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.3643
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3871, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3872, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3873, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1502
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3874, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3875, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4573
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3876, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0946
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3877, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2860
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3878, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3879, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4404
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3880, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3881, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3882, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3883, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3884, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0498
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3885, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9020
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3886, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3887, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3888, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1358
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3889, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4510
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3890, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.9529
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3891, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3892, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4620
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3893, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3894, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3895, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5496
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3896, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3897, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6306
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3898, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3899, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.8078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3900, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5871
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3901, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2762
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3902, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7250
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3903, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2387
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3904, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3905, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3906, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3907, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3908, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4494
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3909, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3910, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3911, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4024
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3912, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3913, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4565
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3914, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0939
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3915, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0374
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3916, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3917, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5243
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3918, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3289
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3919, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3920, num samples collected 5750, FPS 78
  Algorithm: train_loss 1.1706
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3921, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3922, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5653
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3923, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3924, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3925, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1385
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3926, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5732
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3927, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3928, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.3975
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3929, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5358
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3930, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3931, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3932, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1414
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3933, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4628
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3934, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3935, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2773
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3936, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4505
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3937, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3938, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1346
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3939, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4074
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3940, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.8518
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3941, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3942, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.6227
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3943, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3944, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3945, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3946, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.2279
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3947, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3948, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3949, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.7496
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3950, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5091
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3951, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3952, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3953, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3954, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4009
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3955, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3956, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3957, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4030
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3958, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.5439
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3959, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.4902
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3960, num samples collected 5750, FPS 78
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1736.6820, l 200.0000, t 149.1249, TestReward -1738.8887
Update 3961, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.4605
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3962, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.4523
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3963, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3964, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.4692
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3965, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3966, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.9953
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3967, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.6869
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3968, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3969, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3970, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3971, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0546
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3972, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3973, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3974, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.2938
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3975, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.7768
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3976, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3977, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3978, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3979, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.6267
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3980, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.6425
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3981, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3982, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3983, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3984, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3985, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3986, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.2008
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3987, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.6762
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3988, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3989, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3990, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1503
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3991, num samples collected 6000, FPS 66
  Algorithm: train_loss 1.1945
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3992, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1738
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3993, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.3810
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3994, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3995, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0553
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3996, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1045
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3997, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.5027
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3998, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 3999, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4000, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.9257
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4001, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4002, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4003, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.5646
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4004, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.4171
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4005, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.6690
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4006, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0489
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4007, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4008, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4009, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4010, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.3187
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4011, num samples collected 6000, FPS 66
  Algorithm: train_loss 0.4398
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4012, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4013, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4014, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6913
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4015, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4016, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4017, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2378
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4018, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4812
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4019, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4020, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4021, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4022, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4023, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.9881
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4024, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4025, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4026, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1870
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4027, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4028, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4133
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4029, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3221
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4030, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8764
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4031, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4032, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0837
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4033, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4034, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4035, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4036, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5729
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4037, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5718
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4038, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0888
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4039, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4962
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4040, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4041, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8729
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4042, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3379
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4043, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4044, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1758
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4045, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4046, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4047, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6581
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4048, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0391
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4049, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4050, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4051, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4052, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4053, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5706
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4054, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0501
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4055, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4056, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.0838
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4057, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4058, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.9644
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4059, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4060, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3276
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4061, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3626
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4062, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6450
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4063, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4064, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4065, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0473
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4066, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4067, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4068, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4069, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4070, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1327
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4071, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1806
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4072, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4073, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4074, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5659
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4075, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.7412
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4076, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4077, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6699
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4078, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4079, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4080, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4081, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0402
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4082, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1304
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4083, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4084, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4085, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2010
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4086, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4087, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4684
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4088, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2811
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4089, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4090, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3128
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4091, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4092, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4093, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.2607
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4094, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4095, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2040
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4096, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4097, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1625
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4098, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4099, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.9679
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4100, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4578
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4101, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4102, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4103, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4104, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4105, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4106, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4107, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0461
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4108, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4990
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4109, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4110, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4646
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4111, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4112, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4113, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4114, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0636
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4115, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4116, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1507
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4117, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4118, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4119, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3298
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4120, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4121, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4122, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4915
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4123, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.0373
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4124, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4403
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4125, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4126, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.1295
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4127, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4128, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4129, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4130, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4131, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0770
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4132, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4133, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2448
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4134, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4135, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4136, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6471
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4137, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4138, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4139, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.9030
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4140, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5198
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4141, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4142, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4143, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4144, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4145, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6740
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4146, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4147, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.2007
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4148, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4149, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4150, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1378
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4151, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4152, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.0625
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4153, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4154, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4155, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4740
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4156, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4157, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4158, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.7143
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4159, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4160, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3126
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4161, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1639
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4162, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4163, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3397
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4164, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.2318
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4165, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4166, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2208
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4167, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4168, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4169, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4170, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4171, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2526
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4172, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4173, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4174, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8724
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4175, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4624
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4176, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4177, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6522
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4178, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4179, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4180, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4181, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4182, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5806
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4183, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4184, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8128
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4185, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4186, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6015
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4187, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1355
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4188, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4189, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4857
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4190, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5947
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4191, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4192, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4193, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4036
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4194, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4195, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4196, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4197, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4198, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2723
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4199, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4200, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1128
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4201, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4202, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4203, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4204, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4205, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5043
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4206, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.7137
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4207, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1694
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4208, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4209, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1034
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4210, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4211, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0476
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4212, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4213, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4214, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4215, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6600
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4216, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.0790
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4217, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6663
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4218, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4219, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4220, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4221, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8145
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4222, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4223, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4500
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4224, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4225, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4226, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2274
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4227, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.1100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4228, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6439
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4229, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5775
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4230, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1367
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4231, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4232, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5645
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4233, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4234, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1779
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4235, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4423
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4236, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4237, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0546
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4238, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0361
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4239, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6222
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4240, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5032
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4241, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4242, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4243, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4244, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4245, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4246, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2859
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4247, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4248, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4249, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1813
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4250, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4251, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.8704
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4252, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4253, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4254, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4255, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.5425
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4256, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4257, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.2597
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4258, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4505
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4259, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1592
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4260, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1969
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4261, num samples collected 6000, FPS 65
  Algorithm: train_loss 1.5183
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4262, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0362
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4263, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4264, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4265, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4266, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.3377
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4267, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.6567
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4268, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4269, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4270, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4271, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4272, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0815
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4273, num samples collected 6000, FPS 65
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4274, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4275, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4276, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4277, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6132
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4278, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4279, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7312
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4280, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4281, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0496
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4282, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.2402
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4283, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4284, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2954
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4285, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4286, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5929
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4287, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4288, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4289, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4290, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4291, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3360
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4292, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5293
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4293, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4294, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4295, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4296, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4297, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2541
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4298, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1812
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4299, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4300, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4301, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4302, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1733
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4303, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0591
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4304, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4305, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4923
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4306, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4307, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4308, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6976
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4309, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4310, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8883
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4311, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4312, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1356
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4313, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4314, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4315, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.9541
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4316, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5497
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4317, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5427
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4318, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3997
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4319, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6349
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4320, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4321, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4322, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.1273
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4323, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4324, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1416
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4325, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4326, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3843
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4327, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4137
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4328, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4329, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1024
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4330, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4331, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0403
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4332, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8737
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4333, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8732
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4334, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4335, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8254
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4336, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4337, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1548
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4338, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4339, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4340, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.0528
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4341, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4342, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4343, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4344, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4345, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4346, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.9189
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4347, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4348, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4349, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4350, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4351, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4352, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6449
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4353, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4354, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2244
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4355, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0398
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4356, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2029
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4357, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6759
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4358, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4359, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4360, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1515
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4361, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.3336
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4362, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4363, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7272
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4364, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4365, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4366, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4676
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4367, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4368, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4369, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4370, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4371, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4372, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0369
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4373, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4374, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3984
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4375, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4933
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4376, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1890
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4377, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4378, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0978
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4379, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4948
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4380, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4381, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6487
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4382, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2019
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4383, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4384, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.0652
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4385, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.9811
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4386, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4387, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4388, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0369
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4389, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4390, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4391, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5811
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4392, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4393, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4394, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7116
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4395, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4396, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3992
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4397, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1128
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4398, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4399, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1841
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4400, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5553
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4401, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.9598
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4402, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4403, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4113
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4404, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4405, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4406, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4010
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4407, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4408, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6447
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4409, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4410, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4411, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4412, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4413, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4414, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6189
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4415, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4416, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4417, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4613
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4418, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4419, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4420, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.0572
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4421, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4422, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4423, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1848
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4424, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0520
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4425, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4426, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4744
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4427, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1303
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4428, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0980
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4429, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0421
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4430, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2038
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4431, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.0029
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4432, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4433, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4383
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4434, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4435, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8901
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4436, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1422
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4437, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4438, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4439, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.9276
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4440, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4441, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4442, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4443, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4444, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.1231
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4445, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4446, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3277
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4447, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4847
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4448, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3319
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4449, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4450, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4451, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4452, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7985
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4453, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4454, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4455, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6013
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4456, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2650
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4457, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6625
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4458, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4459, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4460, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2834
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4461, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0509
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4462, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4463, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4464, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1133
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4465, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4466, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8008
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4467, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0335
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4468, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4469, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0972
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4470, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4957
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4471, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4472, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5657
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4473, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4474, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4122
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4475, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0297
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4476, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4477, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4478, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4479, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4642
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4480, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1492
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4481, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4922
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4482, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4483, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.7806
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4484, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1617
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4485, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4486, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4487, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4488, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4489, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4490, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0637
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4491, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8490
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4492, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4493, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4494, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4401
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4495, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4496, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0988
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4497, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4498, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4008
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4499, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4970
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4500, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1391
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4501, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4502, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4632
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4503, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4504, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5689
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4505, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3321
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4506, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4744
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4507, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0466
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4508, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4975
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4509, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4510, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4511, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4512, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4513, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5472
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4514, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4926
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4515, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0967
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4516, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4517, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5080
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4518, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4699
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4519, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4520, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4521, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4522, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4523, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4524, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.6754
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4525, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4526, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4527, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4528, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4529, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.8964
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4530, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4531, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.5180
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4532, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4118
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4533, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4621
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4534, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3916
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4535, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1945
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4536, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.3360
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4537, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4538, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4539, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1525
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4540, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4541, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4542, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.0521
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4543, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4353
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4544, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4545, num samples collected 6000, FPS 64
  Algorithm: train_loss 1.2098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4546, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.4458
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4547, num samples collected 6000, FPS 64
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4548, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6265
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4549, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1793
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4550, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4538
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4551, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4552, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4553, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3205
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4554, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4555, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4556, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4557, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4558, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5887
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4559, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4560, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4561, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.2744
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4562, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4563, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4564, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8556
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4565, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4566, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0552
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4567, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1373
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4568, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4569, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4570, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4571, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4572, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4573, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4574, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4575, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4576, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.9468
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4577, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3418
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4578, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0710
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4579, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8118
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4580, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4581, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4582, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4583, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5024
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4584, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.9283
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4585, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0903
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4586, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4587, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4588, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4589, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4590, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6411
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4591, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4592, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2818
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4593, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4594, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5942
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4595, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4596, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4597, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1528
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4598, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4599, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4600, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4601, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4600
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4602, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4603, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6622
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4604, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4605, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4606, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5773
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4607, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6060
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4608, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4147
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4609, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6189
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4610, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4611, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4161
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4612, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6445
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4613, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4614, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4615, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2747
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4616, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1197
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4617, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4618, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8335
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4619, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4620, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6009
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4621, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3980
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4622, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4623, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4624, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4625, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4626, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1584
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4627, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4091
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4628, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4629, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2928
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4630, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0832
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4631, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1779
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4632, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.3506
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4633, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4523
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4634, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4635, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4636, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6963
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4637, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5760
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4638, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4639, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4640, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6572
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4641, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2835
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4642, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4136
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4643, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4644, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4645, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1567
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4646, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4647, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5517
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4648, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4676
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4649, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0264
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4650, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7450
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4651, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0387
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4652, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4653, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4654, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6003
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4655, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4656, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4657, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4658, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4659, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1231
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4660, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4661, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8557
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4662, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4033
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4663, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4615
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4664, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0404
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4665, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6682
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4666, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0389
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4667, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0557
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4668, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4669, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8842
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4670, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4671, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4672, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4673, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4674, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4675, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2714
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4676, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4677, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.5505
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4678, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4679, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4680, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5798
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4681, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4682, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4683, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1824
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4684, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4685, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0470
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4686, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8844
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4687, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6950
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4688, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4689, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4690, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4667
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4691, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3165
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4692, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1736
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4693, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1283
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4694, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4695, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.9458
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4696, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0427
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4697, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4698, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4699, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3207
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4700, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4701, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4702, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3168
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4703, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7094
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4704, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.9363
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4705, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4706, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4707, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4708, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4709, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4710, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7324
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4711, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4712, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4713, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0543
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4714, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7414
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4715, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4716, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.3420
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4717, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5306
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4718, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4719, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1684
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4720, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4721, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4722, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2173
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4723, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7403
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4724, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0366
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4725, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4726, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4727, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4707
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4728, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3961
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4729, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4730, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.8111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4731, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4732, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4607
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4733, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2181
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4734, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1350
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4735, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4844
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4736, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7407
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4737, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4738, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4739, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1520
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4740, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4741, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4742, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4743, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4744, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4726
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4745, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.9821
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4746, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4747, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6157
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4748, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4749, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4750, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0593
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4751, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4752, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7165
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4753, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4754, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4755, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4756, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6324
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4757, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0953
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4758, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4759, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.6036
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4760, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4761, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4762, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1766
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4763, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4764, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4765, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4766, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4767, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4768, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4769, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.2828
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4770, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1511
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4771, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4772, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4773, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7022
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4774, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.7833
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4775, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4776, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.8427
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4777, num samples collected 6000, FPS 63
  Algorithm: train_loss 1.1119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4778, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4779, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.0297
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4780, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.5586
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4781, num samples collected 6000, FPS 63
  Algorithm: train_loss 0.3956
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4782, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6265
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4783, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4784, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2867
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4785, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4786, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4787, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4788, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3420
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4789, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4790, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4791, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0981
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4792, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2300
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4793, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1511
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4794, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4764
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4795, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5787
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4796, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4797, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4798, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3579
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4799, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5125
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4800, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4801, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6640
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4802, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4803, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4804, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4870
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4805, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4806, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0411
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4807, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1512
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4808, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5019
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4809, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4810, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5682
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4811, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4812, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4581
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4813, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4814, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4694
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4815, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4816, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4817, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1842
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4818, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4819, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4820, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8226
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4821, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1806
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4822, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3939
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4823, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4824, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4825, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4826, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6331
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4827, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9362
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4828, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4829, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6258
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4830, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4831, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4832, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0723
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4833, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4940
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4834, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4835, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4836, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.0567
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4837, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4838, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4045
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4839, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2461
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4840, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4841, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4842, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4843, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4844, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4845, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4846, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4847, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3512
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4848, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4849, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9527
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4850, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4851, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3141
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4852, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4853, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4854, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4855, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6167
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4856, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.0704
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4857, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4858, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4859, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4860, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4861, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4862, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4863, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0937
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4864, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8915
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4865, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4866, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4867, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6218
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4868, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4869, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6870
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4870, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4871, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2310
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4872, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4873, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4874, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4875, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4876, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8905
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4877, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.7619
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4878, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5337
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4879, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1568
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4880, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5768
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4881, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4882, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4809
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4883, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4451
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4884, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4885, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5092
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4886, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4887, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4888, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4889, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4890, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4891, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4892, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4893, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4894, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4895, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9478
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4896, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4897, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6944
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4898, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4899, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4900, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4901, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1601
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4902, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1817
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4903, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6542
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4904, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4905, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.1411
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4906, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0383
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4907, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4908, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4159
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4909, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4910, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.8245
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4911, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2014
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4912, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1216
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4913, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4721
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4914, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4915, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3542
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4916, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4917, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4918, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5824
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4919, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4920, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4921, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5696
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4922, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4923, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4924, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4294
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4925, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4656
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4926, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4927, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4928, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4929, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4930, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4931, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4932, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4933, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4934, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4935, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4936, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4937, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.1094
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4938, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4939, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4940, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1847
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4941, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.1355
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4942, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6240
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4943, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4944, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4945, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4946, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.0161
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4947, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6316
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4948, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1216
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4949, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6403
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4950, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4951, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4952, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6146
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4953, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1632
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4954, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4955, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1847
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4956, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.3968
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4957, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1238
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4958, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4959, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4960, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4961, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0969
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4962, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.9669
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4963, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.7874
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4964, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0956
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4965, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4966, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4967, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4968, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4969, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6244
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4970, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6258
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4971, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4972, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4973, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4974, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4975, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1274
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4976, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4607
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4977, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5930
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4978, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.7544
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4979, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4980, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4981, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4982, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4983, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1794
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4984, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6382
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4985, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4986, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4987, num samples collected 6000, FPS 62
  Algorithm: train_loss 1.1093
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4988, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0925
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4989, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4990, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4991, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4992, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4152
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4993, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4994, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4995, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4996, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4997, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.5666
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4998, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.4699
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 4999, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1344
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5000, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5001, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5002, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5003, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.6482
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5004, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5005, num samples collected 6000, FPS 62
  Algorithm: train_loss 0.2539
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5006, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5007, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5008, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5009, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2427
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5010, num samples collected 6000, FPS 61
  Algorithm: train_loss 1.8536
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5011, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5012, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4874
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5013, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9205
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5014, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5015, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5016, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5017, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5018, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1166
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5019, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4240
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5020, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5021, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4820
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5022, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5023, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5024, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1270
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5025, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5026, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8445
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5027, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5028, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4587
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5029, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5030, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5031, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5032, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5033, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9285
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5034, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5035, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5036, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1840
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5037, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1377
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5038, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5486
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5039, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3074
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5040, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5041, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5042, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5043, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5044, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5045, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5046, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5047, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5848
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5048, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8904
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5049, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5050, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5051, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4839
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5052, num samples collected 6000, FPS 61
  Algorithm: train_loss 1.1380
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5053, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5054, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.7928
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5055, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0267
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5056, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3342
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5057, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5058, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1358
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5059, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5060, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0533
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5061, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5062, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5063, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5297
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5064, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9130
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5065, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1554
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5066, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.7371
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5067, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5068, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5461
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5069, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5070, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5471
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5071, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5072, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5073, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5074, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3552
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5075, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5076, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5077, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4685
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5078, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5079, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1090
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5080, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5081, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5082, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2294
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5083, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5084, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5085, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9776
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5086, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4849
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5087, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5088, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5089, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5090, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5091, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6231
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5092, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5093, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5094, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5095, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4217
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5096, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4395
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5097, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5098, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5906
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5099, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2023
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5100, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5101, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2874
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5102, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4965
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5103, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3005
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5104, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5105, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4411
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5106, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9211
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5107, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6959
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5108, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1742
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5109, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5110, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0421
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5111, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1780
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5112, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5113, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1796
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5114, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5009
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5115, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8599
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5116, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5369
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5117, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5118, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2810
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5119, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5120, num samples collected 6000, FPS 61
  Algorithm: train_loss 1.2575
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5121, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5122, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2819
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5123, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4045
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5124, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5125, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4703
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5126, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5127, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0418
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5128, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0717
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5129, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5130, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5131, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5132, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5133, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5134, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3004
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5135, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5868
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5136, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1171
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5137, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4521
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5138, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5139, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5140, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5141, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5142, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5143, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5144, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5145, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5146, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1353
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5147, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4573
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5148, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5149, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5150, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.7725
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5151, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6374
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5152, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5153, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5154, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5155, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3326
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5156, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0964
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5157, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9190
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5158, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5159, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6394
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5160, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2203
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5161, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8260
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5162, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5163, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1799
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5164, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8695
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5165, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5166, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5167, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5168, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2385
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5169, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1811
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5170, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2882
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5171, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5439
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5172, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5173, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5174, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4112
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5175, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5176, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0619
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5177, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5178, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6476
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5179, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5180, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5026
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5181, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5182, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5080
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5183, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4051
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5184, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5185, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5186, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4098
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5187, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5188, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.3922
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5189, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5190, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5191, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4036
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5192, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1386
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5193, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0509
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5194, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5195, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.9337
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5196, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2770
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5197, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6367
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5198, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5199, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5200, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5201, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5373
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5202, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6416
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5203, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5204, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4343
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5205, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4656
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5206, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5207, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5208, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0290
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5209, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5210, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6343
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5211, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1759
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5212, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4572
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5213, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5214, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.8730
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5215, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5216, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5217, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0895
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5218, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.5465
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5219, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6037
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5220, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1678
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5221, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5222, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2883
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5223, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5224, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5225, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5226, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4608
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5227, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5228, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5229, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.6599
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5230, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.4901
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5231, num samples collected 6000, FPS 61
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5232, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5233, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5234, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5235, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4889
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5236, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5237, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5238, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5239, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5240, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5241, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5242, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5243, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5244, num samples collected 6000, FPS 60
  Algorithm: train_loss 1.1772
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5245, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5246, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4608
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5247, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5248, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2764
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5249, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1574
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5250, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5251, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9127
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5252, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6186
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5253, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5254, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9489
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5255, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5256, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5257, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4819
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5258, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6277
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5259, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5260, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5261, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0556
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5262, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3839
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5263, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0589
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5264, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3616
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5265, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5266, num samples collected 6000, FPS 60
  Algorithm: train_loss 1.5250
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5267, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5268, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5269, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5270, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5271, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5272, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5273, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0399
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5274, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5275, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4668
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5276, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9595
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5277, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5278, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5279, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5280, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5281, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5282, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1748
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5283, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4538
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5284, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5666
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5285, num samples collected 6000, FPS 60
  Algorithm: train_loss 1.6608
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5286, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5287, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3230
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5288, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5289, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0821
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5290, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5291, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4106
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5292, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3604
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5293, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5294, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4765
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5295, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5296, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5297, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5298, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5299, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0416
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5300, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6295
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5301, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5302, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5303, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5304, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5305, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5306, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.7970
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5307, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4558
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5308, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.7344
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5309, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5310, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4005
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5311, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6529
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5312, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5313, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1594
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5314, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5315, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5316, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9111
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5317, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1432
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5318, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5319, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5320, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5321, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6024
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5322, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5323, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3043
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5324, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5325, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0928
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5326, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5327, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6392
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5328, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5329, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5330, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4118
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5331, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6403
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5332, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5333, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5334, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5335, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6331
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5336, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5337, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1337
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5338, num samples collected 6000, FPS 60
  Algorithm: train_loss 1.0490
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5339, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5340, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5341, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3062
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5342, num samples collected 6000, FPS 60
  Algorithm: train_loss 1.0233
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5343, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.5801
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5344, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5345, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3289
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5346, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5347, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6518
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5348, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5349, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5350, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5351, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5352, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5353, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4068
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5354, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5355, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6266
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5356, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4719
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5357, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5358, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.6462
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5359, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5360, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5361, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1374
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5362, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5363, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1077
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5364, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5365, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5366, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4041
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5367, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4701
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5368, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5369, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5370, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0469
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5371, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1982
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5372, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2644
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5373, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1541
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5374, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9449
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5375, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5376, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5377, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.7384
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5378, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5379, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.2056
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5380, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5381, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5382, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1386
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5383, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.8359
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5384, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5385, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5386, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1467
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5387, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5388, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1420
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5389, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.8544
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5390, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.9149
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5391, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1852
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5392, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5393, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5394, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5395, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5396, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5397, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.1535
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5398, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.4299
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5399, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.3496
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5400, num samples collected 6000, FPS 60
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1703.5520, l 200.0000, t 175.0469, TestReward -1795.4831
Update 5401, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5402, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4761
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5403, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.9366
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5404, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0391
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5405, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5406, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3145
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5407, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4691
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5408, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4577
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5409, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5839
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5410, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5411, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2763
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5412, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5413, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0927
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5414, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5415, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5416, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6805
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5417, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5418, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5419, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4169
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5420, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6493
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5421, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5422, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5423, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5367
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5424, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0968
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5425, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3971
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5426, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5427, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4097
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5428, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5429, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4644
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5430, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8292
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5431, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5432, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5433, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5434, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5435, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5436, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5437, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7618
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5438, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5439, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6177
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5440, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1517
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5441, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5442, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5443, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4763
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5444, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5445, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5003
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5446, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5447, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6796
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5448, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0438
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5449, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0653
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5450, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5451, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5452, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4664
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5453, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1863
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5454, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5455, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5456, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8799
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5457, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5458, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5459, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5954
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5460, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3964
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5461, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5462, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5995
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5463, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2951
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5464, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5465, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5466, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5467, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5468, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4149
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5469, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5470, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5471, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5472, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4720
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5473, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3439
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5474, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5475, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.1844
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5476, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2841
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5477, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6812
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5478, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2241
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5479, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5480, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5847
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5481, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5482, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6640
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5483, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5484, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5485, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5486, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5487, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5488, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3629
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5489, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6544
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5490, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5491, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5678
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5492, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4352
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5493, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0410
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5494, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1397
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5495, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4540
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5496, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5497, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0416
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5498, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5499, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5500, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.0127
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5501, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5502, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5503, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5504, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5505, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5506, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5507, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0391
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5508, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8003
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5509, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0915
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5510, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5130
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5511, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5512, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8813
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5513, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5514, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5515, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5516, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.9150
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5517, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5518, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6727
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5519, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4793
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5520, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5521, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5522, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5523, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5524, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5525, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3789
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5526, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8296
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5527, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5528, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5529, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.2428
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5530, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5531, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4783
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5532, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0470
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5533, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5534, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4562
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5535, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3812
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5536, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5537, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2515
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5538, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5539, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1417
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5540, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2860
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5541, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4497
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5542, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6713
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5543, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5544, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6198
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5545, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5546, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5547, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2533
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5548, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5549, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1264
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5550, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5551, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5552, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4123
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5553, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.5441
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5554, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5555, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5556, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5557, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7660
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5558, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0417
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5559, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5560, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7406
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5561, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5562, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5563, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5564, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5565, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0886
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5566, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4762
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5567, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5568, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5569, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5570, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0979
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5571, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5572, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5232
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5573, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.3287
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5574, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6362
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5575, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6748
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5576, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5577, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8338
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5578, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0932
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5579, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5580, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5581, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5582, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5583, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5584, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4590
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5585, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5586, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1549
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5587, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6352
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5588, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5202
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5589, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1366
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5590, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5591, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0541
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5592, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1611
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5593, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1446
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5594, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5595, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5596, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.0740
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5597, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1718
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5598, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0958
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5599, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8187
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5600, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5601, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5602, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8910
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5603, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5604, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5204
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5605, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5606, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5607, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5608, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5609, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5610, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5611, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5948
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5612, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5613, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5614, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4405
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5615, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6494
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5616, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5722
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5617, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5618, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1905
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5619, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5743
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5620, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5621, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4355
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5622, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7109
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5623, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5624, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5625, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5626, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6554
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5627, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1443
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5628, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.2257
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5629, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5630, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5631, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5632, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1878
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5633, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1544
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5634, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5635, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0955
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5636, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5637, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4362
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5638, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5639, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6241
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5640, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5641, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5642, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.9534
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5643, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4787
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5644, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5645, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5646, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5893
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5647, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5648, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0430
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5649, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5650, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5651, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5652, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1543
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5653, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5654, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1409
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5655, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5656, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2627
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5657, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5658, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2288
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5659, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5660, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6516
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5661, num samples collected 6250, FPS 53
  Algorithm: train_loss 1.7634
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5662, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2579
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5663, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5956
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5664, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4124
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5665, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5666, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1341
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5667, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5668, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5669, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4730
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5670, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5671, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5672, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5621
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5673, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5633
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5674, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.2069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5675, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5676, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5677, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5678, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1836
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5679, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5680, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4638
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5681, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.7267
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5682, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5683, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4712
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5684, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.8201
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5685, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0904
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5686, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.5800
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5687, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.9610
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5688, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1601
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5689, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5690, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1945
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5691, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.4490
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5692, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1887
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5693, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1523
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5694, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5695, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5696, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5697, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5698, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.6923
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5699, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5700, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.1229
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5701, num samples collected 6250, FPS 53
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5702, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5703, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0507
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5704, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6986
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5705, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8959
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5706, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5707, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5708, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6570
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5709, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5710, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2745
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5711, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2997
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5712, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5713, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5714, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5715, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5716, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5717, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1643
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5718, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7467
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5719, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5720, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5721, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9295
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5722, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5723, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5724, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4154
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5725, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5726, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4078
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5727, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5728, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5729, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4866
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5730, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5731, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9952
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5732, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4847
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5733, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5734, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2033
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5735, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5736, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5737, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4829
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5738, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5739, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0402
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5740, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8835
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5741, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4238
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5742, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7974
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5743, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1492
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5744, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3560
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5745, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5746, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5747, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5748, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5749, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0983
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5750, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3742
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5751, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8879
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5752, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0579
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5753, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5754, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5755, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2530
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5756, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0547
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5757, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.4743
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5758, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5759, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5760, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5761, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1391
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5762, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5763, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5764, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5765, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5766, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5767, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5768, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5769, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5286
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5770, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6575
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5771, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3640
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5772, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5773, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5774, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5775, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5776, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5777, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6289
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5778, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5779, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5722
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5780, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5781, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0313
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5782, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5783, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4395
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5784, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5997
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5785, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4108
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5786, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2817
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5787, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0416
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5788, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0486
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5789, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5790, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0972
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5791, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5676
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5792, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5793, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5794, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5795, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5796, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5797, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5857
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5798, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1417
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5799, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4820
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5800, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5801, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4407
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5802, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5803, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2002
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5804, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5805, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7577
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5806, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5807, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5808, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.6914
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5809, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5810, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1836
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5811, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1548
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5812, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5813, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5814, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1542
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5815, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1388
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5816, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5817, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5818, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5819, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1189
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5820, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5821, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5822, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5823, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5824, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5825, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1291
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5826, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5827, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5828, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1533
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5829, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0854
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5830, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5831, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5008
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5832, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1403
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5833, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5834, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5375
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5835, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5836, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.5349
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5837, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0976
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5838, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3013
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5839, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5840, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5841, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5842, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5946
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5843, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5844, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5845, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5846, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4697
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5847, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5848, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1608
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5849, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5306
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5850, num samples collected 6250, FPS 52
  Algorithm: train_loss 2.3115
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5851, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6969
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5852, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5853, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3196
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5854, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5855, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5856, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5857, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4579
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5858, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5859, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5860, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5861, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4693
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5862, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0923
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5863, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5864, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9655
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5865, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0410
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5866, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1008
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5867, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6636
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5868, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5869, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2027
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5870, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5871, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5872, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2203
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5873, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4213
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5874, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5875, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5876, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5877, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1813
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5878, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5879, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.0167
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5880, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5881, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5882, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5883, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2234
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5884, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5885, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5886, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6138
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5887, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5888, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4118
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5889, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4674
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5890, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5891, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5892, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5893, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2293
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5894, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5895, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4188
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5896, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6615
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5897, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4954
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5898, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5899, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9050
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5900, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5901, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5902, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2933
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5903, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4030
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5904, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0396
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5905, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5906, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6505
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5907, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8414
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5908, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5909, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5910, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5754
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5911, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0278
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5912, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0277
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5913, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4681
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5914, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5653
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5915, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2787
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5916, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5917, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5918, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5811
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5919, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5920, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5921, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5922, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5923, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5924, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5925, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5926, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5927, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4917
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5928, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5929, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5930, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0376
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5931, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0930
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5932, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5933, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7565
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5934, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5935, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4611
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5936, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5937, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5938, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5939, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1415
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5940, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5941, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5942, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.4862
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5943, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5944, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3293
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5945, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7753
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5946, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.0732
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5947, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5948, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5949, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5950, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5951, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5952, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0433
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5953, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4213
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5954, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1560
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5955, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0601
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5956, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5957, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4558
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5958, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4248
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5959, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5960, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5961, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1574
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5962, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5963, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5964, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5965, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5966, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5967, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5202
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5968, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5969, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2866
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5970, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1502
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5971, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3651
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5972, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1974
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5973, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5974, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4650
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5975, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5976, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5547
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5977, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5978, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6360
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5979, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5980, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5981, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0402
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5982, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5983, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4584
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5984, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5985, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5986, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5987, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4406
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5988, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4375
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5989, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5990, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3578
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5991, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5992, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5934
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5993, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0480
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5994, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4988
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5995, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5996, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1273
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5997, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5998, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 5999, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6000, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6001, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0836
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6002, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4742
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6003, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1873
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6004, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6005, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2889
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6006, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6007, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4187
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6008, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8450
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6009, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.1434
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6010, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4668
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6011, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6012, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6013, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6014, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6015, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6016, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6017, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4182
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6018, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6019, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6020, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3831
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6021, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6022, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6023, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3933
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6024, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6025, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4445
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6026, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4208
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6027, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8783
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6028, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6029, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5815
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6030, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6031, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6455
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6032, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6033, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6034, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6035, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4709
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6036, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1551
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6037, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6038, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4035
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6039, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0525
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6040, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6041, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0401
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6042, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2675
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6043, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6708
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6044, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0541
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6045, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2951
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6046, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6843
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6047, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6048, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6049, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6050, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6051, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6052, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6053, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6054, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6055, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6056, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6057, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4944
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6058, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2565
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6059, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.2027
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6060, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6061, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6725
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6062, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8872
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6063, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6064, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6065, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6066, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6067, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6068, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6069, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6070, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6071, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6072, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4238
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6073, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6074, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4488
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6075, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6076, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6077, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2928
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6078, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6079, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0425
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6080, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6081, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2379
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6082, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6083, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6084, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.0413
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6085, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6086, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5851
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6087, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4663
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6088, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9256
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6089, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.7192
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6090, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6091, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4852
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6092, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6093, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6094, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.8425
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6095, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6096, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6097, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6098, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6099, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6100, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6101, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6102, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6103, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6104, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6105, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6106, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6107, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4137
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6108, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6109, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1543
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6110, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6590
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6111, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2693
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6112, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6113, num samples collected 6250, FPS 52
  Algorithm: train_loss 1.0368
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6114, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.9342
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6115, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6116, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6117, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0806
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6118, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.6028
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6119, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4788
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6120, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2714
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6121, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6122, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1783
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6123, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6124, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.5241
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6125, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6126, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6127, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6128, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1537
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6129, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6130, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6131, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6132, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.4139
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6133, num samples collected 6250, FPS 52
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6134, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2230
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6135, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4375
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6136, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.4196
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6137, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6138, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0542
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6139, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2721
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6140, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4223
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6141, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7991
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6142, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1535
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6143, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6144, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4137
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6145, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6742
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6146, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6147, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6148, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6149, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3673
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6150, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6151, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4770
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6152, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6153, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6154, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5779
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6155, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6156, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6492
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6157, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3252
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6158, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6159, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4606
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6160, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4305
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6161, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6162, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6163, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6164, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6165, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0271
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6166, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8314
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6167, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7938
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6168, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6169, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6170, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6171, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6172, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5449
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6173, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6174, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6011
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6175, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6176, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1778
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6177, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4858
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6178, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0468
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6179, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6180, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6181, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0842
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6182, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6183, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6184, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6185, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6186, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8300
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6187, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5619
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6188, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2597
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6189, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6190, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0746
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6191, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.1945
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6192, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4303
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6193, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4888
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6194, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6195, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6196, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5974
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6197, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6198, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6199, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6200, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6201, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6029
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6202, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1009
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6203, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5843
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6204, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8419
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6205, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3242
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6206, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8457
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6207, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6208, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1408
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6209, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4921
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6210, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6211, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4697
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6212, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6213, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5988
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6214, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0585
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6215, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6216, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7092
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6217, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6218, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6219, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6220, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6221, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1556
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6222, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6223, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6224, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6225, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6226, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5452
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6227, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1420
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6228, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6534
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6229, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6230, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6231, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1577
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6232, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8270
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6233, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9971
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6234, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6235, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6236, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6237, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6238, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6239, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6240, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2896
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6241, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6242, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6243, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6244, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4569
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6245, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8782
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6246, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6247, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6248, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6249, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6250, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6251, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7946
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6252, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6253, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6254, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4377
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6255, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6189
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6256, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6280
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6257, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6258, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3961
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6259, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6260, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6261, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8707
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6262, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4620
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6263, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6264, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5417
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6265, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6266, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6267, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6268, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6269, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0980
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6270, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5033
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6271, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6272, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6273, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6274, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4286
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6275, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2383
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6276, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.2747
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6277, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2916
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6278, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0471
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6279, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6280, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6281, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4675
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6282, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6283, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6284, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6285, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6286, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6287, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4036
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6288, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0364
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6289, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0946
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6290, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1578
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6291, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6292, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6293, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4299
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6294, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6295, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6296, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5301
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6297, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6298, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6299, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6329
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6300, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6301, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8621
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6302, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4302
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6303, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6304, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6305, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1107
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6306, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4990
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6307, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0881
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6308, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6309, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6310, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6311, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6647
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6312, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3376
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6313, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6314, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4540
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6315, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4947
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6316, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6317, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6318, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4406
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6319, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1773
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6320, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6321, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2650
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6322, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6323, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9812
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6324, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6325, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6326, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6327, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4649
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6328, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4688
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6329, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6330, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0738
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6331, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8765
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6332, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6333, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1504
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6334, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6924
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6335, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6336, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6337, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6338, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6339, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1425
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6340, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6341, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1792
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6342, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6343, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.2016
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6344, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6345, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5468
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6346, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6347, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6348, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6349, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6350, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6351, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1987
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6352, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4977
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6353, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6374
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6354, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1187
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6355, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6356, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1484
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6357, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6358, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4212
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6359, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3178
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6360, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6361, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0601
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6362, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6363, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4123
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6364, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0324
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6365, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1484
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6366, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6706
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6367, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6368, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6369, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2474
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6370, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9149
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6371, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6372, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8050
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6373, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6374, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0446
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6375, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6376, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6449
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6377, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6378, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6379, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6434
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6380, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6381, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6382, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5821
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6383, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7421
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6384, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6385, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6386, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6387, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1565
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6388, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0496
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6389, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6390, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1848
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6391, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6392, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6393, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0793
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6394, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4636
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6395, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6396, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6397, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0866
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6398, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5023
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6399, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2468
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6400, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.4170
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6401, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6402, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6403, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6404, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9358
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6405, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6406, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4719
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6407, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6408, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6409, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6410, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1417
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6411, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6412, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6413, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6414, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6862
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6415, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5652
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6416, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6417, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8256
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6418, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6419, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6420, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6421, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0272
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6422, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6423, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6424, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7475
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6425, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1155
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6426, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6427, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4120
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6428, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6429, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9268
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6430, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6431, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6432, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0793
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6433, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7371
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6434, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6435, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6436, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6437, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6438, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2727
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6439, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6440, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6441, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1878
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6442, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4159
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6443, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5507
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6444, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6445, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6446, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0348
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6447, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6448, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6449, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6450, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6451, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0213
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6452, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6453, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6454, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6455, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6456, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6457, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0579
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6458, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0302
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6459, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6460, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6461, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5851
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6462, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1773
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6463, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6556
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6464, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1545
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6465, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2269
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6466, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6467, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9461
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6468, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1967
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6469, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6470, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6471, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5183
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6472, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1240
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6473, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6466
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6474, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4334
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6475, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6476, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2272
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6477, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6478, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5618
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6479, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.0470
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6480, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6481, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0504
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6482, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2181
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6483, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4682
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6484, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4933
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6485, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1024
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6486, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6487, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4760
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6488, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4077
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6489, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3452
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6490, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6491, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6492, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0809
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6493, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6494, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6495, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4484
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6496, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6497, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6498, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6499, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6872
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6500, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9835
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6501, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6502, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6503, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6088
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6504, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4644
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6505, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2769
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6506, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.9407
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6507, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4217
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6508, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6384
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6509, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6510, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6511, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1811
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6512, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6513, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6514, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6515, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6516, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0591
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6517, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6518, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6519, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4233
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6520, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6521, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5846
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6522, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5823
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6523, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5162
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6524, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0647
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6525, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6526, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6527, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3949
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6528, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5910
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6529, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0385
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6530, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6521
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6531, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4279
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6532, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6533, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5858
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6534, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6535, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.7626
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6536, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6339
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6537, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2450
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6538, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2762
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6539, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6540, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6541, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6542, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6543, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6544, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6545, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0482
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6546, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6547, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6198
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6548, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6549, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6550, num samples collected 6250, FPS 51
  Algorithm: train_loss 1.3632
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6551, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6552, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4659
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6553, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6554, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6555, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6556, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6557, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1382
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6558, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.8761
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6559, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6560, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4833
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6561, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3791
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6562, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6563, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.1139
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6564, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6565, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6566, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.5259
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6567, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.6552
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6568, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6569, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6570, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6571, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6572, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6573, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.3679
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6574, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.4979
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6575, num samples collected 6250, FPS 51
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6576, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6577, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6578, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6579, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6580, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6581, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4667
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6582, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2972
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6583, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2198
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6584, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2456
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6585, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6586, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6226
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6587, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7058
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6588, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6589, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6590, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5742
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6591, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6592, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5734
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6593, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6594, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3240
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6595, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4177
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6596, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6597, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6598, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6599, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6600, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.9926
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6601, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6602, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1020
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6603, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6604, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6605, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6606, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7327
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6607, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6608, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6609, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4305
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6610, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6757
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6611, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1739
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6612, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.2348
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6613, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1543
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6614, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6615, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6616, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4709
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6617, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6618, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6619, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6620, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6621, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6330
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6622, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1533
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6623, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6624, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6625, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4534
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6626, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6627, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6628, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6629, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6630, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8256
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6631, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5560
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6632, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.1521
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6633, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6634, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6635, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6636, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6637, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6638, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6639, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4166
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6640, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2935
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6641, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5595
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6642, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6643, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6644, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6645, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0582
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6646, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6650
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6647, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5265
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6648, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6127
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6649, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6650, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6651, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5483
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6652, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5147
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6653, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6515
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6654, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6655, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3681
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6656, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6657, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5346
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6658, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6522
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6659, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6660, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6661, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6662, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4396
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6663, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0879
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6664, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3205
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6665, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6382
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6666, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4856
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6667, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6668, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6669, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6670, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6671, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6672, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6673, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7166
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6674, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6675, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6676, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6677, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1184
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6678, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6679, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0476
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6680, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6681, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6682, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6683, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6684, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6685, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6686, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4589
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6687, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6688, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.8162
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6689, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6690, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5592
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6691, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4738
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6692, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1539
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6693, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6694, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6695, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.1427
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6696, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6697, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1870
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6698, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1444
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6699, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6700, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6701, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6702, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7980
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6703, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6704, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4460
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6705, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6706, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6707, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8118
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6708, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6709, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6710, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6461
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6711, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6712, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6713, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4745
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6714, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6715, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6716, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4648
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6717, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2469
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6718, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6719, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2226
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6720, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4268
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6721, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6722, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4889
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6723, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6724, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6725, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4397
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6726, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2510
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6727, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6728, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6729, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4131
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6730, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6731, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6732, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.9439
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6733, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2859
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6734, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6735, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5965
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6736, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6737, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6738, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6739, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6740, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0858
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6741, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4147
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6742, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4472
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6743, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.9900
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6744, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0393
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6745, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3550
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6746, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6747, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6748, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4380
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6749, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6750, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.6738
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6751, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6752, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0951
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6753, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2517
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6754, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5871
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6755, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6756, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0532
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6757, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7353
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6758, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6759, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.0435
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6760, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.1026
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6761, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6762, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6763, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6764, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6765, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6766, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.9493
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6767, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5764
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6768, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0841
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6769, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6770, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6771, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6772, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6773, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6774, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6775, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3644
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6776, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6777, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6778, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6779, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6780, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1345
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6781, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6782, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4212
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6783, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2485
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6784, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6785, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6786, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8162
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6787, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6788, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8783
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6789, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6790, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6791, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2736
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6792, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0964
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6793, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6794, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6401
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6795, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5536
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6796, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6797, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4843
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6798, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6799, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4706
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6800, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6801, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1025
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6802, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6803, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1413
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6804, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0364
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6805, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4767
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6806, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6807, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2331
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6808, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6809, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0994
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6810, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6811, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5036
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6812, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3635
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6813, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6814, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6016
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6815, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7017
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6816, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6817, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6011
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6818, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5424
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6819, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8060
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6820, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6821, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4077
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6822, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4750
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6823, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6824, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0913
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6825, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6826, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0289
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6827, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2382
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6828, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6829, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6830, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4008
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6831, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6832, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6833, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5150
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6834, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5363
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6835, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6836, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8268
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6837, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1785
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6838, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6839, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7456
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6840, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4638
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6841, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4067
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6842, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6843, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6844, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4379
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6845, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2896
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6846, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6847, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.7729
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6848, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6849, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6850, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6851, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6671
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6852, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6510
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6853, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6854, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6855, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1271
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6856, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8863
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6857, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6858, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6859, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1614
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6860, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4064
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6861, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6862, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6544
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6863, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.0293
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6864, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6865, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6866, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6867, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6868, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5703
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6869, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6870, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6871, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6872, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0409
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6873, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6874, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6875, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2616
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6876, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6877, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1424
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6878, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2192
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6879, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.6662
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6880, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6881, num samples collected 6250, FPS 50
  Algorithm: train_loss 1.4786
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6882, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6883, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1847
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6884, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6885, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6886, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6887, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6888, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6889, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.4169
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6890, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.5103
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6891, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6892, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6893, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.8532
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6894, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3038
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6895, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6896, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6897, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6898, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6899, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6900, num samples collected 6250, FPS 50
  Algorithm: train_loss 0.3594
  Episodes: TrainReward -1597.0379, l 200.0000, t 201.7657, TestReward -1696.6187
Update 6901, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.4201
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6902, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6903, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6904, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.5429
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6905, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.5295
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6906, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6907, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.4981
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6908, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.9192
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6909, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.4877
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6910, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.1972
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6911, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6912, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6913, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6914, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.7554
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6915, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6916, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.2075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6917, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6918, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6919, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.2667
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6920, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.4182
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6921, num samples collected 6500, FPS 46
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6922, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6923, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0384
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6924, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4283
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6925, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6926, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6927, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6928, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4905
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6929, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.7056
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6930, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3726
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6931, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1493
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6932, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6933, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6934, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6973
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6935, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6936, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6937, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6938, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4461
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6939, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6940, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6941, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3036
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6942, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4178
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6943, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4268
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6944, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8188
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6945, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4538
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6946, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0632
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6947, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2536
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6948, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5469
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6949, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0911
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6950, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6951, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1845
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6952, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6953, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0543
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6954, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5272
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6955, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6956, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1562
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6957, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1194
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6958, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8447
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6959, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6960, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4301
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6961, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6962, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0671
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6963, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.7710
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6964, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6965, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6850
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6966, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3424
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6967, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6968, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6969, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1299
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6970, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6971, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4681
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6972, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1694
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6973, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6974, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6975, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6976, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6977, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1175
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6978, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6979, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6980, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1504
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6981, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6982, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6734
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6983, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4195
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6984, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6985, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6986, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4771
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6987, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6988, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6989, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6990, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2198
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6991, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6992, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1592
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6993, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6994, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6978
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6995, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6996, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1189
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6997, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4897
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6998, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 6999, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6155
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7000, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9168
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7001, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4432
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7002, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7003, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0853
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7004, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4780
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7005, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0444
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7006, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1379
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7007, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7008, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1927
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7009, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6698
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7010, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7011, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7012, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7013, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7014, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2883
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7015, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4137
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7016, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7017, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7018, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7019, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6050
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7020, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7021, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7022, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2831
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7023, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7024, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1034
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7025, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1870
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7026, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7027, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7028, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4350
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7029, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1578
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7030, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0532
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7031, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7032, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7033, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7034, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1498
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7035, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9574
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7036, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7037, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5097
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7038, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7039, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7040, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7041, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2149
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7042, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7043, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7044, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.5452
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7045, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0378
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7046, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7047, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7048, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1619
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7049, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7050, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7051, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7052, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4831
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7053, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7054, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1919
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7055, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5911
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7056, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7057, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6330
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7058, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.3043
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7059, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6690
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7060, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7061, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0626
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7062, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6690
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7063, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7064, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0798
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7065, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7066, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7067, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1577
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7068, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7069, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7070, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6260
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7071, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7072, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7073, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1529
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7074, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7075, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7076, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7077, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0418
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7078, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7079, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.7215
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7080, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7081, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7082, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7083, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9655
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7084, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7085, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8265
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7086, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7087, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2710
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7088, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7089, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2984
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7090, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7091, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2297
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7092, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7093, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7094, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7095, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7096, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5492
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7097, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4811
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7098, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1436
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7099, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7100, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7101, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0320
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7102, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6886
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7103, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7104, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0837
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7105, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7106, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5648
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7107, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7108, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7109, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7110, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8570
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7111, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9316
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7112, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7113, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7114, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4749
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7115, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7116, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7117, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7118, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7119, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5921
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7120, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3268
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7121, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7122, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7123, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5175
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7124, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1840
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7125, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7126, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4938
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7127, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7128, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1155
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7129, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4320
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7130, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0430
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7131, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4322
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7132, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7133, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2178
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7134, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7135, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7136, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7137, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1552
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7138, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1418
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7139, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4298
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7140, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2862
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7141, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0557
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7142, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7143, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0742
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7144, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9991
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7145, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7146, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7147, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7148, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4317
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7149, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3718
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7150, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7151, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.3523
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7152, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7153, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7154, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6638
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7155, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4855
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7156, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0411
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7157, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5994
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7158, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1446
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7159, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7160, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7161, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7162, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7163, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7164, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7165, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7166, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0445
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7167, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7168, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7169, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5958
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7170, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7171, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7172, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1573
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7173, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1823
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7174, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6698
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7175, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0978
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7176, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1029
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7177, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5827
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7178, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0445
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7179, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4782
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7180, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7181, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7182, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1258
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7183, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0682
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7184, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0394
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7185, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7186, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7187, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3737
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7188, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1694
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7189, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7190, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2279
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7191, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7192, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4231
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7193, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7194, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7195, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7196, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7197, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7198, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4257
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7199, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1616
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7200, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.7573
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7201, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7202, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7203, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7204, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0516
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7205, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5647
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7206, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8394
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7207, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7208, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4937
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7209, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1526
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7210, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7211, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7212, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4507
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7213, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8516
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7214, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7215, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7216, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7217, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7218, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7219, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2588
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7220, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7221, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1520
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7222, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1425
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7223, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5740
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7224, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2245
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7225, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.2664
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7226, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4235
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7227, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5520
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7228, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7229, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0918
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7230, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0620
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7231, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7232, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7233, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7234, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7235, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7236, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1494
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7237, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7238, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7239, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7240, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0725
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7241, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2153
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7242, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7243, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7244, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7245, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4884
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7246, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0443
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7247, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7248, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7249, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0986
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7250, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7251, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1773
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7252, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6505
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7253, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7254, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7255, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2822
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7256, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7257, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7258, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0534
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7259, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3283
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7260, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4854
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7261, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6343
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7262, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7263, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.2147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7264, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7265, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3447
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7266, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7267, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6645
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7268, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7269, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7270, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5516
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7271, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7272, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7273, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3670
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7274, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7275, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6043
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7276, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2793
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7277, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0855
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7278, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1219
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7279, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1424
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7280, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5288
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7281, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7282, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1227
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7283, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5420
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7284, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7285, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7286, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7287, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7288, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7289, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4816
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7290, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7291, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7292, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7293, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7294, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7295, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7296, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.2259
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7297, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7298, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2849
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7299, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7300, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7301, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7302, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5338
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7303, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0715
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7304, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4285
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7305, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7306, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6696
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7307, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2940
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7308, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1945
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7309, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7310, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7311, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6399
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7312, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6865
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7313, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7314, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7315, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7316, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0795
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7317, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5841
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7318, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1511
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7319, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7320, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7321, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0383
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7322, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.5445
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7323, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4844
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7324, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4689
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7325, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4129
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7326, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7327, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7328, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5292
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7329, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7330, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7331, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7332, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1983
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7333, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6907
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7334, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7335, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7336, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7337, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7338, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7339, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0240
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7340, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1080
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7341, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7342, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7343, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7344, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6851
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7345, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7346, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0512
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7347, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7348, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2769
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7349, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1408
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7350, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0530
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7351, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7352, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0721
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7353, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7354, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7355, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7356, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4186
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7357, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4851
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7358, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1240
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7359, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3744
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7360, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7361, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5495
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7362, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7363, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7364, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1768
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7365, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7366, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0650
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7367, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6441
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7368, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7369, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7370, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0409
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7371, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2528
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7372, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7373, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7374, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1150
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7375, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7376, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4139
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7377, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7378, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7379, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.0825
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7380, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4311
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7381, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4209
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7382, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1550
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7383, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6272
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7384, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7385, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7386, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1491
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7387, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7388, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7389, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7390, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7391, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7392, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7393, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0433
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7394, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7395, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7396, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.7159
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7397, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7398, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4878
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7399, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6012
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7400, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7401, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7402, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5112
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7403, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2987
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7404, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0401
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7405, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1452
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7406, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7407, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2295
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7408, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7409, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2348
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7410, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7411, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7412, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7413, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4825
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7414, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7415, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7416, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.2247
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7417, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7418, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7419, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5768
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7420, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7421, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7422, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7423, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0671
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7424, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.2804
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7425, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7426, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7427, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7428, num samples collected 6500, FPS 45
  Algorithm: train_loss 1.1398
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7429, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7430, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0419
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7431, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3718
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7432, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7433, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7434, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1579
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7435, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3710
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7436, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7437, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6392
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7438, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5279
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7439, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3998
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7440, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7441, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7442, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7443, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1264
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7444, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7445, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5417
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7446, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7447, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4135
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7448, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1888
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7449, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7450, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7451, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7452, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7453, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7454, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7455, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7456, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7457, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4179
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7458, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7459, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5839
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7460, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4265
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7461, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7462, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1768
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7463, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7464, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4987
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7465, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1935
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7466, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6671
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7467, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7468, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8603
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7469, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.5158
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7470, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.6111
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7471, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0817
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7472, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7473, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7474, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7475, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7476, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9427
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7477, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7478, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7479, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7480, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.3389
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7481, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7482, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7483, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.4257
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7484, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7485, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.0712
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7486, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.1371
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7487, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.9169
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7488, num samples collected 6500, FPS 45
  Algorithm: train_loss 0.8289
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7489, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7490, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3656
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7491, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7492, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1930
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7493, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2280
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7494, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7344
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7495, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7496, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0440
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7497, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7498, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7499, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7500, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7501, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4901
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7502, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7503, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7504, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7505, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5563
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7506, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7507, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1930
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7508, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7509, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7510, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1137
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7511, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.0309
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7512, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2317
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7513, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0512
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7514, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7515, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8960
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7516, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9126
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7517, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0918
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7518, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8463
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7519, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2990
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7520, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7521, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7522, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5021
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7523, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7524, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7525, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7526, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7527, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7528, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4801
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7529, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7530, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7531, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7532, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4282
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7533, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7534, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7535, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7536, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3898
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7537, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0365
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7538, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.0407
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7539, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3095
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7540, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7541, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1448
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7542, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7543, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5163
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7544, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4723
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7545, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5606
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7546, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7547, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.2301
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7548, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0661
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7549, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4634
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7550, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7551, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6981
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7552, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2408
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7553, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3258
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7554, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7555, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7556, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7557, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5645
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7558, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7559, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6778
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7560, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7561, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0654
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7562, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4188
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7563, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7564, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0598
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7565, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7566, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.1868
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7567, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7568, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7569, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7570, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7571, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3909
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7572, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7573, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0796
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7574, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1116
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7575, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7576, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7577, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7578, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4794
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7579, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7580, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7581, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7582, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7583, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7584, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7585, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3894
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7586, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7587, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1864
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7588, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7589, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1928
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7590, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1833
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7591, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7592, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1238
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7593, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7594, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.3261
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7595, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4316
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7596, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7597, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8432
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7598, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.0183
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7599, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7600, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7601, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7602, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7603, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1967
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7604, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2981
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7605, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8648
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7606, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7607, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7608, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7609, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7610, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7611, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4152
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7612, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7613, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7614, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4930
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7615, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7616, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7617, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7618, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3212
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7619, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7620, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7621, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8509
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7622, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7623, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7624, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.3816
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7625, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7626, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7627, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4944
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7628, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4561
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7629, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5263
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7630, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7631, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2198
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7632, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6714
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7633, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7634, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4235
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7635, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7636, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5188
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7637, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7638, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.3792
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7639, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2679
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7640, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7641, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7637
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7642, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7643, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7644, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7645, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6717
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7646, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7647, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7648, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2432
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7649, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7650, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7651, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7652, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7653, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7654, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7655, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7656, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7657, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7658, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6892
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7659, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7660, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7661, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.4599
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7662, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7663, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8138
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7664, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7665, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7666, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7667, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7668, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7669, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7670, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7671, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5177
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7672, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7673, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0988
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7674, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7675, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7676, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2683
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7677, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2858
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7678, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1455
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7679, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0524
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7680, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4354
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7681, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4886
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7682, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7683, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7684, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7685, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7686, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7687, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5266
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7688, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4862
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7689, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7690, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3124
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7691, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6877
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7692, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7693, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4207
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7694, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7695, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7696, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6223
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7697, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3264
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7698, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7699, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0225
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7700, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7701, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0711
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7702, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7703, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4728
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7704, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7190
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7705, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7706, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7707, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6699
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7708, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7709, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7710, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7711, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1351
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7712, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7713, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7714, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6764
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7715, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7716, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.3859
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7717, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7718, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7719, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5417
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7720, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6606
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7721, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7722, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0522
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7723, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7724, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0370
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7725, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7726, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6339
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7727, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7728, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6733
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7729, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7730, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7731, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7732, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0023
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7733, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7734, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7735, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8193
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7736, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6579
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7737, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7738, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4088
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7739, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7740, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4181
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7741, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7742, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7743, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7744, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5242
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7745, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7746, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5189
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7747, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7748, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1610
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7749, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7750, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7751, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7752, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7753, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0433
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7754, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.1629
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7755, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3897
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7756, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2758
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7757, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4247
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7758, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7759, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.1325
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7760, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7761, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5866
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7762, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7763, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7764, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7765, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7766, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7678
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7767, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7768, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0713
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7769, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7770, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7771, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7772, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4755
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7773, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3373
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7774, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7775, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7776, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1035
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7777, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1176
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7778, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7779, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7780, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1550
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7781, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7782, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6006
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7783, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7784, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7785, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.0643
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7786, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7787, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7788, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1449
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7789, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1863
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7790, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6650
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7791, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1266
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7792, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4543
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7793, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4343
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7794, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4247
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7795, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0775
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7796, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1486
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7797, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7798, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7799, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4023
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7800, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7801, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7802, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7803, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4928
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7804, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7805, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6945
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7806, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7807, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1611
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7808, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0599
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7809, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5345
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7810, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7811, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2258
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7812, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1574
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7813, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7814, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7815, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7816, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7817, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3752
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7818, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5252
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7819, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1346
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7820, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4783
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7821, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7822, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7823, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4813
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7824, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7825, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7826, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0500
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7827, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7828, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4435
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7829, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4307
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7830, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7831, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9693
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7832, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6878
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7833, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2862
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7834, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7835, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7090
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7836, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7837, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7838, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7839, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4108
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7840, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.1530
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7841, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7842, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4719
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7843, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7844, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7845, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7846, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7847, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9132
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7848, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0507
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7849, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9281
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7850, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7851, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7852, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7853, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6742
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7854, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3708
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7855, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4242
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7856, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7857, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7858, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3062
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7859, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7860, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7861, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7862, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7863, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7864, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7865, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7866, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7867, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7868, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2348
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7869, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7685
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7870, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0496
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7871, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6139
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7872, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5909
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7873, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5967
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7874, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1608
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7875, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.2535
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7876, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7113
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7877, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7878, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7879, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3334
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7880, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7881, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7882, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7883, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0604
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7884, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7885, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3964
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7886, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7887, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7888, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7889, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7890, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7891, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.2540
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7892, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7893, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7894, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7895, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7896, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7897, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1500
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7898, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7899, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7900, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4630
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7901, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6840
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7902, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7903, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7904, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7905, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7906, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7907, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7908, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9005
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7909, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7910, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1642
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7911, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7912, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1403
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7913, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4280
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7914, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7915, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7916, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1149
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7917, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3748
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7918, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7919, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7920, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7921, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0802
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7922, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7923, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5552
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7924, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7925, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4645
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7926, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7927, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7928, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7929, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7930, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3250
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7931, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.1544
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7932, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0997
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7933, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7934, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7935, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0384
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7936, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2884
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7937, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5632
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7938, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1643
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7939, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4202
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7940, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.0527
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7941, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1470
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7942, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7943, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7944, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2268
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7945, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7946, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6213
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7947, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7948, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7949, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1965
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7950, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7951, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8271
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7952, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9059
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7953, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3639
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7954, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6759
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7955, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7956, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7957, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7958, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7959, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7960, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7961, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7962, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7963, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7964, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7965, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8958
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7966, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7967, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4874
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7968, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7969, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9616
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7970, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7971, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7972, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0766
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7973, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3041
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7974, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7975, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4663
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7976, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7977, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7978, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7979, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7980, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7981, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1608
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7982, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5260
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7983, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7984, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2476
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7985, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0987
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7986, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7987, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7988, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7989, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.7915
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7990, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8713
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7991, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7992, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0886
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7993, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6556
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7994, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7995, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4655
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7996, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7997, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4210
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7998, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9357
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 7999, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8000, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5628
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8001, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8002, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8003, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8004, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8005, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5413
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8006, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2106
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8007, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8008, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8009, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5343
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8010, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8011, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8012, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1167
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8013, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8014, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.6580
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8015, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8016, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4282
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8017, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8018, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8019, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8020, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8021, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4924
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8022, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5794
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8023, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8024, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3424
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8025, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8026, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.2004
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8027, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8028, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4101
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8029, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8030, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8031, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8032, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5824
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8033, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3590
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8034, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8035, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.9367
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8036, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0361
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8037, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0269
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8038, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1385
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8039, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2018
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8040, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8041, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3422
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8042, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0648
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8043, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8044, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4782
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8045, num samples collected 6500, FPS 44
  Algorithm: train_loss 1.3131
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8046, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8047, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8048, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4862
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8049, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5996
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8050, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1776
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8051, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8052, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8053, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8054, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8055, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3080
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8056, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.8218
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8057, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4659
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8058, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8059, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.2197
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8060, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8061, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8062, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.4246
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8063, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.3771
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8064, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.5740
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8065, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8066, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.1462
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8067, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8068, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8069, num samples collected 6500, FPS 44
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8070, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8071, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.5249
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8072, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1424
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8073, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8074, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3689
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8075, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8076, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8077, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8078, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4710
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8079, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8080, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8081, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8082, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5945
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8083, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8084, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3729
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8085, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4096
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8086, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8087, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8088, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8089, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1422
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8090, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4663
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8091, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8092, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8093, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8094, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6404
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8095, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8096, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8097, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8098, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5976
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8099, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8100, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2759
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8101, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5711
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8102, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5036
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8103, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8104, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6644
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8105, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1862
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8106, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3756
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8107, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1947
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8108, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5710
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8109, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5218
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8110, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4793
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8111, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8112, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8113, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8114, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4861
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8115, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8116, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1927
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8117, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8118, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8119, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8120, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8121, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8122, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8123, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1799
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8124, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8125, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6626
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8126, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8127, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6310
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8128, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8129, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8130, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8131, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8132, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8133, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8134, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4325
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8135, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8136, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0904
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8137, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8106
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8138, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1973
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8139, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1364
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8140, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8141, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8142, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8143, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8144, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8145, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5672
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8146, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.5333
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8147, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8148, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8149, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8150, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8151, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8152, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8153, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8154, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8155, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8156, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8157, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0504
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8158, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6736
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8159, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8160, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8161, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8162, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4158
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8163, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8164, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8165, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8166, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.9229
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8167, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8168, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8169, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4770
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8170, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8171, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6310
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8172, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8173, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8174, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8175, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8176, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0589
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8177, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2943
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8178, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4906
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8179, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8180, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8181, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8182, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8183, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.9089
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8184, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8185, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8186, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8187, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3405
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8188, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8189, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4270
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8190, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2998
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8191, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8192, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8193, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6690
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8194, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8918
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8195, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4549
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8196, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8197, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8198, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8199, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8200, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2640
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8201, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4195
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8202, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8203, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8204, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7722
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8205, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8206, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2382
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8207, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8208, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8209, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8210, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8211, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8212, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1529
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8213, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8214, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8215, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8216, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3923
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8217, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5789
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8218, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8332
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8219, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8220, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8221, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8222, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1138
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8223, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.2828
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8224, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0642
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8225, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8226, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4148
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8227, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8228, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2580
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8229, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8230, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1621
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8231, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8232, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8233, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0517
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8234, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8235, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8236, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8237, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4317
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8238, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1499
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8239, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6838
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8240, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6637
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8241, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8242, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4157
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8243, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8246
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8244, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8245, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1537
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8246, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8247, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4885
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8248, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7270
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8249, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8250, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0430
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8251, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5727
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8252, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8253, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8254, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8255, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8256, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8257, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1926
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8258, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8259, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3483
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8260, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4220
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8261, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2308
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8262, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6928
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8263, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8264, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8265, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1918
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8266, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6592
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8267, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8624
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8268, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0897
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8269, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8270, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2985
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8271, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8272, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6137
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8273, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8274, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5297
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8275, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8276, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8277, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4798
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8278, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8279, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8280, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8281, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8282, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1007
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8283, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8129
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8284, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4510
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8285, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2409
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8286, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8287, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0254
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8288, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2414
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8289, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.9537
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8290, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8291, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8292, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8293, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8294, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8295, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0647
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8296, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5332
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8297, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8298, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5779
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8299, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.4528
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8300, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8301, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1524
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8302, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8303, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0390
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8304, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8305, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5934
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8306, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8307, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1455
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8308, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3468
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8309, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5630
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8310, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8311, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1305
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8312, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8313, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8314, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5978
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8315, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6746
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8316, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5187
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8317, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7654
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8318, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8319, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5528
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8320, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4978
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8321, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8322, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8323, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8324, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8325, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8326, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8327, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8328, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2837
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8329, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8330, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0533
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8331, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8332, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8333, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8334, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0579
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8335, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8336, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.9304
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8337, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8338, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5209
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8339, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4170
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8340, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8341, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4280
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8342, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1792
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8343, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2881
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8344, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1576
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8345, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.0174
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8346, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1375
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8347, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8594
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8348, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8349, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8350, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8351, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0451
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8352, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1329
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8353, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8354, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8355, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6600
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8356, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0020
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8357, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8358, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8359, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3112
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8360, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4073
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8361, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2016
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8362, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.1833
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8363, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8364, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6416
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8365, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8366, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8367, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8368, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4855
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8369, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8699
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8370, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8371, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8555
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8372, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3890
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8373, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8374, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8375, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1176
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8376, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8377, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8378, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0364
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8379, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8380, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8381, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0398
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8382, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4444
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8383, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0341
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8384, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8385, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3408
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8386, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8387, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8388, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8389, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0032
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8390, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4782
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8391, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1200
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8392, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1026
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8393, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.8706
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8394, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8395, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8396, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4192
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8397, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5226
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8398, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3051
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8399, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8400, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8401, num samples collected 6500, FPS 43
  Algorithm: train_loss 1.1215
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8402, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0444
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8403, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4847
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8404, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7608
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8405, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8406, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2387
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8407, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1842
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8408, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8409, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8410, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1462
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8411, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4753
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8412, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8413, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.9674
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8414, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1190
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8415, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8416, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8417, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8418, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5533
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8419, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8420, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7315
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8421, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8422, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8423, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4245
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8424, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8425, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8426, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7705
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8427, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8428, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8429, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0515
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8430, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8431, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1494
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8432, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8433, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8434, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8435, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5617
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8436, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4828
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8437, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1281
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8438, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8439, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8440, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3600
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8441, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.3743
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8442, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1028
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8443, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8444, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8445, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8446, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8447, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8448, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8449, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8450, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.5165
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8451, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4888
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8452, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7740
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8453, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8454, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.6605
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8455, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8456, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.1517
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8457, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8458, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.7329
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8459, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.4920
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8460, num samples collected 6500, FPS 43
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1719.2362, l 200.0000, t 225.6478, TestReward -1713.5121
Update 8461, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8462, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3832
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8463, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8464, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.7732
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8465, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1305
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8466, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0665
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8467, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8468, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8469, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8470, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5359
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8471, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1592
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8472, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4158
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8473, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.4449
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8474, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8475, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8476, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2484
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8477, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8478, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4260
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8479, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1329
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8480, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5316
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8481, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0740
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8482, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8483, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3815
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8484, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8485, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5853
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8486, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8487, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8488, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1597
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8489, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4811
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8490, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4391
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8491, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.8324
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8492, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4752
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8493, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.8580
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8494, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8495, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4982
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8496, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8497, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0367
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8498, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8499, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2865
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8500, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8501, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8502, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0675
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8503, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8504, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8505, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2029
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8506, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1179
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8507, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8508, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8509, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.0199
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8510, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8511, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8512, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8513, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8514, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5138
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8515, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0805
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8516, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.7229
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8517, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6507
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8518, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8519, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6724
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8520, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.8217
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8521, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0419
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8522, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8523, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3612
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8524, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.8231
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8525, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8526, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8527, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8528, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8529, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8530, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1490
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8531, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5909
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8532, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8533, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8534, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8535, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8536, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4801
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8537, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2903
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8538, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8539, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6033
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8540, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4041
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8541, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8542, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0323
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8543, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1405
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8544, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8545, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8546, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6854
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8547, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8548, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8549, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.8171
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8550, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8551, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0889
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8552, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8553, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6965
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8554, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8555, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3463
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8556, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3286
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8557, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5537
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8558, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6595
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8559, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8560, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8561, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.0745
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8562, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8563, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1221
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8564, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6657
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8565, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8566, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1138
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8567, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8568, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8569, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.0929
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8570, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8571, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3006
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8572, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8573, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8574, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8575, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8576, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3815
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8577, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8578, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6820
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8579, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8580, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4710
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8581, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1852
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8582, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8583, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8584, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8585, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5480
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8586, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8587, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3327
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8588, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.4379
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8589, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2750
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8590, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8591, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0262
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8592, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8593, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8594, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8595, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8596, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8597, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8598, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8599, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8600, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8601, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6153
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8602, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8603, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4730
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8604, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3931
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8605, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4638
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8606, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8607, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8608, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0636
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8609, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4801
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8610, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2442
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8611, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5157
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8612, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8613, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3188
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8614, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3226
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8615, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6007
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8616, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4335
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8617, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8618, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8619, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4798
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8620, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6816
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8621, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2845
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8622, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8623, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5046
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8624, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8625, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8626, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0579
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8627, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.3248
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8628, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8629, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8630, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8631, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8632, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.7772
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8633, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0489
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8634, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8635, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5903
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8636, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8637, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1819
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8638, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2951
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8639, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.1573
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8640, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8641, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8642, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1393
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8643, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4688
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8644, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3586
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8645, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8646, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8647, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8648, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8649, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0470
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8650, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8651, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8652, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2834
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8653, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0349
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8654, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8655, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4674
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8656, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8657, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8658, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8659, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8660, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8661, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8662, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5812
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8663, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5901
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8664, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8665, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4145
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8666, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2746
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8667, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1467
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8668, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8669, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2379
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8670, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2324
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8671, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8672, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6800
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8673, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8674, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0581
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8675, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.9855
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8676, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8677, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3167
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8678, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8679, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.7164
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8680, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2885
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8681, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.1747
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8682, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8683, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3244
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8684, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8685, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8686, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8687, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8688, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8689, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8690, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6999
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8691, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8692, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8693, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8694, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.6709
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8695, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8696, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4976
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8697, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8698, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8699, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8700, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8701, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8702, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4313
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8703, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8704, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8705, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.5708
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8706, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8707, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.4869
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8708, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8709, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8710, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0648
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8711, num samples collected 6750, FPS 40
  Algorithm: train_loss 1.1411
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8712, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8713, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8714, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2911
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8715, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0638
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8716, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.3158
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8717, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.2744
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8718, num samples collected 6750, FPS 40
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8719, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1391
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8720, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8721, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5985
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8722, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0624
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8723, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3841
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8724, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0358
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8725, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8726, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8727, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4969
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8728, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8729, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.2333
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8730, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3844
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8731, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8732, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1034
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8733, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5157
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8734, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8592
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8735, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8736, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8737, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8738, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8739, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1789
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8740, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9630
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8741, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2395
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8742, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8743, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5552
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8744, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8745, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8746, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0430
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8747, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1408
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8748, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8749, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8750, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7476
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8751, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8752, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8753, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8754, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3633
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8755, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9555
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8756, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2790
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8757, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8758, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7031
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8759, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4187
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8760, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0557
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8761, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1161
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8762, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8763, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8764, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8765, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8766, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8767, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9879
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8768, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8769, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3022
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8770, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8771, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4026
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8772, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0419
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8773, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4306
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8774, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8775, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6524
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8776, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8777, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3422
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8778, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4986
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8779, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0317
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8780, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6299
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8781, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8782, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2987
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8783, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4942
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8784, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8785, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0498
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8786, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4740
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8787, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8788, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2961
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8789, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1801
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8790, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4228
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8791, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.5635
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8792, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4559
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8793, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8794, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8795, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8796, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8797, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3819
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8798, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3028
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8799, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8800, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8801, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8802, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1451
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8803, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1952
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8804, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7485
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8805, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8806, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8807, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0680
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8808, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8809, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7265
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8810, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8811, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8812, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8813, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2694
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8814, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4154
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8815, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6672
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8816, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4365
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8817, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8818, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3804
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8819, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1346
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8820, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8821, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8822, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8823, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8824, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8825, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5786
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8826, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8827, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3031
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8828, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1446
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8829, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3687
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8830, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4462
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8831, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3324
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8832, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1109
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8833, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9656
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8834, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8835, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4847
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8836, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0311
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8837, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1958
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8838, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8839, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8840, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6467
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8841, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5606
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8842, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8843, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8844, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8845, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1860
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8846, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4797
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8847, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9678
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8848, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8849, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8850, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8851, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8852, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8853, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8854, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2758
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8855, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8856, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8857, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8858, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7796
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8859, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8860, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1910
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8861, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3541
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8862, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8863, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8864, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7352
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8865, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0381
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8866, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8867, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6653
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8868, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8869, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2033
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8870, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8871, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2127
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8872, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8873, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4041
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8874, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2317
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8875, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0611
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8876, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7745
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8877, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8878, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8518
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8879, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8880, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8881, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8882, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6542
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8883, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4304
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8884, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3355
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8885, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4947
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8886, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3971
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8887, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3183
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8888, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8889, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8890, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8891, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8892, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8893, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6020
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8894, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1209
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8895, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2787
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8896, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8897, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8898, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8899, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8900, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0556
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8901, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8902, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8903, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8904, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8046
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8905, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4339
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8906, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8907, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.4642
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8908, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8909, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1819
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8910, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8911, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8912, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5520
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8913, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8914, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1393
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8915, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5361
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8916, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8917, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4215
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8918, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8919, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8920, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8921, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8922, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8923, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3856
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8924, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1523
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8925, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4629
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8926, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8927, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0759
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8928, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0986
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8929, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5892
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8930, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8931, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8932, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9251
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8933, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8672
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8934, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8935, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8936, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1650
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8937, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5046
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8938, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6356
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8939, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8940, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8941, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8942, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8943, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8944, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8945, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8946, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8947, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8948, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3713
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8949, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4254
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8950, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8951, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8952, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5730
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8953, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8954, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8955, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4439
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8956, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8957, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6388
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8958, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3721
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8959, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4037
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8960, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8961, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6781
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8962, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8963, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8964, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5126
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8965, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8966, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8967, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8968, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8969, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8970, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8971, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4909
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8972, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8973, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8974, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8975, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5918
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8976, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8977, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2758
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8978, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3410
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8979, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8980, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8981, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8982, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8983, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0491
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8984, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5199
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8985, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5453
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8986, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.2363
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8987, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1265
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8988, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5238
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8989, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8990, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8991, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8992, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8993, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4968
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8994, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8995, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8996, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8997, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8998, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4758
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 8999, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4363
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9000, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9001, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9002, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7677
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9003, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2664
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9004, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9005, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2941
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9006, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9007, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9008, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9009, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9010, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9011, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9012, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2465
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9013, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3722
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9014, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7220
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9015, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9016, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9017, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9018, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9019, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4774
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9020, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.0405
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9021, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.1556
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9022, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0373
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9023, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9024, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9025, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6512
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9026, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9027, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1339
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9028, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9029, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9030, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9031, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9032, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9033, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6708
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9034, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9035, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4167
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9036, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9037, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0417
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9038, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.0750
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9039, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4834
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9040, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9026
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9041, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9042, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4773
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9043, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0611
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9044, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2158
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9045, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9046, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9047, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9048, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9049, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8859
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9050, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5899
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9051, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9052, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9053, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2726
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9054, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9055, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9056, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2738
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9057, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6673
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9058, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4185
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9059, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9060, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9061, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9062, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2914
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9063, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0373
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9064, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2908
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9065, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5142
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9066, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9067, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6019
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9068, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9069, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9070, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4853
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9071, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1917
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9072, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9073, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1308
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9074, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5296
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9075, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1550
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9076, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9077, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9030
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9078, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9079, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9080, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8901
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9081, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9082, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0473
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9083, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7312
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9084, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9085, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9086, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3108
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9087, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9088, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9089, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7217
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9090, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6740
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9091, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9092, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6440
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9093, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9094, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9095, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8293
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9096, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9097, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9098, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4015
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9099, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9100, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9101, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4038
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9102, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4272
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9103, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8278
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9104, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9105, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9106, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9107, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9108, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9109, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5184
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9110, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9111, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6813
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9112, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0738
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9113, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9114, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9115, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.4298
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9116, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9117, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9118, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5396
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9119, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5818
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9120, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9121, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3799
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9122, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9123, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9124, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2868
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9125, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9126, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9127, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9128, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9129, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4155
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9130, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9131, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9132, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1365
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9133, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9134, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4804
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9135, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9136, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9137, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.7904
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9138, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9139, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9140, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8711
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9141, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9142, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9143, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9144, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4767
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9145, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9146, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9147, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4948
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9148, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2461
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9149, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9150, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9151, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2922
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9152, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3474
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9153, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9154, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1836
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9155, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1528
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9156, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9157, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9158, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9159, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9160, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5434
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9161, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3959
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9162, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9163, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4499
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9164, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6689
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9165, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9166, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1362
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9167, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9168, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9562
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9169, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9170, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9171, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9172, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9173, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4108
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9174, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9175, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9176, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9177, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6877
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9178, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0422
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9179, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9180, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9181, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0680
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9182, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9183, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3673
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9184, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3873
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9185, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9186, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4148
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9187, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9188, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2549
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9189, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9190, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9191, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9192, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3777
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9193, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9194, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9195, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9350
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9196, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9197, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9198, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0630
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9199, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9200, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3638
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9201, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1595
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9202, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1332
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9203, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9204, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0860
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9205, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7381
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9206, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3388
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9207, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9208, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2188
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9209, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9210, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9211, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9212, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9840
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9213, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9214, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9215, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.1654
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9216, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.5647
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9217, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9218, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9219, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5968
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9220, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9221, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0595
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9222, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2775
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9223, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9224, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2838
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9225, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9226, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9227, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0590
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9228, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9229, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.2049
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9230, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9231, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9232, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2370
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9233, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0242
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9234, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4976
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9235, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4621
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9236, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9237, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9778
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9238, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2306
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9239, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9240, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5854
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9241, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9242, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1420
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9243, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9244, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9245, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4867
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9246, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3232
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9247, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9248, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4571
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9249, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9250, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9251, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9252, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4561
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9253, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9254, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6765
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9255, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9183
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9256, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9257, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9258, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9259, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9260, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9261, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9262, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4947
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9263, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9264, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5206
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9265, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9266, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9267, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9268, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9269, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6459
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9270, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9271, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9272, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6642
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9273, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9274, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0344
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9275, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2723
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9276, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4140
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9277, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9278, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9279, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1095
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9280, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1864
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9281, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4702
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9282, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9283, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4775
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9284, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5377
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9285, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2728
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9286, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9287, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9288, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3863
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9289, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2921
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9290, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9291, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9292, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2254
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9293, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1430
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9294, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4989
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9295, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9296, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1919
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9297, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9298, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9299, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2669
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9300, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9301, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4678
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9302, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7151
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9303, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9304, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9305, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9306, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5738
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9307, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9308, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1949
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9309, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9112
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9310, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9311, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1175
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9312, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9313, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4150
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9314, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9315, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9316, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3755
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9317, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9318, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9319, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9320, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1926
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9321, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4181
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9322, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5986
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9323, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9324, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9325, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3766
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9326, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9327, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9328, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4713
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9329, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9330, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9331, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9332, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9333, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4889
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9334, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9335, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5506
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9336, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3952
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9337, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9338, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.0569
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9339, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9340, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9341, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6860
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9342, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1910
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9343, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9344, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9345, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1231
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9346, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9347, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9348, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4160
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9349, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5824
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9350, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2408
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9351, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9352, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.4318
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9353, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9354, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9355, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4526
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9356, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9515
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9357, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9358, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9359, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9360, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.1005
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9361, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9362, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9363, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9364, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4710
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9365, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9366, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9367, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9368, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9369, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9370, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9371, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9372, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4329
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9373, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1378
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9374, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9375, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3185
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9376, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9377, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2494
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9378, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9379, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9380, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9381, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9382, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9383, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.9890
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9384, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9385, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9386, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9387, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9388, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0937
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9389, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4735
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9390, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9391, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1514
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9392, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9393, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9394, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9395, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2721
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9396, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4955
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9397, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9398, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9399, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3915
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9400, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4774
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9401, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5264
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9402, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9403, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8924
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9404, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9405, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3556
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9406, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6333
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9407, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0757
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9408, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9409, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9410, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9411, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9412, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9413, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9414, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9415, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9416, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9417, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9418, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5916
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9419, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6560
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9420, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6480
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9421, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0619
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9422, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9423, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2800
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9424, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9425, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2138
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9426, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9427, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4247
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9428, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9429, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3711
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9430, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9431, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9432, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9433, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0997
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9434, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4943
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9435, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4591
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9436, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0436
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9437, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3881
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9438, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2943
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9439, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9440, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9441, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9442, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9443, num samples collected 6750, FPS 39
  Algorithm: train_loss 1.1521
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9444, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9445, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3126
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9446, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4153
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9447, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9448, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9449, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9450, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9451, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5176
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9452, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9453, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.5595
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9454, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0590
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9455, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.3708
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9456, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1440
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9457, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9458, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4248
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9459, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7283
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9460, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.7582
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9461, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2679
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9462, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8331
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9463, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9464, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1993
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9465, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9466, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2713
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9467, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1969
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9468, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9469, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9470, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9471, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9472, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9473, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9474, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6781
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9475, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9476, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1453
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9477, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9478, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.8885
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9479, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1985
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9480, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2038
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9481, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9482, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9483, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9484, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.4886
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9485, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9486, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9487, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9488, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9489, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9490, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9491, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9492, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9493, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9494, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.2541
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9495, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6886
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9496, num samples collected 6750, FPS 39
  Algorithm: train_loss 0.6782
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9497, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5132
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9498, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9499, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9500, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0542
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9501, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9502, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9503, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4865
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9504, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1904
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9505, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9506, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2717
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9507, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9508, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6835
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9509, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8921
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9510, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1162
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9511, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3466
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9512, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9513, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9514, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5272
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9515, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9516, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9517, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2016
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9518, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9519, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4782
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9520, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4406
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9521, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2143
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9522, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9523, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3779
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9524, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9525, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9526, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9527, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6754
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9528, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5422
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9529, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6891
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9530, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6009
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9531, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0673
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9532, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2897
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9533, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9534, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9535, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2920
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9536, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4214
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9537, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9538, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9539, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9540, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9541, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9542, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3464
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9543, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9544, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9545, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2991
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9546, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9547, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9548, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1413
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9549, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9550, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0394
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9551, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1387
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9552, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9553, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6331
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9554, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9555, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.9745
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9556, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9557, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9558, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4145
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9559, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9560, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3416
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9561, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4131
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9562, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5553
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9563, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9564, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6747
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9565, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9566, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9567, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7973
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9568, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9569, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9570, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9571, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1966
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9572, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0294
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9573, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2416
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9574, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1480
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9575, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9576, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1523
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9577, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6128
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9578, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5277
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9579, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4135
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9580, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9581, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0699
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9582, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9583, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9584, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9585, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9586, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1404
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9587, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5503
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9588, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0440
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9589, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6164
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9590, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1190
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9591, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9592, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3171
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9593, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9594, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8733
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9595, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3240
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9596, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2753
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9597, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9598, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9599, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9600, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4714
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9601, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9602, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9603, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9604, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4294
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9605, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9606, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4792
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9607, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9608, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1149
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9609, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9610, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4759
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9611, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1621
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9612, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3381
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9613, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9614, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9615, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9616, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1110
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9617, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9618, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1680
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9619, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9620, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9621, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0463
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9622, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9623, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9624, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7974
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9625, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0305
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9626, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9627, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9628, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.0836
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9629, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9630, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6808
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9631, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9632, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9633, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7764
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9634, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9635, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9636, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4566
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9637, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4290
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9638, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9639, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6796
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9640, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9641, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9642, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2853
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9643, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4183
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9644, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9645, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2040
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9646, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9647, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3744
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9648, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9649, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1357
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9650, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4031
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9651, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9652, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0392
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9653, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9654, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9655, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2774
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9656, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9657, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6426
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9658, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9659, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7913
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9660, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9661, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3418
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9662, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9663, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9664, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4836
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9665, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4125
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9666, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9667, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9668, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6787
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9669, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9670, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.2550
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9671, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9672, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0414
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9673, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2670
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9674, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9675, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9676, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9677, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9678, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4733
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9679, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4660
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9680, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6261
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9681, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3021
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9682, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5979
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9683, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9684, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0755
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9685, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0711
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9686, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9687, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9688, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9689, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9690, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9691, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1881
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9692, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9693, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1172
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9694, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3818
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9695, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2539
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9696, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9697, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5655
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9698, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6684
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9699, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0440
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9700, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4914
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9701, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6799
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9702, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9703, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9704, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9705, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3747
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9706, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9707, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9708, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0359
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9709, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4787
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9710, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9711, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9712, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5915
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9713, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9714, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6248
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9715, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9716, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7683
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9717, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9718, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4160
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9719, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3976
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9720, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9721, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5973
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9722, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3870
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9723, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1966
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9724, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9725, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0787
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9726, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9727, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9728, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.0407
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9729, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0464
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9730, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1491
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9731, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9732, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9733, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1558
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9734, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9735, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0419
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9736, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8500
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9737, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9738, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9739, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0585
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9740, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9741, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0605
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9742, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7662
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9743, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2208
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9744, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9745, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9746, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9747, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4808
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9748, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0325
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9749, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3077
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9750, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9751, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0199
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9752, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4783
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9753, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9754, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9755, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3706
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9756, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.3169
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9757, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2627
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9758, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3900
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9759, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6794
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9760, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6104
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9761, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9762, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9763, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3938
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9764, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4854
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9765, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9766, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9767, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9768, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3932
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9769, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1403
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9770, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3045
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9771, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9772, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9773, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8356
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9774, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0672
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9775, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9776, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0369
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9777, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9778, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5846
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9779, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9780, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9781, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7766
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9782, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9783, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3552
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9784, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6970
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9785, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0598
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9786, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9787, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4707
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9788, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2658
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9789, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0314
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9790, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1930
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9791, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4315
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9792, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2637
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9793, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9794, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4286
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9795, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9796, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8295
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9797, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9798, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2308
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9799, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7069
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9800, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3518
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9801, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0538
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9802, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4225
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9803, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9804, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4140
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9805, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0997
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9806, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0365
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9807, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1063
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9808, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1335
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9809, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9810, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9811, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4714
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9812, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9813, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9814, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1608
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9815, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3732
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9816, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9817, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.0939
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9818, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8081
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9819, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0525
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9820, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9821, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5136
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9822, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9823, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6955
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9824, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1971
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9825, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9826, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9827, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9828, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9829, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9830, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5034
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9831, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3620
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9832, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1935
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9833, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4235
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9834, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9835, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1234
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9836, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9837, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9838, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4729
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9839, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9840, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0510
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9841, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1918
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9842, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9843, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9844, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9845, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9846, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9847, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9848, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9849, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4938
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9850, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4173
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9851, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9852, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9853, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8285
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9854, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9855, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4155
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9856, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7800
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9857, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9858, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0773
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9859, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5032
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9860, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9861, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3836
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9862, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9863, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9864, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9865, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2347
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9866, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5936
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9867, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9868, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1389
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9869, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9870, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9871, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1389
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9872, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5907
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9873, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7030
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9874, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4928
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9875, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9876, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9877, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9878, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3290
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9879, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9880, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9881, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2735
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9882, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9883, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5491
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9884, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9885, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0537
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9886, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9887, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9888, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9889, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9890, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9891, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0695
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9892, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1357
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9893, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2223
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9894, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9895, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9896, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9897, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9898, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4759
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9899, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8871
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9900, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9901, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9902, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9903, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9904, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.9071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9905, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9906, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4433
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9907, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0199
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9908, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7987
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9909, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7203
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9910, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4231
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9911, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9912, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9913, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9914, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9915, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1126
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9916, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3143
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9917, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1990
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9918, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9919, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6744
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9920, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9921, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2452
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9922, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2417
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9923, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9924, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5554
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9925, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4054
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9926, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1980
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9927, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9928, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9929, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9930, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9931, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1346
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9932, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.9499
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9933, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2637
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9934, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1013
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9935, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3682
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9936, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3598
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9937, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9938, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6764
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9939, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9940, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9941, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9942, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0419
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9943, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9944, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9945, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9946, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4872
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9947, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1254
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9948, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9949, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7447
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9950, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4369
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9951, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4384
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9952, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9953, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9954, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0421
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9955, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9956, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3396
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9957, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9958, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9959, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4849
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9960, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1826
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9961, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9962, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3393
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9963, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9964, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9965, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.0879
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9966, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9967, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9968, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0315
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9969, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9970, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3321
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9971, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4516
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9972, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9973, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9974, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9975, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9976, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4050
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9977, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9978, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9979, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9980, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.3583
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9981, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0435
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9982, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2558
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9983, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9984, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3375
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9985, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9986, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6754
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9987, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9988, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.7884
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9989, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2637
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9990, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1458
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9991, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0340
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9992, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3755
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9993, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5477
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9994, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9995, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9996, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9997, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9998, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4308
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 9999, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10000, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1344
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10001, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10002, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5994
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10003, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10004, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1817
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10005, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10006, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10007, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10008, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5995
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10009, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3323
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10010, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6395
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10011, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0280
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10012, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3280
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10013, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.0457
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10014, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.3023
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10015, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10016, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4932
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10017, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10018, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1890
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10019, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10020, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2693
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10021, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0537
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10022, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10023, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10024, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4177
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10025, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10026, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10027, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5820
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10028, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10029, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1869
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10030, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5242
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10031, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10032, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10033, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10034, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10035, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10036, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10037, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10038, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10039, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8573
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10040, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.8197
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10041, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10042, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4401
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10043, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10044, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10045, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5251
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10046, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5088
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10047, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0199
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10048, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10049, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10050, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10051, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10052, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6873
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10053, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0962
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10054, num samples collected 6750, FPS 38
  Algorithm: train_loss 1.1538
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10055, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4479
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10056, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10057, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10058, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10059, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4153
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10060, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1482
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10061, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1525
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10062, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10063, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.5144
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10064, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10065, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2846
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10066, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10067, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10068, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10069, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.2909
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10070, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4060
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10071, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10072, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.6748
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10073, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10074, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10075, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0920
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10076, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10077, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10078, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4751
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10079, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10080, num samples collected 6750, FPS 38
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -207.9319, l 200.0000, t 250.6823, TestReward -1688.4978
Update 10081, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10082, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.1289
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10083, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10084, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0617
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10085, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6835
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10086, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10087, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10088, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10089, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10090, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10091, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4985
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10092, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4385
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10093, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10094, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10095, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10096, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10097, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10098, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10099, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4259
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10100, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5555
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10101, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2621
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10102, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10103, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10104, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10105, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4352
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10106, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1194
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10107, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4919
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10108, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10109, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6800
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10110, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7482
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10111, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1299
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10112, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10113, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4938
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10114, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10115, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10116, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2448
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10117, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10118, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1646
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10119, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2817
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10120, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10121, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2455
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10122, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10123, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10124, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10125, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4688
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10126, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8764
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10127, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10128, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2683
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10129, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2925
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10130, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10131, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10132, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0453
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10133, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10134, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5271
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10135, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4300
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10136, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10137, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10138, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10139, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10140, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10141, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4817
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10142, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6399
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10143, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10144, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10145, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2645
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10146, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5838
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10147, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10148, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2854
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10149, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10150, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10151, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3683
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10152, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1552
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10153, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1968
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10154, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10155, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0690
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10156, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2509
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10157, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10158, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0670
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10159, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2564
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10160, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6203
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10161, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2965
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10162, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.2889
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10163, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10164, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10165, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10166, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6009
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10167, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10168, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10169, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10170, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2778
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10171, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6336
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10172, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10173, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2645
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10174, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3883
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10175, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10176, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10177, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10178, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6222
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10179, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10180, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10181, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6642
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10182, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0379
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10183, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3374
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10184, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2496
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10185, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10186, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10187, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.0737
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10188, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0998
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10189, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10190, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10191, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2441
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10192, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.2413
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10193, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10194, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4181
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10195, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10196, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10197, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10198, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10199, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8434
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10200, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10201, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1409
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10202, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4926
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10203, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10204, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10205, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10206, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1763
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10207, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7399
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10208, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3885
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10209, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10210, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1340
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10211, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10212, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3264
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10213, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10214, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10215, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10216, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10217, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8785
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10218, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6869
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10219, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10220, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10221, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10222, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4270
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10223, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10224, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10225, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4708
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10226, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10227, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5520
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10228, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10229, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4705
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10230, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1441
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10231, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0393
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10232, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10233, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10234, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4271
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10235, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1456
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10236, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4943
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10237, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10238, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10239, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10240, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5922
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10241, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6876
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10242, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10243, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10244, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4231
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10245, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10246, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10247, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10248, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5598
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10249, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.0753
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10250, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10251, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1771
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10252, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10253, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10254, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10255, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9001
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10256, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10257, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10258, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10259, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2609
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10260, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10261, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3464
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10262, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2846
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10263, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.2300
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10264, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10265, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10266, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10267, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0346
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10268, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0537
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10269, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10270, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0420
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10271, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10272, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7306
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10273, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10274, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10275, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4259
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10276, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10277, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10278, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5449
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10279, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4858
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10280, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1655
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10281, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0691
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10282, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10283, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7359
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10284, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10285, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10286, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.2701
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10287, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10288, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1189
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10289, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10290, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10291, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10292, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8915
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10293, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10294, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0350
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10295, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10296, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10297, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10298, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10299, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7494
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10300, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10301, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8165
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10302, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1750
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10303, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10304, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10305, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0542
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10306, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10307, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10308, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1010
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10309, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3323
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10310, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10311, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9452
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10312, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.4456
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10313, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1139
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10314, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10315, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10316, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10317, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4140
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10318, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10319, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3265
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10320, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10321, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7032
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10322, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10323, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4647
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10324, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3200
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10325, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10326, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10327, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2628
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10328, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4965
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10329, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4760
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10330, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10331, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10332, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10333, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6878
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10334, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10335, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0591
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10336, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2636
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10337, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10338, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1629
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10339, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9921
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10340, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10341, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10342, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2919
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10343, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10344, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10345, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6729
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10346, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10347, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10348, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7189
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10349, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6641
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10350, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5400
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10351, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10352, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10353, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0388
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10354, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7972
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10355, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10356, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10357, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10358, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10359, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10360, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3542
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10361, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10362, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10363, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1463
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10364, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2676
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10365, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10366, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.3610
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10367, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5403
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10368, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1975
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10369, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0895
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10370, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.5397
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10371, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1971
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10372, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5372
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10373, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2979
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10374, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1276
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10375, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4503
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10376, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10377, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10378, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10379, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1242
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10380, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10381, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10382, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10383, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10384, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10385, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0617
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10386, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10387, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10388, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10389, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1537
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10390, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6750
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10391, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2501
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10392, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0278
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10393, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6796
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10394, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10395, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10396, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10397, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6646
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10398, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10399, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3328
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10400, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1436
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10401, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10402, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10403, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3940
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10404, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10405, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1972
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10406, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3502
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10407, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10408, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0344
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10409, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6479
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10410, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10411, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10412, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4200
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10413, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1952
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10414, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4835
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10415, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4283
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10416, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10417, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10418, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0302
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10419, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10420, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10421, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5250
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10422, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10423, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10424, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10425, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6502
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10426, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10427, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5514
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10428, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4755
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10429, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10430, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8733
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10431, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10432, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.0861
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10433, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2201
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10434, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10435, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10436, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10437, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8374
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10438, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10439, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10440, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10441, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2299
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10442, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0317
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10443, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10444, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8803
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10445, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1643
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10446, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10447, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10448, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1887
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10449, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6841
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10450, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10451, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1180
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10452, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10453, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10454, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3924
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10455, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10456, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5611
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10457, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3680
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10458, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4820
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10459, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5485
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10460, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10461, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10462, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10463, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10464, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10465, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5123
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10466, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10467, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10468, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5435
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10469, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10470, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10471, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5467
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10472, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.3834
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10473, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10474, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10475, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10476, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6900
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10477, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6567
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10478, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10479, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10480, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10481, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3008
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10482, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.3408
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10483, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10484, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1172
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10485, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10486, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0414
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10487, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10488, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7090
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10489, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2384
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10490, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10491, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1514
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10492, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10493, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10494, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0595
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10495, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10496, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10497, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1043
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10498, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10499, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9807
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10500, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10501, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10502, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10503, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1196
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10504, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10505, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3025
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10506, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4570
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10507, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3570
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10508, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1049
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10509, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10510, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10511, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10512, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10513, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4954
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10514, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10515, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10516, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10517, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6786
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10518, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10519, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10520, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5011
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10521, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6015
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10522, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6243
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10523, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10524, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10525, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4791
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10526, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10527, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10528, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10529, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4697
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10530, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5585
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10531, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10532, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4751
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10533, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2934
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10534, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10535, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1185
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10536, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10537, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0654
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10538, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10539, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10540, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7557
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10541, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10542, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10543, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10544, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10545, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10546, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8192
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10547, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2999
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10548, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2798
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10549, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10550, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10551, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0263
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10552, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9450
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10553, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10554, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10555, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10556, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.4322
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10557, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10558, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3020
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10559, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10560, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1349
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10561, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8968
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10562, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5984
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10563, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4307
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10564, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3483
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10565, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10566, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10567, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4445
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10568, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10569, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1118
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10570, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10571, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10572, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1432
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10573, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10574, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1118
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10575, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10576, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5002
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10577, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10578, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10579, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10580, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10581, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10582, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10583, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5277
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10584, num samples collected 7000, FPS 35
  Algorithm: train_loss 2.0733
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10585, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5407
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10586, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0594
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10587, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7158
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10588, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10589, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5324
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10590, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2721
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10591, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10592, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10593, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10594, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.1380
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10595, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10596, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6000
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10597, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10598, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10599, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2051
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10600, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10601, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10602, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10603, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10604, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10605, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10606, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3976
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10607, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10608, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5126
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10609, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10610, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0435
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10611, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0819
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10612, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10613, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4712
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10614, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10615, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0945
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10616, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2917
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10617, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10618, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10619, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5423
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10620, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10621, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4849
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10622, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1172
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10623, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10624, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4426
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10625, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1250
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10626, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10627, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4353
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10628, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3907
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10629, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10630, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2871
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10631, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.0420
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10632, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10633, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10634, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0239
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10635, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10636, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10637, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10638, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1847
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10639, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10640, num samples collected 7000, FPS 35
  Algorithm: train_loss 2.4584
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10641, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2377
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10642, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4220
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10643, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10644, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10645, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4944
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10646, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10647, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1229
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10648, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10649, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6579
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10650, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10651, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2498
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10652, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10653, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10654, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10655, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10656, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10657, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10658, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2583
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10659, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4221
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10660, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1321
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10661, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10662, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0412
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10663, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3716
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10664, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7372
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10665, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10666, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2872
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10667, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10668, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.4374
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10669, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10670, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10671, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10672, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10673, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10674, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10675, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4175
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10676, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10677, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2036
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10678, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7668
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10679, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10680, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0351
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10681, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10682, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1600
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10683, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10684, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1968
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10685, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3492
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10686, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3839
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10687, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5040
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10688, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10689, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10690, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10691, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4796
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10692, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1169
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10693, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9882
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10694, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10695, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10696, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10697, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10698, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10699, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10700, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1293
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10701, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6158
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10702, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10703, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8711
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10704, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10705, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2109
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10706, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10707, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10708, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10709, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5819
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10710, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6869
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10711, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7495
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10712, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10713, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10714, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10715, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0917
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10716, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10717, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10718, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10719, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6648
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10720, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10721, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.3851
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10722, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10723, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10724, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10725, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10726, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10727, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8932
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10728, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4090
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10729, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10730, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10731, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4484
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10732, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2884
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10733, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10734, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10735, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10736, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0512
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10737, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10738, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5670
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10739, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10740, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0877
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10741, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10742, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10743, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3685
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10744, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10745, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2831
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10746, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0911
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10747, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4932
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10748, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4964
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10749, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2374
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10750, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10751, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.4744
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10752, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10753, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10754, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4620
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10755, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1031
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10756, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4299
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10757, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10758, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10759, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10760, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5582
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10761, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2599
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10762, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10763, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10764, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0592
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10765, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2409
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10766, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.0933
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10767, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9203
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10768, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3539
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10769, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3553
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10770, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10771, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10772, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10773, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10774, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.4252
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10775, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0299
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10776, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10777, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10778, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10779, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10780, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10781, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10782, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10783, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1739
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10784, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10785, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9915
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10786, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0943
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10787, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0531
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10788, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10789, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.6528
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10790, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2954
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10791, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3818
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10792, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10793, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10794, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10795, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5381
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10796, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2814
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10797, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10798, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0429
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10799, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2022
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10800, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1837
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10801, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10802, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2675
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10803, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10804, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10805, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10806, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8903
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10807, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10808, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10809, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5241
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10810, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3386
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10811, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10812, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10813, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10814, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10815, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6996
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10816, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10817, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5936
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10818, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10819, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3895
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10820, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1988
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10821, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10822, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2905
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10823, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10824, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5729
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10825, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10826, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6521
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10827, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10828, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2004
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10829, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0492
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10830, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6905
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10831, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10832, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0322
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10833, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10834, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10835, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0629
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10836, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10837, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4733
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10838, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10839, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4151
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10840, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1323
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10841, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10842, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10843, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10844, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10845, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2453
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10846, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10847, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10848, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10849, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10850, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6866
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10851, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7642
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10852, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6987
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10853, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4798
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10854, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10855, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3663
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10856, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5339
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10857, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10858, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10859, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1625
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10860, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10861, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10862, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1863
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10863, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3847
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10864, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10865, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5181
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10866, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10867, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10868, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0507
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10869, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10870, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10871, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5168
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10872, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8043
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10873, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3877
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10874, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10875, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1194
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10876, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1160
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10877, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7168
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10878, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10879, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10880, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4436
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10881, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9549
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10882, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2588
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10883, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10884, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10885, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.7436
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10886, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2010
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10887, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10888, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10889, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10890, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2749
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10891, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10892, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10893, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0940
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10894, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10895, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3860
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10896, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1152
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10897, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10898, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1876
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10899, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10900, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10901, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10902, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.1593
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10903, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2136
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10904, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10905, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2906
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10906, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4293
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10907, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10908, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9401
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10909, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0478
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10910, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10911, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10912, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10913, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4958
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10914, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10915, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3801
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10916, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1336
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10917, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10918, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10919, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2634
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10920, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0222
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10921, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6776
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10922, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0617
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10923, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10924, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10925, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5150
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10926, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10927, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10928, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10929, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10930, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2593
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10931, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4165
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10932, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.9771
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10933, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10934, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2248
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10935, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10936, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.2403
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10937, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10938, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0707
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10939, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10940, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2828
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10941, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10942, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10943, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10944, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10945, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5569
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10946, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10947, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.8061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10948, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10949, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10950, num samples collected 7000, FPS 35
  Algorithm: train_loss 1.3813
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10951, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10952, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4670
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10953, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1224
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10954, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3527
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10955, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3209
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10956, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10957, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10958, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0271
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10959, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10960, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3607
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10961, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.3437
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10962, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2585
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10963, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10964, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0557
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10965, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10966, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1718
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10967, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.6815
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10968, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10969, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10970, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10971, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.5071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10972, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.2243
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10973, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4918
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10974, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10975, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4297
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10976, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10977, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10978, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10979, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10980, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.4155
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10981, num samples collected 7000, FPS 35
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10982, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10983, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3286
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10984, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10985, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10986, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10987, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10988, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5708
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10989, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1398
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10990, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2388
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10991, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1860
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10992, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10993, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1647
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10994, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3715
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10995, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3668
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10996, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10997, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4806
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10998, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 10999, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3522
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11000, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7458
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11001, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11002, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1905
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11003, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.2779
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11004, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11005, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11006, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6925
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11007, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2558
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11008, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3047
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11009, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11010, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11011, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0296
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11012, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3095
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11013, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11014, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11015, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11016, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1262
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11017, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0992
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11018, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11019, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0440
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11020, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11021, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11022, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11023, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1196
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11024, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11025, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5960
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11026, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11027, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5480
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11028, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11029, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0503
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11030, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11031, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11032, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5666
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11033, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11034, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11035, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11036, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2221
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11037, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1642
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11038, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4298
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11039, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11040, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11041, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11042, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0847
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11043, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3635
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11044, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11045, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3668
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11046, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.1842
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11047, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0988
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11048, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9188
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11049, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5589
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11050, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11051, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11052, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11053, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5848
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11054, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11055, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11056, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6726
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11057, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4906
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11058, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11059, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11060, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11061, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1021
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11062, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11063, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11064, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8203
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11065, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5166
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11066, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2008
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11067, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11068, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11069, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11070, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11071, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11072, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.3027
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11073, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4275
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11074, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1287
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11075, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11076, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11077, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3459
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11078, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6384
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11079, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11080, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11081, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2630
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11082, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11083, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1964
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11084, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11085, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11086, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5398
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11087, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5822
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11088, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11089, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11090, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4551
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11091, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11092, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3495
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11093, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4109
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11094, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4959
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11095, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11096, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11097, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0409
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11098, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11099, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1847
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11100, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11101, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11102, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11103, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11104, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4740
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11105, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11106, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11107, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11108, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.3945
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11109, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1476
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11110, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11111, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11112, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11113, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11114, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11115, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7772
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11116, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6816
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11117, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1811
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11118, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11119, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.3019
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11120, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11121, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11122, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11123, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11124, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11125, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4816
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11126, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11127, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11128, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3317
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11129, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11130, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11131, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11132, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4390
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11133, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.7069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11134, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11135, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4170
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11136, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11137, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0882
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11138, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2678
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11139, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1985
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11140, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11141, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11142, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11143, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11144, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11145, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1267
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11146, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11147, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11148, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0495
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11149, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1413
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11150, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11151, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11152, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0516
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11153, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8159
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11154, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.6559
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11155, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5180
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11156, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11157, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11158, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3555
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11159, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1007
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11160, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11161, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11162, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11163, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5386
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11164, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11165, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3967
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11166, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11167, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9194
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11168, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4716
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11169, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0283
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11170, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11171, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11172, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11173, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11174, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11175, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2536
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11176, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11177, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0510
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11178, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11179, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11180, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11181, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.3520
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11182, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11183, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6954
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11184, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11185, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11186, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7689
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11187, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11188, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5966
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11189, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11190, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3183
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11191, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6194
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11192, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11193, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11194, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1725
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11195, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1499
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11196, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1644
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11197, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6761
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11198, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11199, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11200, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11201, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11202, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3940
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11203, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11204, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5325
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11205, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3254
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11206, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11207, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2880
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11208, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11209, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1484
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11210, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11211, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0513
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11212, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11213, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11214, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6862
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11215, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11216, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11217, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11218, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9603
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11219, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4139
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11220, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11221, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11222, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1648
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11223, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4181
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11224, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4840
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11225, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0256
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11226, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11227, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5978
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11228, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11229, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11230, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11231, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11232, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11233, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3697
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11234, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4594
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11235, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11236, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4803
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11237, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1160
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11238, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11239, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5459
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11240, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0635
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11241, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.1111
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11242, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3231
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11243, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8905
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11244, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11245, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11246, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0995
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11247, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11248, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2425
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11249, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11250, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.1142
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11251, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11252, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4270
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11253, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0247
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11254, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11255, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2813
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11256, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11257, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11258, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0847
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11259, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3215
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11260, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1269
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11261, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11262, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11263, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0535
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11264, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11265, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1864
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11266, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6474
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11267, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5871
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11268, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7880
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11269, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1994
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11270, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11271, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11272, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4231
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11273, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2016
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11274, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4988
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11275, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5258
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11276, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11277, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0642
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11278, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11279, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11280, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8296
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11281, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11282, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4914
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11283, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11284, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.2116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11285, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3417
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11286, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11287, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2586
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11288, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11289, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2679
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11290, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8587
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11291, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11292, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11293, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4600
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11294, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11295, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11296, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11297, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4637
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11298, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11299, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6141
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11300, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11301, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2955
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11302, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11303, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9703
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11304, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4779
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11305, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11306, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11307, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11308, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2444
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11309, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4668
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11310, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1252
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11311, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1975
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11312, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11313, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1917
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11314, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11315, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11316, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5276
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11317, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11318, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11319, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4683
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11320, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11321, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2701
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11322, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11323, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11324, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11325, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5011
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11326, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6925
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11327, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11328, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11329, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11330, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11331, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8530
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11332, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4571
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11333, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11334, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11335, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0469
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11336, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11337, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11338, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3804
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11339, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2726
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11340, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11341, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4853
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11342, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11343, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11344, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11345, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11346, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5732
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11347, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11348, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11349, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11350, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0356
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11351, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11352, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11353, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0303
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11354, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11355, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11356, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11357, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11358, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5658
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11359, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6868
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11360, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5338
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11361, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4454
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11362, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11363, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7601
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11364, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11365, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5928
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11366, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6711
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11367, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11368, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11369, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11370, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11371, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7199
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11372, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0831
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11373, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1521
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11374, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6773
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11375, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11376, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11377, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11378, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11379, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11380, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11381, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11382, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2590
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11383, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11384, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1636
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11385, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6670
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11386, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2842
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11387, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4352
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11388, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1484
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11389, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4326
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11390, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11391, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0041
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11392, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11393, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11394, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11395, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11396, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11397, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11398, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4792
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11399, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11400, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1137
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11401, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11402, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11403, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0501
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11404, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11405, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11406, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7844
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11407, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6249
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11408, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11409, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1983
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11410, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7751
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11411, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1980
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11412, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11413, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4223
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11414, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11415, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11416, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11417, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2168
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11418, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0452
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11419, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4955
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11420, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1227
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11421, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11422, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2534
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11423, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11424, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11425, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11426, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2605
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11427, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6826
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11428, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11429, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11430, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3029
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11431, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11432, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1982
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11433, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11434, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0930
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11435, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1492
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11436, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7239
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11437, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6180
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11438, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11439, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11440, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5939
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11441, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11442, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11443, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2421
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11444, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11445, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0322
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11446, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11447, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6030
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11448, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6312
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11449, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11450, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11451, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11452, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11453, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8460
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11454, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5331
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11455, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0596
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11456, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11457, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11458, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11459, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11460, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11461, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11462, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2526
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11463, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11464, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11465, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11466, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8792
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11467, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1925
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11468, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11469, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1454
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11470, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11471, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11472, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6698
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11473, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3141
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11474, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4850
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11475, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11476, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11477, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11478, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4917
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11479, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0022
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11480, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11481, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4036
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11482, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11483, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11484, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11485, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2824
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11486, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2757
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11487, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11488, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2638
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11489, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1038
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11490, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11491, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4555
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11492, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0536
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11493, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11494, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.6296
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11495, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11496, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11497, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3545
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11498, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2585
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11499, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11500, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5427
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11501, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0626
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11502, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1266
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11503, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11504, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11505, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11506, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0701
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11507, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5979
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11508, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5259
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11509, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3559
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11510, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0657
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11511, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11512, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8334
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11513, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0606
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11514, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9700
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11515, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11516, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11517, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11518, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11519, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11520, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11521, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0342
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11522, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4978
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11523, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8936
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11524, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1183
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11525, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0348
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11526, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11527, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3400
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11528, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11529, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11530, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11531, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11532, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1388
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11533, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11534, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5652
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11535, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1958
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11536, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3281
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11537, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11538, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3337
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11539, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11540, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0628
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11541, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4347
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11542, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11543, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11544, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1985
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11545, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11546, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11547, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11548, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6478
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11549, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11550, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3850
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11551, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11552, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2786
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11553, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11554, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1179
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11555, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5519
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11556, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6583
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11557, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3393
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11558, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6859
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11559, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3471
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11560, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4972
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11561, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4930
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11562, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11563, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11564, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11565, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2032
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11566, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2559
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11567, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11568, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11569, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1969
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11570, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11571, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6067
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11572, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11573, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11574, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11575, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6486
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11576, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11577, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11578, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9339
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11579, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0333
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11580, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11581, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2687
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11582, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2004
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11583, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5241
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11584, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3140
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11585, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1485
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11586, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11587, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11588, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2699
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11589, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11590, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8587
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11591, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6861
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11592, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11593, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1116
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11594, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11595, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11596, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0332
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11597, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11598, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2965
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11599, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4739
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11600, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11601, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11602, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11603, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8370
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11604, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11605, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.0575
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11606, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11607, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11608, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8650
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11609, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11610, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1360
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11611, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11612, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11613, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11614, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4954
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11615, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1971
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11616, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1745
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11617, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6796
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11618, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11619, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11620, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11621, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4686
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11622, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11623, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11624, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11625, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11626, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1962
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11627, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11628, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0418
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11629, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11630, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4206
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11631, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3684
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11632, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11633, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11634, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11635, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4204
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11636, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.2300
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11637, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6892
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11638, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11639, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2201
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11640, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11641, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2684
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11642, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2446
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11643, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11644, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11645, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11646, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11647, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.4134
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11648, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11649, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4839
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11650, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11651, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11652, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11653, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11654, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0455
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11655, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11656, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11657, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5705
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11658, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3235
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11659, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3273
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11660, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2460
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11661, num samples collected 7000, FPS 34
  Algorithm: train_loss 1.2475
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11662, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11663, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11664, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3401
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11665, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0599
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11666, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11667, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11668, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11669, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11670, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6936
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11671, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6600
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11672, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11673, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11674, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1965
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11675, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2506
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11676, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11677, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11678, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11679, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11680, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11681, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1162
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11682, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1033
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11683, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5597
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11684, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4112
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11685, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9232
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11686, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6575
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11687, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11688, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0634
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11689, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11690, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11691, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11692, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11693, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0860
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11694, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11695, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3244
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11696, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.9173
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11697, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11698, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5834
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11699, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8793
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11700, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1183
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11701, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11702, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11703, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1697
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11704, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11705, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11706, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11707, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4870
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11708, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0429
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11709, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5376
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11710, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11711, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11712, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3438
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11713, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1942
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11714, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4374
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11715, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2337
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11716, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11717, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11718, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4940
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11719, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11720, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11721, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5466
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11722, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7261
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11723, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6120
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11724, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11725, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.2564
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11726, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11727, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0400
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11728, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0635
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11729, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11730, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5748
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11731, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11732, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11733, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.8243
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11734, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4963
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11735, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4089
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11736, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11737, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11738, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4066
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11739, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3208
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11740, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0324
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11741, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.7144
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11742, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3106
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11743, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11744, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11745, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11746, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4972
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11747, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.3841
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11748, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11749, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11750, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11751, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0510
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11752, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1285
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11753, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11754, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0525
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11755, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.6776
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11756, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.5877
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11757, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11758, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11759, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.4272
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11760, num samples collected 7000, FPS 34
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1616.7013, l 200.0000, t 279.4929, TestReward -1677.2754
Update 11761, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.1027
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11762, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11763, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11764, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11765, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11766, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11767, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0292
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11768, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5576
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11769, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11770, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1579
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11771, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11772, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2375
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11773, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4490
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11774, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2442
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11775, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11776, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11777, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7782
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11778, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11779, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11780, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3386
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11781, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11782, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11783, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11784, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11785, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0696
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11786, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4669
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11787, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11788, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11789, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11790, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2733
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11791, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11792, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11793, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11794, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2031
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11795, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11796, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5190
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11797, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11798, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6858
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11799, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11800, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6972
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11801, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6190
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11802, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11803, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3179
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11804, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11805, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2703
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11806, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11807, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11808, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11809, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11810, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4354
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11811, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11812, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11813, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3892
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11814, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6446
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11815, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11816, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5043
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11817, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11818, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11819, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11820, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11821, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1177
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11822, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6749
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11823, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.3679
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11824, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5455
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11825, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1698
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11826, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3570
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11827, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1684
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11828, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11829, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11830, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0486
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11831, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3904
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11832, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11833, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11834, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11835, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11836, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7030
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11837, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11838, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1681
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11839, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11840, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7327
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11841, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1509
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11842, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11843, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11844, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11845, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11846, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1739
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11847, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6004
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11848, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11849, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3390
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11850, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11851, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11852, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11853, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11854, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4253
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11855, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5382
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11856, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11857, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11858, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11859, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2221
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11860, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11861, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1159
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11862, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0547
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11863, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2975
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11864, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11865, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1706
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11866, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3141
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11867, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8806
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11868, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11869, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11870, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0318
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11871, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11872, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11873, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11874, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11875, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5471
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11876, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.9304
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11877, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7718
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11878, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3947
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11879, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1319
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11880, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1935
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11881, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11882, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11883, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4286
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11884, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4916
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11885, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0624
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11886, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5672
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11887, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6804
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11888, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1512
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11889, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0873
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11890, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5726
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11891, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11892, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11893, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1928
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11894, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11895, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11896, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11897, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4709
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11898, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1321
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11899, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11900, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5699
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11901, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3209
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11902, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0474
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11903, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0309
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11904, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11905, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11906, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11907, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11908, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11909, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4334
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11910, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6920
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11911, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11912, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6447
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11913, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2792
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11914, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0674
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11915, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11916, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11917, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11918, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2640
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11919, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4602
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11920, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11921, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11922, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11923, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11924, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11925, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11926, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11927, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6235
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11928, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11929, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5486
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11930, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11931, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.1469
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11932, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11933, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5527
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11934, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4556
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11935, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4899
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11936, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11937, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11938, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2044
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11939, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11940, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0545
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11941, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4162
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11942, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11943, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11944, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1569
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11945, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3652
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11946, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11947, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2570
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11948, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1216
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11949, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5860
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11950, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0838
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11951, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11952, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1150
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11953, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11954, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11955, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11956, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9322
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11957, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11958, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7919
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11959, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9554
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11960, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2370
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11961, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11962, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2115
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11963, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0304
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11964, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11965, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4990
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11966, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6021
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11967, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6895
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11968, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0605
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11969, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2420
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11970, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11971, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4126
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11972, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1321
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11973, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11974, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4271
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11975, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11976, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11977, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2385
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11978, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11979, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11980, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7461
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11981, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1529
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11982, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11983, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4215
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11984, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11985, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11986, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11987, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1764
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11988, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11989, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9905
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11990, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5856
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11991, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11992, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11993, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1973
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11994, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11995, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11996, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0946
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11997, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11998, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 11999, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2001
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12000, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2847
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12001, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12002, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5326
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12003, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12004, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0291
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12005, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1305
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12006, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4238
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12007, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4258
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12008, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12009, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12010, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12011, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4983
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12012, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1920
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12013, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6259
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12014, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12015, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12016, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2765
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12017, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12018, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.2064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12019, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3915
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12020, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3495
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12021, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12022, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3717
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12023, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2550
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12024, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12025, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12026, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12027, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1894
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12028, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12029, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12030, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12031, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12032, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1358
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12033, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0286
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12034, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4593
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12035, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6753
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12036, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12037, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5588
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12038, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3965
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12039, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12040, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4923
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12041, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12042, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12043, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2588
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12044, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12045, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12046, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2545
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12047, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3879
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12048, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0275
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12049, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12050, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12051, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12052, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12053, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2431
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12054, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3383
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12055, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7731
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12056, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1999
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12057, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1645
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12058, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12059, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12060, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4332
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12061, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12062, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12063, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2655
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12064, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1968
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12065, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12066, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4173
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12067, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8007
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12068, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12069, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12070, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12071, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12072, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12073, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4852
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12074, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4977
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12075, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4897
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12076, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5526
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12077, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1169
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12078, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2028
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12079, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12080, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12081, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12082, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6119
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12083, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12084, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7295
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12085, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6450
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12086, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4355
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12087, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12088, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3053
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12089, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12090, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12091, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12092, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12093, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12094, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2654
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12095, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12096, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12097, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12098, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2115
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12099, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12100, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7025
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12101, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12102, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2433
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12103, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12104, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12105, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9821
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12106, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12107, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12108, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12109, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12110, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12111, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5879
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12112, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12113, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12114, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12115, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12116, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5645
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12117, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12118, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12119, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12120, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12121, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12122, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3896
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12123, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.1494
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12124, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12125, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2812
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12126, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2594
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12127, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12128, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3164
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12129, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12130, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12131, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12132, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12133, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12134, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.3273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12135, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3312
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12136, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1224
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12137, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12138, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4600
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12139, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12140, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5215
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12141, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12142, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12143, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12144, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12145, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1474
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12146, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12147, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12148, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6338
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12149, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12150, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1341
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12151, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12152, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0867
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12153, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5495
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12154, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12155, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2916
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12156, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9557
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12157, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12158, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2747
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12159, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12160, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1316
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12161, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12162, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2043
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12163, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6996
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12164, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12165, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.2013
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12166, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12167, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0562
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12168, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12169, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12170, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3158
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12171, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.2814
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12172, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12173, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12174, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12175, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2779
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12176, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3427
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12177, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5841
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12178, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12179, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12180, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3790
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12181, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9647
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12182, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2005
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12183, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3519
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12184, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12185, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4847
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12186, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3819
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12187, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12188, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12189, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12190, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12191, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1339
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12192, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12193, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12194, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12195, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12196, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12197, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12198, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4345
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12199, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3443
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12200, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12201, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2967
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12202, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8409
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12203, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2231
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12204, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5012
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12205, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0875
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12206, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2710
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12207, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12208, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12209, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12210, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2266
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12211, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12212, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12213, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12214, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7030
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12215, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12216, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6637
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12217, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12218, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12219, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12220, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7284
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12221, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12222, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12223, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7286
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12224, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12225, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12226, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12227, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12228, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8252
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12229, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12230, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12231, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12232, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4205
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12233, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12234, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1442
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12235, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0637
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12236, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12237, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7566
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12238, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6785
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12239, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12240, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2890
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12241, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12242, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12243, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1936
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12244, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2731
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12245, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5126
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12246, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12247, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12248, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12249, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3937
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12250, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2938
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12251, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8866
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12252, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12253, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12254, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12255, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12256, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1958
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12257, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12258, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12259, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12260, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1235
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12261, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6502
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12262, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4577
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12263, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9474
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12264, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2753
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12265, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12266, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12267, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12268, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4582
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12269, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0971
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12270, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0360
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12271, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12272, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4835
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12273, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12274, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12275, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12276, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12277, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8650
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12278, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12279, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6679
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12280, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12281, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0355
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12282, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12283, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5757
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12284, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12285, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1725
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12286, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4169
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12287, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12288, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1973
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12289, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5582
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12290, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2010
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12291, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12292, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12293, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5177
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12294, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12295, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12296, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12297, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12298, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4647
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12299, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12300, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12301, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12302, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12303, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7595
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12304, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8218
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12305, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12306, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12307, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1034
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12308, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1565
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12309, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5913
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12310, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1318
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12311, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12312, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12313, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1253
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12314, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12315, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12316, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12317, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12318, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0881
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12319, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12320, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3034
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12321, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6797
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12322, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12323, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5585
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12324, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12325, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12326, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4173
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12327, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12328, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12329, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0497
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12330, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12331, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3674
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12332, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2981
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12333, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12334, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12335, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0152
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12336, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0605
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12337, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4919
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12338, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12339, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3626
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12340, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12341, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0242
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12342, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12343, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12344, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12345, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12346, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2324
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12347, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12348, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2201
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12349, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3919
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12350, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6627
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12351, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8960
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12352, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.2142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12353, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12354, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12355, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1702
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12356, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5676
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12357, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12358, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1940
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12359, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12360, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12361, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12362, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0874
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12363, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1266
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12364, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12365, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12366, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12367, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5249
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12368, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12369, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12370, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12371, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1282
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12372, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12373, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12374, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12375, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12376, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6954
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12377, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5410
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12378, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1873
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12379, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1281
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12380, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12381, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12382, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2012
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12383, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12384, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2725
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12385, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0613
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12386, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4997
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12387, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12388, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7724
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12389, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0435
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12390, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12391, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2585
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12392, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0394
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12393, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12394, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12395, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12396, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4739
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12397, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4098
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12398, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12399, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12400, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12401, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2439
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12402, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.1326
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12403, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3198
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12404, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12405, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4249
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12406, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12407, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4242
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12408, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5784
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12409, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2403
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12410, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12411, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12412, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0259
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12413, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12414, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4465
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12415, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1539
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12416, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2822
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12417, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0642
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12418, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4671
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12419, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12420, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1382
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12421, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0888
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12422, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12423, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6390
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12424, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4950
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12425, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12426, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12427, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12428, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4362
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12429, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0833
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12430, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8402
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12431, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12432, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1128
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12433, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1739
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12434, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12435, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12436, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3759
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12437, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4729
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12438, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2004
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12439, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12440, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12441, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2686
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12442, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12443, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4360
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12444, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2467
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12445, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12446, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12447, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0438
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12448, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12449, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3623
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12450, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.1057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12451, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12452, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12453, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0837
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12454, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3537
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12455, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4806
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12456, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0194
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12457, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6182
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12458, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4380
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12459, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7241
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12460, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3279
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12461, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12462, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12463, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12464, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12465, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4421
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12466, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12467, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12468, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12469, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12470, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2649
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12471, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12472, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1311
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12473, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6911
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12474, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2409
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12475, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12476, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4507
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12477, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12478, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2418
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12479, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3707
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12480, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4271
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12481, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4440
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12482, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12483, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12484, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5768
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12485, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3808
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12486, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3373
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12487, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12488, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4253
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12489, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4761
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12490, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12491, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12492, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12493, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0882
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12494, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12495, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12496, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12497, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12498, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4735
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12499, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12500, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12501, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8382
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12502, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2577
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12503, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12504, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12505, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12506, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0932
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12507, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7010
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12508, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4958
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12509, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5514
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12510, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0304
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12511, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2966
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12512, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12513, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0610
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12514, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0325
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12515, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12516, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12517, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3345
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12518, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12519, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2010
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12520, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4810
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12521, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0290
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12522, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6021
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12523, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12524, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12525, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12526, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12527, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2461
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12528, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12529, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4687
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12530, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12531, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12532, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.7039
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12533, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12534, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3683
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12535, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12536, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12537, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12538, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12539, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12540, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12541, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6401
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12542, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12543, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12544, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12545, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2695
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12546, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4995
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12547, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0858
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12548, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2040
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12549, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12550, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12551, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12552, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5263
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12553, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12554, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3773
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12555, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12556, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.9610
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12557, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12558, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12559, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5782
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12560, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2388
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12561, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3887
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12562, num samples collected 7250, FPS 32
  Algorithm: train_loss 1.0326
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12563, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12564, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5797
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12565, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5884
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12566, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0267
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12567, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12568, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12569, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12570, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12571, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12572, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2222
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12573, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4822
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12574, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12575, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.3037
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12576, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0679
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12577, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12578, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12579, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12580, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12581, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12582, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1693
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12583, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.2243
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12584, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.5373
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12585, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0514
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12586, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12587, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12588, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.4377
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12589, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.8646
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12590, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12591, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12592, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12593, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.6925
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12594, num samples collected 7250, FPS 32
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12595, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4227
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12596, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3947
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12597, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12598, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12599, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12600, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4425
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12601, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3833
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12602, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12603, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12604, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3749
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12605, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7345
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12606, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1899
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12607, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5874
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12608, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12609, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3444
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12610, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12611, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12612, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12613, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12614, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12615, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2700
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12616, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12617, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12618, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12619, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4382
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12620, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3671
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12621, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12622, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12623, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12624, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7439
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12625, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12626, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12627, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4837
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12628, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12629, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12630, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12631, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12632, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12633, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0363
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12634, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12635, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12636, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0568
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12637, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6946
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12638, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6404
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12639, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12640, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12641, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12642, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1925
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12643, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12644, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8949
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12645, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2645
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12646, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2842
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12647, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1501
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12648, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7883
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12649, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12650, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3848
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12651, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4602
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12652, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12653, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12654, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4255
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12655, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2685
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12656, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3803
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12657, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4845
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12658, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1287
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12659, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12660, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2766
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12661, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1919
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12662, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1427
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12663, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3147
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12664, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12665, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6879
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12666, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6554
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12667, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4749
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12668, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2036
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12669, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12670, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12671, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12672, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12673, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2114
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12674, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6983
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12675, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7333
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12676, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0609
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12677, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12678, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2432
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12679, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12680, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12681, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12682, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5877
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12683, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2659
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12684, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12685, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12686, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0294
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12687, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2826
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12688, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5265
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12689, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12690, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12691, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8753
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12692, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12693, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.1877
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12694, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12695, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12696, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3502
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12697, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0308
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12698, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0305
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12699, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12700, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1350
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12701, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12702, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3654
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12703, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12704, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12705, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2966
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12706, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12707, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2406
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12708, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0371
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12709, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12710, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12711, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0537
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12712, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12713, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1923
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12714, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12715, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0887
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12716, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1610
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12717, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5232
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12718, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12719, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12720, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2819
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12721, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1932
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12722, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0211
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12723, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12724, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1154
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12725, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12726, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12727, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12728, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0802
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12729, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12730, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2861
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12731, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9679
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12732, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12733, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7464
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12734, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12735, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12736, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12737, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5817
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12738, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12739, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12740, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5523
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12741, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12742, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12743, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4537
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12744, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12745, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2041
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12746, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12747, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12748, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12749, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3238
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12750, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1254
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12751, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3895
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12752, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12753, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1375
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12754, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12755, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4770
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12756, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12757, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4912
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12758, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2239
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12759, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2890
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12760, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0912
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12761, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12762, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6167
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12763, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12764, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0590
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12765, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3279
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12766, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0300
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12767, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12768, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4190
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12769, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2961
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12770, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12771, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0213
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12772, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12773, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6663
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12774, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12775, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12776, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3531
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12777, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12778, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3962
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12779, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12780, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1304
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12781, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12782, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12783, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2016
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12784, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1961
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12785, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8332
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12786, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3614
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12787, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12788, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12789, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8571
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12790, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12791, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12792, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4297
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12793, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12794, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12795, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12796, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12797, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12798, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4144
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12799, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3467
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12800, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12801, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4838
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12802, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12803, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4507
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12804, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12805, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1642
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12806, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12807, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7174
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12808, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12809, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12810, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12811, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12812, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12813, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12814, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12815, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12816, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12817, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2018
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12818, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12819, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5282
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12820, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12821, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6499
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12822, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4335
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12823, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12824, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12825, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5262
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12826, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12827, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12828, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12829, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1556
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12830, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6496
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12831, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12832, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4826
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12833, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12834, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6650
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12835, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12836, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12837, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2368
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12838, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12839, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12840, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12841, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12842, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12843, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12844, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4644
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12845, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1184
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12846, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12847, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12848, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1714
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12849, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12850, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12851, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9374
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12852, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12853, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1504
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12854, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12855, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12856, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2740
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12857, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6192
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12858, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12859, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1689
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12860, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8022
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12861, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4364
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12862, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.8107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12863, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0901
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12864, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2543
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12865, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1639
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12866, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12867, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12868, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12869, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1103
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12870, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3008
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12871, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12872, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8791
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12873, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12874, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1197
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12875, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0947
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12876, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12877, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2158
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12878, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12879, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8221
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12880, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2782
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12881, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12882, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12883, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12884, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12885, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3209
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12886, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12887, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4290
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12888, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1909
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12889, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12890, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12891, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.9038
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12892, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12893, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12894, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1408
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12895, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8677
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12896, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0605
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12897, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12898, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12899, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0229
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12900, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5826
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12901, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12902, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2143
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12903, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12904, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12905, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12906, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12907, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1177
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12908, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12909, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4908
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12910, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4674
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12911, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12912, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4872
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12913, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4337
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12914, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12915, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12916, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0429
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12917, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12918, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12919, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0248
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12920, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12921, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12922, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12923, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1186
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12924, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12925, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2798
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12926, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12927, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12928, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12929, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12930, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12931, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1927
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12932, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8201
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12933, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1293
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12934, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12935, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4329
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12936, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3544
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12937, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12938, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12939, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12940, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12941, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12942, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0877
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12943, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12944, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0598
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12945, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12946, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12947, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12948, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9243
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12949, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12950, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12951, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12952, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12953, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7786
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12954, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3637
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12955, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6815
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12956, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4195
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12957, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12958, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12959, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2103
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12960, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12961, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6402
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12962, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4404
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12963, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12964, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12965, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4986
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12966, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12967, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6609
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12968, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12969, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12970, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0862
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12971, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12972, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12973, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12974, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4378
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12975, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2144
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12976, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12977, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2250
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12978, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3794
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12979, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3597
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12980, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0698
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12981, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0076
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12982, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12983, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12984, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0469
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12985, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6845
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12986, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12987, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2490
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12988, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12989, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12990, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1225
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12991, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7845
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12992, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12993, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12994, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1498
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12995, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12996, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12997, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12998, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1964
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 12999, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13000, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13001, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13002, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13003, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13004, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1276
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13005, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13006, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13007, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1485
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13008, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13009, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1642
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13010, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0522
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13011, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0828
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13012, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13013, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1712
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13014, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0337
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13015, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13016, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13017, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8198
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13018, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13019, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6801
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13020, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3502
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13021, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5018
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13022, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5173
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13023, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4599
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13024, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1597
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13025, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13026, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13027, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8632
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13028, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13029, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13030, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13031, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13032, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13033, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5418
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13034, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13035, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13036, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.3050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13037, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13038, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13039, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6870
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13040, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13041, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13042, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3481
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13043, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6965
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13044, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13045, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13046, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13047, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2149
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13048, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13049, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13050, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13051, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13052, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13053, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5017
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13054, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3453
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13055, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13056, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3131
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13057, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4438
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13058, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0543
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13059, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0884
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13060, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13061, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13062, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13063, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5352
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13064, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5310
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13065, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6284
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13066, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13067, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6490
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13068, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13069, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13070, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13071, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0256
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13072, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3497
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13073, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13074, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13075, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5738
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13076, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13077, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1115
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13078, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13079, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13080, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1253
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13081, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13082, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4741
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13083, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1461
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13084, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6943
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13085, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2448
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13086, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4942
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13087, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13088, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2993
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13089, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13090, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.4275
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13091, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13092, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13093, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13094, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2636
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13095, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4453
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13096, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0582
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13097, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13098, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13099, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13100, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13101, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6451
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13102, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2012
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13103, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13104, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13105, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13106, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0448
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13107, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13108, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1668
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13109, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13110, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2247
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13111, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13112, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6808
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13113, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2005
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13114, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9590
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13115, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13116, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13117, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13118, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3061
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13119, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4216
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13120, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4333
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13121, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1219
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13122, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13123, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0581
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13124, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5214
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13125, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13126, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2353
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13127, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4592
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13128, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4607
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13129, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13130, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13131, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0672
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13132, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5153
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13133, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13134, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0880
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13135, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2594
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13136, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4915
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13137, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3996
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13138, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2683
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13139, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13140, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1982
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13141, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13142, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13143, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2034
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13144, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13145, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6687
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13146, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13147, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13148, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0515
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13149, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13150, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6815
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13151, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13152, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13153, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13154, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13155, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13156, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13157, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6999
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13158, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13159, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2787
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13160, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13161, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13162, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13163, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4608
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13164, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3814
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13165, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13166, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13167, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13168, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0230
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13169, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13170, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13171, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2060
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13172, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.1080
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13173, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13174, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7716
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13175, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13176, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1009
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13177, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13178, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2565
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13179, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6143
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13180, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3733
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13181, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13182, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13183, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5822
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13184, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4212
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13185, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13186, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4335
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13187, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4241
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13188, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13189, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13190, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13191, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5022
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13192, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2413
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13193, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13194, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1526
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13195, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6887
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13196, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1187
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13197, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2498
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13198, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8642
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13199, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13200, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13201, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13202, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1229
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13203, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13204, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13205, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13206, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4961
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13207, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3973
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13208, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13209, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13210, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0499
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13211, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13212, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7132
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13213, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13214, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4744
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13215, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7221
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13216, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13217, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0699
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13218, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13219, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2105
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13220, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0936
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13221, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3577
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13222, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0654
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13223, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1240
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13224, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13225, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13226, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13227, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13228, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4221
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13229, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4399
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13230, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4315
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13231, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13232, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8405
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13233, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13234, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1773
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13235, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4397
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13236, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6635
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13237, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13238, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1207
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13239, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13240, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13241, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13242, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13243, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0542
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13244, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13245, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13246, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13247, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0849
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13248, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8707
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13249, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3942
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13250, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13251, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13252, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3621
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13253, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13254, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13255, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13256, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2533
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13257, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0796
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13258, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13259, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7526
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13260, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5344
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13261, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13262, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0311
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13263, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5248
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13264, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13265, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1633
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13266, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13267, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13268, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13269, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13270, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8000
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13271, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0632
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13272, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13273, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0313
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13274, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8256
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13275, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0516
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13276, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13277, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6260
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13278, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2025
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13279, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7754
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13280, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2411
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13281, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13282, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13283, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13284, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0425
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13285, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13286, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13287, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13288, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13289, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13290, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5633
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13291, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13292, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13293, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13294, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6512
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13295, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3324
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13296, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13297, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13298, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6930
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13299, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13300, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13301, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13302, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3101
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13303, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4878
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13304, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13305, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13306, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0847
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13307, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13308, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13309, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2012
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13310, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0299
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13311, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5911
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13312, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4831
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13313, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13314, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13315, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8563
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13316, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5174
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13317, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8290
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13318, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0348
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13319, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13320, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3801
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13321, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4963
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13322, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13323, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13324, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13325, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13326, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13327, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13328, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13329, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4521
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13330, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0275
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13331, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13332, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2885
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13333, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0611
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13334, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5032
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13335, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4459
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13336, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13337, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0989
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13338, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13339, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1651
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13340, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13341, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1548
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13342, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13343, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6416
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13344, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13345, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13346, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1769
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13347, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13348, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2199
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13349, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4354
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13350, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1180
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13351, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8964
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13352, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9923
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13353, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3840
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13354, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13355, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13356, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1322
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13357, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0593
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13358, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13359, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7194
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13360, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0209
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13361, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4138
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13362, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13363, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3956
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13364, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13365, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4904
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13366, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3367
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13367, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13368, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13369, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13370, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13371, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13372, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0427
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13373, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2516
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13374, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1949
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13375, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13376, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.4038
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13377, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.0819
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13378, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0225
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13379, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2009
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13380, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13381, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1666
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13382, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0620
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13383, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13384, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13385, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13386, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13387, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6496
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13388, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4743
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13389, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13390, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13391, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13392, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4572
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13393, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4817
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13394, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13395, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3720
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13396, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5472
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13397, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13398, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13399, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6988
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13400, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13401, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5967
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13402, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13403, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13404, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1190
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13405, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13406, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0611
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13407, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13408, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13409, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3034
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13410, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13411, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1980
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13412, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.7779
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13413, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5825
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13414, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1933
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13415, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8994
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13416, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4134
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13417, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3279
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13418, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13419, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13420, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13421, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13422, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13423, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13424, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4229
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13425, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13426, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13427, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13428, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13429, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13430, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4372
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13431, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4961
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13432, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13433, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5749
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13434, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3573
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13435, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5543
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13436, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13437, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4625
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13438, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5363
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13439, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2919
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13440, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13441, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1371
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13442, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13443, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13444, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0845
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13445, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4327
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13446, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5011
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13447, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13448, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4322
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13449, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0638
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13450, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13451, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1201
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13452, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.8835
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13453, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3443
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13454, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3153
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13455, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13456, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13457, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1504
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13458, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13459, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6499
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13460, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13461, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13462, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13463, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9026
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13464, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0337
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13465, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13466, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5639
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13467, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2452
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13468, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13469, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1325
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13470, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2385
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13471, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3542
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13472, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.9013
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13473, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0239
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13474, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13475, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13476, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3414
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13477, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13478, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13479, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1038
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13480, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2406
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13481, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0887
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13482, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.3055
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13483, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13484, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13485, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13486, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.4309
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13487, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6056
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13488, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13489, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13490, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0272
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13491, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13492, num samples collected 7250, FPS 31
  Algorithm: train_loss 1.3768
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13493, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13494, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.2064
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13495, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.6768
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13496, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13497, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13498, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13499, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.5050
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13500, num samples collected 7250, FPS 31
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1738.3372, l 200.0000, t 307.1819, TestReward -1694.2481
Update 13501, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13502, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2043
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13503, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2552
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13504, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1698
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13505, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13506, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13507, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13508, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13509, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13510, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13511, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.8547
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13512, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1962
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13513, num samples collected 7500, FPS 30
  Algorithm: train_loss 1.1845
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13514, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0461
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13515, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0503
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13516, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13517, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6196
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13518, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1562
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13519, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3678
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13520, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13521, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2893
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13522, num samples collected 7500, FPS 30
  Algorithm: train_loss 1.0310
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13523, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13524, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13525, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6410
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13526, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13527, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2213
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13528, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2728
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13529, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13530, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13531, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1979
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13532, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2542
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13533, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6792
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13534, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13535, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13536, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4673
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13537, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13538, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13539, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0739
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13540, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6720
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13541, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13542, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6519
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13543, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0906
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13544, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4811
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13545, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.8378
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13546, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13547, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13548, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4205
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13549, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13550, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0254
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13551, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13552, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2853
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13553, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13554, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13555, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3233
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13556, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13557, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.9268
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13558, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13559, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13560, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13561, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13562, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13563, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13564, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.5393
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13565, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1924
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13566, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4258
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13567, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13568, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3691
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13569, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13570, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13571, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0471
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13572, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0873
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13573, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3241
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13574, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13575, num samples collected 7500, FPS 30
  Algorithm: train_loss 1.1325
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13576, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13577, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.7762
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13578, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3472
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13579, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6048
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13580, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2914
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13581, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13582, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.7601
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13583, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2634
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13584, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13585, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13586, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13587, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13588, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13589, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13590, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13591, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13592, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13593, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.9936
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13594, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13595, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0921
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13596, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13597, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13598, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13599, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6166
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13600, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.7317
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13601, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13602, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13603, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13604, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4263
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13605, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13606, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13607, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13608, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.6197
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13609, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0270
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13610, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13611, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13612, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13613, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.3611
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13614, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13615, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.9360
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13616, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13617, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13618, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13619, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13620, num samples collected 7500, FPS 30
  Algorithm: train_loss 1.8056
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13621, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13622, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4964
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13623, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.4004
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13624, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13625, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2025
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13626, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13627, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13628, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.1112
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13629, num samples collected 7500, FPS 30
  Algorithm: train_loss 0.2010
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13630, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3438
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13631, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13632, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13633, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13634, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4872
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13635, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13636, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1677
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13637, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4821
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13638, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4748
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13639, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7468
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13640, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13641, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13642, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13643, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8290
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13644, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7491
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13645, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6698
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13646, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13647, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13648, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13649, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13650, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13651, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13652, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1549
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13653, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13654, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13655, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5848
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13656, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13657, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7842
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13658, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13659, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1029
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13660, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2188
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13661, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3883
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13662, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4924
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13663, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13664, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3305
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13665, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7992
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13666, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13667, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13668, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5137
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13669, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13670, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13671, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13672, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13673, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13674, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13675, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0367
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13676, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3700
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13677, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6648
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13678, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0428
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13679, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1425
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13680, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5528
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13681, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4042
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13682, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2202
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13683, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13684, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13685, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13686, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13687, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13688, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13689, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2215
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13690, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0838
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13691, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6884
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13692, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5462
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13693, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13694, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1950
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13695, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13696, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.5627
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13697, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5154
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13698, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13699, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0246
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13700, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13701, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13702, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4367
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13703, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13704, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13705, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8756
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13706, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13707, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13708, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13709, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1438
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13710, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0032
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13711, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13712, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0593
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13713, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13714, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13715, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13716, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2491
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13717, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13718, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1494
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13719, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0032
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13720, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2416
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13721, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5268
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13722, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13723, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2451
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13724, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13725, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5273
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13726, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4796
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13727, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13728, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13729, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13730, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2867
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13731, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7387
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13732, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13733, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13734, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13735, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13736, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13737, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3154
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13738, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13739, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6943
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13740, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13741, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7893
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13742, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4395
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13743, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13744, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13745, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6837
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13746, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13747, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13748, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13749, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9185
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13750, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5108
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13751, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13752, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0283
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13753, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13754, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13755, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2481
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13756, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13757, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4039
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13758, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0316
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13759, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2724
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13760, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2622
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13761, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13762, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13763, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13764, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13765, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8574
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13766, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4347
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13767, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0581
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13768, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13769, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13770, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0018
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13771, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13772, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13773, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5772
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13774, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2900
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13775, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0429
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13776, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13777, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2209
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13778, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13779, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2031
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13780, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13781, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0874
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13782, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13783, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13784, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13785, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13786, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13787, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13788, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3842
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13789, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3602
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13790, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2464
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13791, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4568
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13792, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7510
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13793, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13794, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13795, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5964
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13796, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13797, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13798, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7760
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13799, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7349
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13800, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13801, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13802, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.0046
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13803, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13804, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4520
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13805, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13806, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3258
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13807, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13808, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13809, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13810, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8143
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13811, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2905
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13812, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3150
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13813, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13814, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13815, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13816, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13817, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4673
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13818, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13819, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13820, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13821, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13822, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13823, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13824, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13825, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1983
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13826, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13827, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13828, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1530
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13829, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4416
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13830, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13831, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2835
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13832, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13833, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.3429
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13834, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3459
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13835, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7283
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13836, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0616
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13837, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13838, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6852
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13839, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13840, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13841, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2502
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13842, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13843, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13844, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13845, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13846, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2223
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13847, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1763
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13848, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13849, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2691
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13850, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13851, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13852, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5422
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13853, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0627
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13854, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13855, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3755
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13856, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0246
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13857, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13858, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4274
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13859, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13860, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13861, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1549
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13862, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7507
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13863, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13864, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13865, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9218
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13866, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0844
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13867, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13868, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1947
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13869, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13870, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3294
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13871, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0229
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13872, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6013
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13873, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13874, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3923
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13875, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13876, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4295
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13877, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13878, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13879, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13880, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13881, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.3649
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13882, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2553
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13883, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13884, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0255
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13885, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13886, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13887, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4403
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13888, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13889, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3461
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13890, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13891, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13892, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4159
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13893, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13894, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13895, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13896, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2485
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13897, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13898, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13899, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4758
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13900, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1349
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13901, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13902, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13903, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7052
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13904, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13905, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13906, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13907, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0397
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13908, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7411
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13909, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13910, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4332
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13911, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13912, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13913, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13914, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2631
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13915, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6242
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13916, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13917, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3462
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13918, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5639
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13919, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13920, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13921, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13922, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2161
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13923, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0956
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13924, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13925, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2521
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13926, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13927, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13928, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13929, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13930, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13931, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3762
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13932, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13933, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13934, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13935, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13936, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.3628
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13937, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13938, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13939, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13940, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7792
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13941, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7760
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13942, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13943, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2722
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13944, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2451
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13945, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4183
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13946, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1260
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13947, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13948, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13949, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2594
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13950, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13951, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13952, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1174
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13953, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13954, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13955, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13956, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2005
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13957, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13958, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4296
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13959, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5637
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13960, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13961, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4652
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13962, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13963, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7870
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13964, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0607
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13965, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13966, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1710
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13967, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13968, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13969, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13970, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3476
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13971, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7914
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13972, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13973, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13974, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0480
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13975, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0866
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13976, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1578
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13977, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13978, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4914
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13979, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13980, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13981, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13982, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3431
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13983, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13984, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13985, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2324
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13986, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13987, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13988, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13989, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13990, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1622
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13991, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7048
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13992, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5128
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13993, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2965
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13994, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13995, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13996, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2911
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13997, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0806
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13998, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1047
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 13999, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14000, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4198
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14001, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4809
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14002, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4216
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14003, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14004, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14005, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4913
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14006, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1341
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14007, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14008, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14009, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8747
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14010, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0693
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14011, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5935
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14012, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1761
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14013, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14014, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2048
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14015, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14016, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14017, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0735
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14018, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6379
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14019, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6235
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14020, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14021, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14022, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1501
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14023, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14024, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14025, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14026, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14027, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2776
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14028, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14029, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14030, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14031, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4723
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14032, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4897
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14033, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14034, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8247
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14035, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9825
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14036, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14037, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14038, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14039, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2478
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14040, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14041, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1968
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14042, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14043, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14044, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14045, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14046, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7414
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14047, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14048, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14049, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14050, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14051, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1561
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14052, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2044
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14053, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4264
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14054, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0968
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14055, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14056, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14057, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14058, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5822
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14059, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4197
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14060, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14061, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14062, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5157
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14063, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6689
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14064, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1336
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14065, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14066, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3659
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14067, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14068, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6713
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14069, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14070, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3790
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14071, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14072, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3743
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14073, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2401
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14074, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14075, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5263
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14076, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2293
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14077, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1615
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14078, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14079, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6977
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14080, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14081, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7136
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14082, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14083, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14084, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14085, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14086, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14087, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1038
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14088, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14089, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6890
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14090, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2780
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14091, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14092, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2456
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14093, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4581
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14094, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14095, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7451
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14096, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6226
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14097, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1610
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14098, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14099, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14100, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14101, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0774
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14102, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14103, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5214
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14104, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14105, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14106, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1941
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14107, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14108, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14109, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8383
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14110, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14111, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4237
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14112, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14113, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14114, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14115, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2277
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14116, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14117, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6731
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14118, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6209
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14119, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14120, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14121, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14122, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4259
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14123, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5281
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14124, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14125, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14126, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5581
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14127, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14128, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2474
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14129, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3781
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14130, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14131, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2099
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14132, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1758
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14133, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14134, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1574
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14135, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14136, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14137, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14138, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14139, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2052
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14140, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9141
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14141, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14142, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14143, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4586
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14144, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6219
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14145, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14146, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14147, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4682
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14148, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0571
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14149, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2466
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14150, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14151, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14152, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14153, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8138
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14154, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14155, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7797
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14156, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14157, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5921
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14158, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5750
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14159, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14160, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0725
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14161, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14162, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14163, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14164, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1961
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14165, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14166, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0967
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14167, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1915
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14168, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4616
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14169, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5383
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14170, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14171, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14172, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14173, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1458
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14174, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14175, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14176, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1563
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14177, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14178, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14179, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8622
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14180, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14181, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7970
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14182, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3902
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14183, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14184, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6215
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14185, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2398
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14186, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14187, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3547
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14188, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14189, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14190, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14191, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8413
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14192, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14193, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3022
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14194, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14195, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5689
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14196, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14197, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14198, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1813
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14199, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14200, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14201, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0535
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14202, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4640
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14203, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4578
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14204, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14205, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3663
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14206, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0451
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14207, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14208, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14209, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4901
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14210, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14211, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14212, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0858
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14213, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3129
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14214, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4223
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14215, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14216, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14217, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2050
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14218, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8508
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14219, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14220, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14221, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4591
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14222, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2351
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14223, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14224, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1225
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14225, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2489
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14226, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14227, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14228, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14229, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3912
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14230, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5087
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14231, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4303
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14232, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0539
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14233, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14234, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14235, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1541
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14236, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14237, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1980
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14238, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4897
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14239, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14240, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14241, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14242, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4711
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14243, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14244, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1304
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14245, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14246, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3559
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14247, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14248, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14249, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14250, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6786
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14251, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1957
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14252, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14253, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7020
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14254, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14255, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14256, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14257, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2392
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14258, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0303
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14259, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14260, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14261, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14262, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4249
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14263, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2841
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14264, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2912
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14265, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14266, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2715
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14267, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14268, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1686
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14269, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9087
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14270, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14271, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1553
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14272, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0840
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14273, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14274, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14275, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14276, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14277, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14278, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2245
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14279, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9153
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14280, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14281, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5044
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14282, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14283, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14284, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14285, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4809
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14286, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6216
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14287, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0286
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14288, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6200
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14289, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0940
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14290, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14291, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2043
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14292, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6319
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14293, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2480
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14294, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14295, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0657
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14296, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6985
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14297, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14298, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14299, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14300, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3564
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14301, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14302, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3274
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14303, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0982
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14304, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1514
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14305, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14306, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4859
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14307, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3814
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14308, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14309, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1220
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14310, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14311, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14312, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14313, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0440
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14314, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14315, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1221
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14316, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14317, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3612
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14318, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14319, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14320, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14321, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14322, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6302
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14323, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14324, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14325, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14326, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.3010
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14327, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14328, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14329, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6938
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14330, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2034
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14331, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14332, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14333, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2396
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14334, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14335, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1917
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14336, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0851
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14337, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2867
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14338, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14339, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14340, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3721
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14341, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3023
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14342, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14343, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6917
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14344, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14345, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14346, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14347, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14348, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14349, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1199
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14350, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14351, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14352, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0841
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14353, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14354, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14355, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14356, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2419
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14357, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6460
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14358, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14359, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5938
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14360, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14361, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3016
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14362, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2291
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14363, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14364, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4294
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14365, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14366, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2309
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14367, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9659
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14368, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14369, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4463
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14370, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.0050
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14371, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7016
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14372, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14373, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3149
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14374, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1498
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14375, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14376, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1851
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14377, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14378, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5594
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14379, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2243
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14380, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0659
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14381, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2509
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14382, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6976
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14383, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14384, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14385, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6387
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14386, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14387, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14388, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0286
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14389, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2445
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14390, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5879
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14391, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14392, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14393, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14394, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14395, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14396, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14397, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14398, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9985
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14399, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14400, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14401, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14402, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6160
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14403, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14404, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2027
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14405, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14406, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1490
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14407, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14408, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1657
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14409, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2641
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14410, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14411, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14412, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14413, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7164
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14414, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14415, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0408
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14416, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14417, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14418, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0624
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14419, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4366
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14420, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14421, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14422, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4308
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14423, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14424, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14425, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14426, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3390
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14427, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6791
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14428, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7421
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14429, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1244
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14430, num samples collected 7500, FPS 29
  Algorithm: train_loss 2.2610
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14431, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7957
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14432, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14433, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4691
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14434, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14435, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14436, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14437, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14438, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14439, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2471
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14440, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1716
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14441, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6800
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14442, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0848
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14443, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2438
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14444, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.2245
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14445, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14446, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14447, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14448, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14449, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14450, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14451, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14452, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2213
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14453, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8294
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14454, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7515
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14455, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14456, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14457, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3597
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14458, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14459, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14460, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14461, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0264
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14462, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14463, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8026
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14464, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14465, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14466, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5210
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14467, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14468, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14469, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14470, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14471, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3538
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14472, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6834
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14473, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14474, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14475, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1176
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14476, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1224
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14477, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14478, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0609
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14479, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14480, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14481, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14482, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14483, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14484, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6593
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14485, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14486, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4380
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14487, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4521
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14488, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14489, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14490, num samples collected 7500, FPS 29
  Algorithm: train_loss 2.2332
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14491, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6822
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14492, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4556
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14493, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14494, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14495, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14496, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14497, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6756
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14498, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14499, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7109
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14500, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2784
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14501, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14502, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14503, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14504, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5526
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14505, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14506, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2379
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14507, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14508, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1234
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14509, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3770
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14510, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14511, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14512, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14513, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14514, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2373
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14515, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5867
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14516, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14517, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14518, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2009
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14519, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4896
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14520, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14521, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3772
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14522, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4148
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14523, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14524, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1535
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14525, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14526, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6669
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14527, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14528, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0631
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14529, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14530, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1225
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14531, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14532, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14533, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3246
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14534, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.2787
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14535, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14536, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8012
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14537, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14538, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14539, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14540, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.0587
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14541, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14542, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2982
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14543, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14544, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14545, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14546, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14547, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14548, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1326
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14549, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2349
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14550, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14551, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0845
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14552, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14553, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14554, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14555, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14556, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14557, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14558, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2859
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14559, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6864
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14560, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14561, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14562, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14563, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3456
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14564, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4161
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14565, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14566, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14567, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7672
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14568, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14569, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4948
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14570, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2123
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14571, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14572, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14573, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0275
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14574, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4348
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14575, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14576, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3494
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14577, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3640
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14578, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8343
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14579, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14580, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14581, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2381
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14582, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14583, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14584, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14585, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14586, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5282
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14587, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3556
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14588, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4346
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14589, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14590, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0275
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14591, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14592, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2737
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14593, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14594, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0613
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14595, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2255
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14596, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5898
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14597, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0537
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14598, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3515
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14599, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14600, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6564
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14601, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14602, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14603, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6392
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14604, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14605, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2673
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14606, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14607, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1247
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14608, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7141
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14609, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14610, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0375
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14611, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14612, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14613, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3332
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14614, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1513
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14615, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14616, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6615
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14617, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14618, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1209
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14619, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14620, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4830
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14621, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4398
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14622, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14623, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14624, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14625, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8351
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14626, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4925
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14627, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5132
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14628, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0326
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14629, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4237
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14630, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4628
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14631, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14632, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14633, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14634, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14635, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14636, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14637, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14638, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0951
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14639, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5185
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14640, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14641, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14642, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6972
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14643, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14644, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14645, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14646, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6951
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14647, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9896
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14648, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14649, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1338
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14650, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14651, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4790
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14652, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14653, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14654, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14655, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14656, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2038
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14657, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1562
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14658, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14659, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14660, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6033
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14661, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14662, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14663, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0541
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14664, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3236
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14665, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3985
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14666, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14667, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14668, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14669, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14670, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.7339
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14671, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1240
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14672, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.0656
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14673, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5475
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14674, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14675, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14676, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2338
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14677, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14678, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14679, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4916
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14680, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0789
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14681, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14682, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2772
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14683, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5628
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14684, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14685, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14686, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2962
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14687, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14688, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7239
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14689, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14690, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2877
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14691, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6765
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14692, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14693, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6520
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14694, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14695, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14696, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6012
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14697, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14698, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14699, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14700, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14701, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14702, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14703, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5883
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14704, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14705, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14706, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14707, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14708, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1931
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14709, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0578
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14710, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14711, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14712, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14713, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14714, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7288
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14715, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7660
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14716, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14717, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14718, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3652
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14719, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14720, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14721, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1734
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14722, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14723, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14724, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7034
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14725, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2574
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14726, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5882
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14727, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14728, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6166
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14729, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14730, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14731, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5232
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14732, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1699
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14733, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14734, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14735, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14736, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14737, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2809
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14738, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1624
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14739, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3660
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14740, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7264
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14741, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14742, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2428
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14743, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14744, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1962
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14745, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14746, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14747, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6316
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14748, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1190
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14749, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1639
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14750, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0267
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14751, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4405
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14752, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14753, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14754, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0912
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14755, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6812
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14756, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14757, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6894
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14758, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14759, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14760, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14761, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14762, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14763, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1209
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14764, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14765, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1160
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14766, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1592
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14767, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14768, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7255
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14769, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14770, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14771, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0664
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14772, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14773, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6209
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14774, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4587
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14775, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5674
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14776, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2712
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14777, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14778, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2763
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14779, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14780, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0585
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14781, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14782, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6629
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14783, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6848
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14784, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6324
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14785, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14786, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0278
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14787, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0407
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14788, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14789, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14790, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14791, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6412
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14792, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14793, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14794, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4226
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14795, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3196
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14796, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1961
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14797, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14798, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0757
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14799, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.0600
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14800, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14801, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2540
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14802, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2369
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14803, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1586
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14804, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14805, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2804
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14806, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3060
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14807, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14808, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1551
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14809, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6199
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14810, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14811, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6317
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14812, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2146
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14813, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14814, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14815, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0538
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14816, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14817, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6908
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14818, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14819, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14820, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0268
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14821, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3242
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14822, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5600
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14823, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2876
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14824, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3145
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14825, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3721
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14826, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4843
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14827, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6990
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14828, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.9441
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14829, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4283
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14830, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14831, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14832, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3188
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14833, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4664
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14834, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14835, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14836, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0272
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14837, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4509
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14838, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14839, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14840, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14841, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14842, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14843, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14844, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0412
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14845, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14846, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14847, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0536
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14848, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14849, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2099
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14850, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14851, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14852, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14853, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14854, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1550
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14855, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14856, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14857, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6946
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14858, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3174
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14859, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4244
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14860, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14861, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14862, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1643
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14863, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14864, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14865, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14866, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14867, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14868, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0777
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14869, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14870, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14871, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14872, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14873, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14874, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14875, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14876, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14877, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3460
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14878, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0255
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14879, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5949
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14880, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14881, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3298
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14882, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.3018
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14883, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1990
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14884, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6462
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14885, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14886, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6716
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14887, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14888, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14889, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14890, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14891, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0632
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14892, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14893, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14894, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1376
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14895, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14896, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14897, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2685
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14898, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14899, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14900, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5049
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14901, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1414
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14902, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4183
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14903, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2029
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14904, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14905, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14906, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14907, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0549
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14908, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6480
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14909, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1318
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14910, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14911, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14912, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14913, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14914, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8806
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14915, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6904
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14916, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14917, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14918, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5720
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14919, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2913
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14920, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14921, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6797
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14922, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6011
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14923, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14924, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2843
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14925, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14926, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14927, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14928, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4383
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14929, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3280
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14930, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14931, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14932, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2186
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14933, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4762
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14934, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1270
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14935, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14936, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14937, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14938, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14939, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14940, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14941, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4236
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14942, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1200
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14943, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4551
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14944, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7867
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14945, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14946, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14947, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14948, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1914
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14949, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14950, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1794
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14951, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14952, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14953, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14954, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14955, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4259
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14956, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14957, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4230
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14958, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14959, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14960, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7024
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14961, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4585
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14962, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3296
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14963, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14964, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1664
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14965, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2272
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14966, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14967, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2021
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14968, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2323
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14969, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14970, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14971, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1263
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14972, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7808
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14973, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6529
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14974, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14975, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0339
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14976, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14977, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14978, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1744
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14979, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14980, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5677
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14981, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14982, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0541
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14983, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14984, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14985, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2514
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14986, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4284
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14987, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14988, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14989, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14990, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14991, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5661
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14992, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14993, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14994, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6855
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14995, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4513
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14996, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1201
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14997, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14998, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1041
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 14999, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1393
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15000, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15001, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15002, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15003, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15004, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3456
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15005, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5329
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15006, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15007, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15008, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1252
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15009, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15010, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3186
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15011, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15012, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15013, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4810
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15014, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15015, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8950
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15016, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6854
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15017, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15018, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15019, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15020, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15021, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0251
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15022, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15023, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15024, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0741
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15025, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3357
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15026, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3619
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15027, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3811
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15028, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15029, num samples collected 7500, FPS 29
  Algorithm: train_loss 1.1059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15030, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15031, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5664
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15032, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6702
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15033, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15034, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.8266
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15035, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2012
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15036, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15037, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15038, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0450
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15039, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0523
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15040, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15041, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2367
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15042, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15043, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15044, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1551
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15045, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15046, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2012
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15047, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15048, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6913
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15049, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15050, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15051, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15052, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1105
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15053, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5876
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15054, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6285
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15055, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6492
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15056, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15057, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5360
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15058, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15059, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15060, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15061, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15062, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.5134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15063, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15064, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0435
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15065, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15066, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15067, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15068, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15069, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15070, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3236
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15071, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2081
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15072, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15073, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15074, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0239
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15075, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15076, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15077, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15078, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15079, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.7542
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15080, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4333
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15081, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.4218
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15082, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6955
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15083, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15084, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15085, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2860
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15086, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.3068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15087, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.2075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15088, num samples collected 7500, FPS 29
  Algorithm: train_loss 0.6774
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15089, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.7153
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15090, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15091, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15092, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15093, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1505
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15094, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2779
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15095, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2647
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15096, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15097, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0518
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15098, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15099, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15100, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15101, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15102, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15103, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4242
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15104, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.6217
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15105, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0624
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15106, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15107, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2977
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15108, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.8653
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15109, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15110, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1382
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15111, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.9297
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15112, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2051
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15113, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15114, num samples collected 7500, FPS 28
  Algorithm: train_loss 1.2155
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15115, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2086
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15116, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15117, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15118, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15119, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15120, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15121, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1913
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15122, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3781
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15123, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15124, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15125, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0593
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15126, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15127, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15128, num samples collected 7500, FPS 28
  Algorithm: train_loss 1.2008
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15129, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0348
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15130, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15131, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15132, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15133, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4455
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15134, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15135, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15136, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1813
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15137, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15138, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.8406
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15139, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15140, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15141, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15142, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2544
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15143, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1168
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15144, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15145, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5486
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15146, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15147, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15148, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2149
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15149, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5446
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15150, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0026
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15151, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3013
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15152, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15153, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15154, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3477
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15155, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15156, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15157, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.8090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15158, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15159, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15160, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4291
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15161, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15162, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2525
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15163, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5386
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15164, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4818
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15165, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15166, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15167, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0505
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15168, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2888
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15169, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5585
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15170, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3808
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15171, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15172, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.7068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15173, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15174, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4322
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15175, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15176, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.7932
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15177, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15178, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15179, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15180, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15181, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15182, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2044
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15183, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0812
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15184, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15185, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15186, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4579
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15187, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5094
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15188, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15189, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0440
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15190, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15191, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4880
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15192, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1987
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15193, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1995
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15194, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2032
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15195, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.8807
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15196, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5471
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15197, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15198, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15199, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2837
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15200, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15201, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15202, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2298
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15203, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15204, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15205, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.9066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15206, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5233
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15207, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15208, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1733
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15209, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15210, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15211, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1426
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15212, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1234
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15213, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15214, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.7482
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15215, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5065
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15216, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15217, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.6847
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15218, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5261
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15219, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1960
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15220, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15221, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4862
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15222, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4192
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15223, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15224, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1152
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15225, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15226, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15227, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4225
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15228, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15229, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.6955
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15230, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15231, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15232, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15233, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15234, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15235, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2961
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15236, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15237, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0535
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15238, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15239, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15240, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.9761
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15241, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15242, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15243, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15244, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4482
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15245, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1142
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15246, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3147
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15247, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0830
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15248, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4350
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15249, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2090
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15250, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.6171
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15251, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1322
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15252, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15253, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0958
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15254, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15255, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1743
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15256, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15257, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4201
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15258, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15259, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1544
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15260, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15261, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.8313
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15262, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15263, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3752
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15264, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15265, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2174
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15266, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5587
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15267, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2452
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15268, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15269, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.5744
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15270, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3974
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15271, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2779
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15272, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15273, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15274, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15275, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2905
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15276, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4062
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15277, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.6559
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15278, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4686
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15279, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0445
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15280, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15281, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15282, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15283, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3919
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15284, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1501
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15285, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.7494
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15286, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.1531
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15287, num samples collected 7500, FPS 28
  Algorithm: train_loss 1.2572
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15288, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3184
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15289, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2673
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15290, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15291, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15292, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3763
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15293, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15294, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15295, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.4357
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15296, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.3016
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15297, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.2211
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15298, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15299, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15300, num samples collected 7500, FPS 28
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1644.2953, l 200.0000, t 333.7461, TestReward -1605.9144
Update 15301, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15302, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15303, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2491
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15304, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2107
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15305, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2275
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15306, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6381
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15307, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15308, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15309, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4450
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15310, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15311, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8236
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15312, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15313, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3574
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15314, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15315, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15316, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15317, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2311
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15318, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3668
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15319, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15320, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1146
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15321, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0635
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15322, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5207
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15323, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15324, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2259
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15325, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15326, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3471
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15327, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15328, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2326
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15329, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15330, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8527
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15331, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15332, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3429
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15333, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7023
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15334, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2632
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15335, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15336, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15337, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15338, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6359
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15339, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15340, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15341, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15342, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15343, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2288
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15344, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1269
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15345, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15346, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15347, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3855
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15348, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5593
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15349, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15350, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15351, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8926
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15352, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5053
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15353, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2264
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15354, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15355, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2304
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15356, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5366
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15357, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15358, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15359, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15360, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15361, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15362, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15363, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15364, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15365, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4400
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15366, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15367, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8497
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15368, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15369, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15370, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15371, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15372, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15373, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15374, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1347
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15375, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1820
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15376, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15377, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2036
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15378, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15379, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3018
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15380, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.1412
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15381, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4824
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15382, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15383, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3147
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15384, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15385, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15386, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5243
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15387, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3181
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15388, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15389, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3141
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15390, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0553
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15391, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4683
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15392, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15393, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4353
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15394, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15395, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2480
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15396, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15397, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15398, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15399, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15400, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2758
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15401, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15402, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1888
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15403, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15404, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15405, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15406, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15407, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0247
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15408, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.3470
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15409, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15410, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4418
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15411, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15412, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15413, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5789
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15414, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15415, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6310
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15416, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2764
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15417, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15418, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15419, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15420, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15421, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0279
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15422, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15423, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4758
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15424, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15425, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15426, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15427, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15428, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15429, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1408
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15430, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15431, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15432, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2192
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15433, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15434, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5448
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15435, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15436, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4680
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15437, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2046
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15438, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5148
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15439, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15440, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15441, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2323
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15442, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15443, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15444, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4554
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15445, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7811
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15446, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4337
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15447, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6872
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15448, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3338
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15449, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4283
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15450, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15451, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0351
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15452, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15453, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4659
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15454, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2146
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15455, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15456, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7402
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15457, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15458, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15459, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15460, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1157
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15461, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4295
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15462, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1283
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15463, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15464, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1239
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15465, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15466, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15467, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2354
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15468, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15469, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15470, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15471, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2498
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15472, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0446
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15473, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1780
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15474, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8382
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15475, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7735
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15476, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2036
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15477, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15478, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5197
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15479, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2920
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15480, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15481, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5480
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15482, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15483, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0801
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15484, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1972
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15485, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15486, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15487, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15488, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15489, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6316
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15490, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3541
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15491, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0639
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15492, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15493, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0222
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15494, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15495, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3246
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15496, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15497, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15498, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15499, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15500, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2211
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15501, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2309
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15502, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1589
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15503, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15504, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15505, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6233
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15506, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8850
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15507, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15508, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15509, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1239
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15510, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15511, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5835
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15512, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15513, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7191
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15514, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1044
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15515, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1397
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15516, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8929
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15517, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15518, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15519, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15520, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15521, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5808
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15522, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15523, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2132
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15524, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5367
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15525, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15526, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15527, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15528, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4279
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15529, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15530, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15531, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15532, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4655
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15533, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15534, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15535, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1892
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15536, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4898
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15537, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.1548
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15538, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0441
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15539, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2293
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15540, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15541, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1591
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15542, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15543, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15544, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15545, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2305
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15546, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8254
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15547, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15548, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0697
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15549, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15550, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15551, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1584
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15552, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0817
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15553, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15554, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2007
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15555, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15556, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2373
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15557, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15558, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5247
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15559, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15560, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15561, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15562, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5460
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15563, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4620
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15564, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15565, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3902
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15566, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2922
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15567, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15568, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1585
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15569, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15570, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6227
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15571, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15572, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15573, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15574, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6561
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15575, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0240
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15576, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15577, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0871
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15578, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7380
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15579, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15580, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6714
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15581, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2774
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15582, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8135
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15583, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15584, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15585, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15586, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0256
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15587, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0929
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15588, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2612
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15589, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5569
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15590, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7019
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15591, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9902
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15592, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15593, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15594, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15595, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15596, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15597, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15598, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15599, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3333
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15600, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15601, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15602, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15603, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5541
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15604, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15605, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4718
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15606, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1216
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15607, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15608, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15609, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2610
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15610, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7557
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15611, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15612, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5356
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15613, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15614, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6347
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15615, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15616, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15617, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0536
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15618, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15619, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15620, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15621, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15622, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15623, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15624, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15625, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15626, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15627, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15628, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0425
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15629, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2479
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15630, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15631, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6845
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15632, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0944
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15633, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.3359
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15634, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15635, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4448
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15636, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6495
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15637, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1763
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15638, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4999
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15639, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15640, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15641, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15642, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0039
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15643, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2450
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15644, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15645, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15646, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3500
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15647, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15648, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15649, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15650, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15651, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15652, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2362
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15653, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15654, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15655, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4578
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15656, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15657, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4371
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15658, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15659, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15660, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15661, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0705
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15662, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2698
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15663, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1496
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15664, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15665, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1793
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15666, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15667, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15668, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15669, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0636
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15670, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15671, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1413
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15672, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15673, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15674, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15675, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15676, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0845
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15677, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2980
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15678, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15679, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15680, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15681, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2576
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15682, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3448
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15683, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6167
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15684, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2134
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15685, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2805
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15686, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2268
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15687, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1704
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15688, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15689, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3650
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15690, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2021
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15691, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15692, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4672
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15693, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15694, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4226
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15695, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15696, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15697, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4986
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15698, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1910
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15699, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15700, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5830
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15701, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7340
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15702, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15703, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15704, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4038
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15705, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2782
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15706, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.3658
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15707, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15708, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3719
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15709, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15710, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15711, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4278
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15712, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0842
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15713, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0891
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15714, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15715, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5966
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15716, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15717, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2925
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15718, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0596
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15719, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15720, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0322
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15721, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0476
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15722, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5667
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15723, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4968
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15724, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15725, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2254
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15726, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15727, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3192
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15728, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15729, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15730, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15731, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15732, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1404
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15733, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1721
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15734, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15735, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15736, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2970
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15737, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15738, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3320
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15739, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1999
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15740, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15741, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15742, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4736
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15743, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5932
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15744, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15745, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3221
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15746, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15747, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7039
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15748, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15749, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15750, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7212
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15751, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15752, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7570
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15753, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15754, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15755, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6208
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15756, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15757, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15758, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4883
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15759, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15760, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3336
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15761, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15762, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3266
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15763, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15764, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15765, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15766, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15767, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15768, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1910
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15769, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15770, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0606
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15771, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15772, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6028
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15773, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15774, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15775, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1705
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15776, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15777, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15778, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15779, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4379
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15780, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5160
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15781, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15782, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15783, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7731
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15784, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4621
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15785, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9960
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15786, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15787, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0521
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15788, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1544
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15789, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15790, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5860
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15791, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15792, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2141
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15793, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3312
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15794, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5321
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15795, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1401
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15796, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15797, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15798, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15799, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15800, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15801, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3624
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15802, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15803, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3280
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15804, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15805, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15806, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15807, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6251
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15808, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15809, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3230
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15810, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2252
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15811, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15812, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7871
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15813, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15814, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4966
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15815, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15816, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1749
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15817, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2963
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15818, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15819, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15820, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5469
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15821, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4246
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15822, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2938
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15823, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15824, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0890
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15825, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1399
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15826, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15827, num samples collected 7750, FPS 27
  Algorithm: train_loss 2.5712
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15828, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15829, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0635
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15830, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15831, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15832, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15833, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15834, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1618
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15835, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15836, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15837, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15838, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15839, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2825
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15840, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1360
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15841, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15842, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5948
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15843, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0657
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15844, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4460
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15845, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4166
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15846, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15847, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15848, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15849, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3386
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15850, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15851, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15852, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15853, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4374
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15854, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0623
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15855, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1043
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15856, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9699
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15857, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0266
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15858, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15859, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15860, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4828
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15861, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15862, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15863, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6671
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15864, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0658
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15865, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15866, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0266
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15867, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15868, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15869, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1516
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15870, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15871, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6383
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15872, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15873, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0442
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15874, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15875, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9276
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15876, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15877, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15878, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15879, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0594
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15880, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9883
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15881, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3747
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15882, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15883, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8193
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15884, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1857
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15885, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15886, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15887, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15888, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15889, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15890, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15891, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15892, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5806
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15893, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15894, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15895, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15896, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15897, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15898, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2248
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15899, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6563
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15900, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5158
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15901, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1396
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15902, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0288
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15903, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15904, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15905, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4275
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15906, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15907, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2700
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15908, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8222
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15909, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15910, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7959
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15911, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4695
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15912, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1646
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15913, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15914, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3698
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15915, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15916, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15917, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15918, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15919, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15920, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.5346
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15921, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15922, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15923, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1729
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15924, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4164
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15925, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15926, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15927, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15928, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15929, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0435
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15930, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15931, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15932, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15933, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7482
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15934, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6450
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15935, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15936, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2648
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15937, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15938, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4864
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15939, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1157
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15940, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5310
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15941, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0844
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15942, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15943, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6976
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15944, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15945, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15946, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0618
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15947, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2966
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15948, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1380
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15949, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15950, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15951, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15952, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5030
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15953, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15954, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3811
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15955, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8505
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15956, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6141
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15957, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15958, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2605
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15959, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0375
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15960, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15961, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7123
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15962, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15963, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15964, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15965, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15966, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2315
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15967, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15968, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15969, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15970, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15971, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.1474
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15972, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1718
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15973, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15974, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15975, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15976, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15977, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15978, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15979, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15980, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15981, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15982, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15983, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1117
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15984, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5064
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15985, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0437
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15986, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15987, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6164
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15988, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15989, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15990, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2556
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15991, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15992, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15993, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15994, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15995, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15996, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15997, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15998, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5626
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 15999, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16000, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8882
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16001, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0801
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16002, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16003, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16004, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3771
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16005, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0356
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16006, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16007, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16008, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2009
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16009, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0535
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16010, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8716
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16011, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16012, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16013, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16014, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16015, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1966
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16016, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16017, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0693
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16018, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0819
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16019, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16020, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2539
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16021, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16022, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16023, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16024, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0324
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16025, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9021
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16026, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3819
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16027, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16028, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16029, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5280
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16030, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7138
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16031, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4364
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16032, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0606
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16033, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8544
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16034, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16035, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16036, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16037, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16038, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2317
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16039, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16040, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1348
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16041, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1146
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16042, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16043, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16044, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16045, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2304
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16046, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3004
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16047, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16048, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16049, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3209
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16050, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16051, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8291
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16052, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16053, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16054, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0559
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16055, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16056, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4419
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16057, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4698
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16058, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0721
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16059, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4954
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16060, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16061, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3939
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16062, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0928
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16063, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.1408
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16064, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16065, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0731
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16066, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4188
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16067, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16068, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4357
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16069, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16070, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3538
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16071, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16072, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3556
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16073, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16074, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3911
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16075, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16076, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6803
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16077, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16078, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2632
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16079, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3576
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16080, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2023
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16081, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16082, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16083, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0280
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16084, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3245
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16085, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16086, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6397
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16087, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16088, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16089, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4393
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16090, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2577
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16091, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16092, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16093, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16094, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0280
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16095, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16096, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7011
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16097, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2688
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16098, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16099, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3873
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16100, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16101, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6219
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16102, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0201
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16103, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16104, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16105, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16106, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16107, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16108, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1649
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16109, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3158
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16110, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0476
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16111, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16112, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4297
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16113, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16114, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16115, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16116, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8932
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16117, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16118, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3400
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16119, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16120, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0847
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16121, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16122, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16123, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16124, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16125, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0558
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16126, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5645
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16127, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2550
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16128, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6515
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16129, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16130, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16131, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16132, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2023
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16133, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5168
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16134, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2138
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16135, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7860
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16136, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5541
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16137, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5013
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16138, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16139, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16140, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16141, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16142, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16143, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1196
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16144, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0685
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16145, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2064
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16146, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0515
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16147, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8362
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16148, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4619
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16149, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16150, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0312
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16151, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16152, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16153, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16154, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7647
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16155, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16156, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4395
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16157, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16158, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16159, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16160, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2169
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16161, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3792
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16162, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16163, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6384
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16164, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1434
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16165, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2685
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16166, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16167, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4056
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16168, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7095
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16169, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0723
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16170, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16171, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16172, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0551
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16173, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2434
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16174, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7320
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16175, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4176
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16176, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1949
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16177, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16178, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16179, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16180, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4836
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16181, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16182, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5149
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16183, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16184, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6608
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16185, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4353
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16186, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4984
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16187, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0342
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16188, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4162
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16189, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1397
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16190, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1683
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16191, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16192, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1241
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16193, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16194, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16195, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0626
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16196, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16197, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16198, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16199, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0032
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16200, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5165
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16201, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16202, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16203, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16204, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16205, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1269
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16206, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1536
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16207, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16208, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4450
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16209, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4987
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16210, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3350
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16211, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16212, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4343
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16213, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16214, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1427
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16215, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16216, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5423
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16217, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16218, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16219, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16220, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0601
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16221, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16222, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3569
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16223, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2869
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16224, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1196
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16225, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16226, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16227, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16228, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16229, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0627
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16230, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16231, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2827
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16232, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16233, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16234, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5405
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16235, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1806
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16236, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4539
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16237, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16238, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1568
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16239, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0263
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16240, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16241, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16242, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2685
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16243, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7531
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16244, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16245, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16246, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16247, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16248, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16249, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16250, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2264
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16251, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7748
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16252, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16253, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16254, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3175
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16255, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2262
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16256, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16257, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16258, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0775
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16259, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4423
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16260, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2476
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16261, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16262, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6963
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16263, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2546
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16264, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16265, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1623
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16266, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16267, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7589
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16268, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9463
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16269, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16270, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1236
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16271, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16272, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16273, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16274, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6216
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16275, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1820
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16276, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16277, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16278, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16279, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7556
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16280, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16281, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4975
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16282, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0280
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16283, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4268
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16284, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16285, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16286, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16287, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16288, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16289, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16290, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16291, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0791
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16292, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1903
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16293, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16294, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16295, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8749
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16296, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7207
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16297, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8303
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16298, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3112
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16299, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16300, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0464
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16301, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16302, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16303, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4245
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16304, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1997
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16305, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4141
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16306, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16307, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6972
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16308, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16309, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16310, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1142
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16311, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16312, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16313, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3420
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16314, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1910
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16315, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0287
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16316, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3303
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16317, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16318, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16319, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1978
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16320, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16321, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16322, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1577
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16323, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16324, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16325, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1259
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16326, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16327, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16328, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7423
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16329, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0540
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16330, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16331, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1159
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16332, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1235
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16333, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16334, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6397
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16335, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0601
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16336, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6141
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16337, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16338, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16339, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16340, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16341, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16342, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6689
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16343, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3406
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16344, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2329
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16345, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4387
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16346, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8367
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16347, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1872
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16348, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16349, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16350, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8530
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16351, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16352, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16353, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16354, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16355, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16356, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16357, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16358, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6562
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16359, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0703
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16360, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16361, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1806
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16362, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6578
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16363, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16364, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16365, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4388
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16366, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2652
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16367, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16368, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4295
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16369, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3166
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16370, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0718
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16371, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16372, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16373, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16374, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0346
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16375, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16376, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16377, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4456
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16378, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16379, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16380, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4519
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16381, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1364
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16382, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16383, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1682
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16384, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8765
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16385, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16386, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16387, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16388, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16389, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16390, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16391, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4319
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16392, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1354
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16393, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16394, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16395, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1564
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16396, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16397, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16398, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16399, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2534
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16400, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0956
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16401, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16402, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0663
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16403, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16404, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4520
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16405, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4207
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16406, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16407, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3800
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16408, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4414
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16409, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1809
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16410, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16411, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0938
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16412, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16413, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16414, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2777
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16415, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0380
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16416, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16417, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3238
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16418, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1132
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16419, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16420, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4247
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16421, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16422, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16423, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16424, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16425, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16426, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16427, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5156
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16428, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16429, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1488
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16430, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16431, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16432, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16433, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3410
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16434, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16435, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16436, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6669
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16437, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5192
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16438, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4163
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16439, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16440, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16441, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4358
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16442, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16443, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4663
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16444, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16445, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16446, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9502
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16447, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4753
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16448, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3057
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16449, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2219
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16450, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0917
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16451, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1342
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16452, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4329
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16453, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16454, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6283
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16455, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16456, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0673
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16457, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0812
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16458, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6337
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16459, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16460, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0210
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16461, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16462, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16463, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16464, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6699
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16465, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16466, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16467, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16468, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16469, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16470, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16471, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6938
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16472, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16473, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16474, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1304
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16475, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3568
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16476, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2503
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16477, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16478, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2832
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16479, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16480, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16481, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16482, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16483, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16484, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7169
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16485, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16486, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0651
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16487, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16488, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16489, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4291
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16490, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16491, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4837
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16492, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0631
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16493, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1565
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16494, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16495, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3384
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16496, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16497, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16498, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16499, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16500, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16501, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2773
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16502, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6048
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16503, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6477
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16504, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5794
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16505, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16506, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16507, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0880
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16508, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16509, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.8660
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16510, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16511, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1356
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16512, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4890
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16513, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16514, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5492
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16515, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16516, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2112
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16517, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2519
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16518, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16519, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16520, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0312
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16521, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1252
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16522, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16523, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16524, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2354
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16525, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.3134
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16526, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7024
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16527, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2213
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16528, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2490
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16529, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16530, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1569
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16531, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0749
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16532, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0287
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16533, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16534, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6189
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16535, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16536, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16537, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16538, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2115
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16539, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16540, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.1117
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16541, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16542, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3336
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16543, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1117
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16544, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6796
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16545, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16546, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16547, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0274
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16548, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6908
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16549, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16550, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1040
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16551, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16552, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1584
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16553, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2395
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16554, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5655
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16555, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3247
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16556, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16557, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16558, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9035
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16559, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16560, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1984
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16561, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16562, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0962
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16563, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3335
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16564, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16565, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16566, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16567, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1598
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16568, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16569, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9901
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16570, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16571, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16572, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16573, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16574, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6685
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16575, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16576, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16577, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2800
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16578, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8551
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16579, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16580, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1985
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16581, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2538
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16582, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2103
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16583, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16584, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16585, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4209
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16586, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16587, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2188
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16588, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8818
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16589, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16590, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16591, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1287
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16592, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4650
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16593, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16594, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3009
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16595, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2717
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16596, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2698
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16597, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5879
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16598, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16599, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16600, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16601, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16602, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16603, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4561
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16604, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16605, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3243
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16606, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7270
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16607, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0881
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16608, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16609, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5028
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16610, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0484
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16611, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16612, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16613, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16614, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5333
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16615, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6611
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16616, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5169
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16617, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5353
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16618, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16619, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1406
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16620, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16621, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16622, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0637
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16623, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16624, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16625, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7859
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16626, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16627, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16628, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16629, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0604
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16630, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16631, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1906
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16632, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16633, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16634, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16635, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16636, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16637, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16638, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4136
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16639, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4971
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16640, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0610
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16641, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16642, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8115
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16643, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16644, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2706
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16645, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16646, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16647, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16648, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16649, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5527
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16650, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16651, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3046
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16652, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16653, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16654, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7543
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16655, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2545
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16656, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16657, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3951
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16658, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16659, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0335
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16660, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16661, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16662, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16663, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16664, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5587
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16665, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1235
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16666, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16667, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1064
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16668, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16669, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16670, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16671, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16672, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4738
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16673, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5200
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16674, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16675, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16676, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16677, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16678, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16679, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1637
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16680, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6994
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16681, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2132
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16682, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4320
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16683, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16684, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16685, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3771
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16686, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16687, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3782
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16688, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2939
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16689, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4394
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16690, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16691, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16692, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2565
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16693, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1823
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16694, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6897
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16695, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16696, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16697, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4130
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16698, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16699, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16700, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3642
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16701, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16702, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16703, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16704, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4559
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16705, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4365
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16706, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16707, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16708, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16709, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16710, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16711, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7573
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16712, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2018
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16713, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7129
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16714, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9957
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16715, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0436
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16716, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2620
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16717, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16718, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4342
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16719, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16720, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3501
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16721, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16722, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3892
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16723, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1412
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16724, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16725, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2647
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16726, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16727, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6729
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16728, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1517
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16729, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16730, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16731, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16732, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16733, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4357
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16734, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16735, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1299
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16736, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16737, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5018
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16738, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1869
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16739, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2903
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16740, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16741, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5057
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16742, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16743, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16744, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16745, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16746, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1818
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16747, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16748, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0770
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16749, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1182
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16750, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4343
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16751, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16752, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16753, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16754, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16755, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.2756
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16756, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1667
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16757, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16758, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0546
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16759, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16760, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1690
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16761, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16762, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16763, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1922
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16764, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16765, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4700
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16766, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0789
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16767, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16768, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16769, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0314
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16770, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0995
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16771, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16772, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1329
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16773, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16774, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16775, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2504
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16776, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4161
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16777, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4313
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16778, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1252
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16779, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16780, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16781, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7272
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16782, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6588
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16783, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.9078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16784, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16785, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16786, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3590
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16787, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16788, num samples collected 7750, FPS 27
  Algorithm: train_loss 2.5082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16789, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3041
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16790, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6946
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16791, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16792, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16793, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4958
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16794, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16795, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8730
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16796, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4123
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16797, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16798, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3004
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16799, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0453
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16800, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0193
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16801, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16802, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3563
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16803, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4404
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16804, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1159
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16805, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16806, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16807, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3211
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16808, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16809, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16810, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16811, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6251
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16812, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16813, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16814, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16815, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1595
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16816, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16817, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16818, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16819, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16820, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2140
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16821, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16822, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16823, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16824, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16825, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3028
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16826, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16827, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16828, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16829, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2653
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16830, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8679
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16831, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1881
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16832, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2848
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16833, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16834, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16835, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16836, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7653
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16837, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16838, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16839, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6662
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16840, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6271
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16841, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1302
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16842, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2248
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16843, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16844, num samples collected 7750, FPS 27
  Algorithm: train_loss 1.0454
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16845, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16846, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16847, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8481
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16848, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16849, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16850, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16851, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1342
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16852, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16853, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16854, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16855, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1525
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16856, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4284
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16857, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6914
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16858, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3671
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16859, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16860, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16861, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.7128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16862, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4094
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16863, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8274
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16864, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16865, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5475
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16866, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3038
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16867, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16868, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16869, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16870, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16871, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16872, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16873, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16874, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1529
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16875, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16876, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5825
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16877, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16878, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2341
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16879, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16880, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16881, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16882, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5406
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16883, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4903
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16884, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16885, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4305
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16886, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4295
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16887, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16888, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8423
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16889, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1927
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16890, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0489
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16891, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0864
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16892, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16893, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16894, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16895, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16896, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1332
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16897, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3085
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16898, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16899, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1554
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16900, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1183
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16901, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2338
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16902, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16903, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.5243
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16904, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16905, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0789
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16906, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1717
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16907, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16908, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.8151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16909, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1875
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16910, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16911, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16912, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16913, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.4290
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16914, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16915, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16916, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0582
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16917, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16918, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.6269
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16919, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16920, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.1742
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16921, num samples collected 7750, FPS 27
  Algorithm: train_loss 0.3736
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16922, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0747
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16923, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16924, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3010
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16925, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.8233
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16926, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16927, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16928, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1998
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16929, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16930, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4741
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16931, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5582
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16932, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3268
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16933, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0699
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16934, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16935, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16936, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4410
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16937, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16938, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16939, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0583
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16940, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2334
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16941, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1755
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16942, num samples collected 7750, FPS 26
  Algorithm: train_loss 1.6231
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16943, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16944, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16945, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16946, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2037
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16947, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2070
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16948, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16949, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16950, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1031
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16951, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16952, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1584
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16953, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6143
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16954, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16955, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4414
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16956, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4995
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16957, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16958, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6635
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16959, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.8371
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16960, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16961, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3701
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16962, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0461
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16963, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6961
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16964, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16965, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3114
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16966, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2286
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16967, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16968, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1201
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16969, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16970, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16971, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16972, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2634
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16973, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3039
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16974, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7076
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16975, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1756
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16976, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7015
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16977, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5189
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16978, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16979, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0432
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16980, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16981, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3391
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16982, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0948
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16983, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.8543
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16984, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16985, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16986, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2096
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16987, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.9285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16988, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2033
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16989, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3135
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16990, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16991, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16992, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16993, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16994, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16995, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2053
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16996, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4451
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16997, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16998, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1220
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 16999, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17000, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17001, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3269
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17002, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0833
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17003, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17004, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17005, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17006, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0261
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17007, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3788
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17008, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17009, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0609
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17010, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17011, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17012, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17013, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17014, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4976
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17015, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17016, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5295
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17017, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17018, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17019, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1128
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17020, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4442
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17021, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17022, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17023, num samples collected 7750, FPS 26
  Algorithm: train_loss 1.1309
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17024, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1490
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17025, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17026, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17027, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17028, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6405
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17029, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17030, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17031, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7149
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17032, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2282
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17033, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1746
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17034, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17035, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7088
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17036, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6346
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17037, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17038, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4248
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17039, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17040, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2086
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17041, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17042, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17043, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17044, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1251
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17045, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17046, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17047, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17048, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.8844
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17049, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1152
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17050, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7497
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17051, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17052, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5150
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17053, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17054, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2864
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17055, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3709
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17056, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17057, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4354
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17058, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1151
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17059, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17060, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5318
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17061, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17062, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17063, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17064, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5155
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17065, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5131
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17066, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17067, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1929
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17068, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2799
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17069, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17070, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1785
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17071, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6969
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17072, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17073, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17074, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2234
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17075, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3694
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17076, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2018
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17077, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7019
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17078, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2080
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17079, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17080, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0664
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17081, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17082, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17083, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0251
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17084, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1365
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17085, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17086, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17087, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17088, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0556
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17089, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0591
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17090, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17091, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3006
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17092, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1925
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17093, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3165
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17094, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17095, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1541
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17096, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4663
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17097, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5105
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17098, num samples collected 7750, FPS 26
  Algorithm: train_loss 1.5380
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17099, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5010
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17100, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3663
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17101, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3179
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17102, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17103, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17104, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17105, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4246
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17106, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17107, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17108, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17109, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17110, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4426
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17111, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1723
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17112, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17113, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17114, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5033
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17115, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5892
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17116, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17117, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17118, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17119, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.9247
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17120, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17121, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17122, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3285
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17123, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2127
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17124, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17125, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1107
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17126, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4629
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17127, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17128, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0703
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17129, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17130, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.6106
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17131, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17132, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0617
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17133, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1222
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17134, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4772
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17135, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17136, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4062
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17137, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17138, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17139, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17140, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2929
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17141, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1566
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17142, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1681
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17143, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0648
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17144, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1058
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17145, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.7061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17146, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17147, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.3640
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17148, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1158
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17149, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17150, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17151, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17152, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17153, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17154, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1220
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17155, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.5676
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17156, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.1836
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17157, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17158, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.9214
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17159, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.4410
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17160, num samples collected 7750, FPS 26
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1692.6170, l 200.0000, t 360.9525, TestReward -1594.0394
Update 17161, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17162, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17163, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0269
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17164, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4206
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17165, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17166, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1192
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17167, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17168, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17169, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17170, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17171, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2779
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17172, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17173, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0785
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17174, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1819
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17175, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9298
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17176, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.7550
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17177, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4371
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17178, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2447
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17179, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0545
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17180, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17181, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17182, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2353
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17183, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17184, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17185, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6432
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17186, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1192
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17187, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2515
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17188, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17189, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17190, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1459
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17191, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17192, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17193, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4050
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17194, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2591
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17195, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17196, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17197, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5744
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17198, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6411
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17199, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17200, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1534
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17201, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17202, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2246
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17203, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0788
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17204, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5376
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17205, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17206, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0485
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17207, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4250
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17208, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17209, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0372
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17210, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17211, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17212, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1232
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17213, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17214, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17215, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17216, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17217, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17218, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1991
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17219, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17220, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17221, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2792
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17222, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.2457
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17223, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17224, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17225, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1221
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17226, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2697
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17227, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17228, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1466
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17229, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17230, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17231, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17232, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7168
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17233, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17234, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17235, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17236, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1392
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17237, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1510
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17238, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.0454
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17239, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4699
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17240, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0247
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17241, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0748
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17242, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17243, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5769
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17244, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2525
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17245, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7735
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17246, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6154
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17247, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17248, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17249, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1315
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17250, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17251, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2333
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17252, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4333
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17253, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17254, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1143
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17255, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2167
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17256, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17257, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17258, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7780
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17259, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17260, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17261, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17262, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17263, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17264, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1931
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17265, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17266, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2370
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17267, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0532
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17268, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17269, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0798
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17270, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17271, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2215
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17272, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17273, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3727
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17274, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7608
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17275, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17276, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17277, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3515
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17278, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.6840
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17279, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3827
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17280, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1304
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17281, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17282, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4978
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17283, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4296
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17284, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17285, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17286, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17287, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17288, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17289, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17290, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0203
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17291, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17292, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2946
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17293, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17294, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1575
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17295, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4126
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17296, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17297, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5946
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17298, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2200
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17299, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17300, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17301, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17302, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3644
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17303, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5229
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17304, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7863
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17305, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17306, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17307, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3281
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17308, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17309, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17310, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7898
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17311, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17312, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17313, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17314, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17315, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4489
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17316, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1656
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17317, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4411
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17318, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6250
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17319, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4326
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17320, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17321, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17322, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17323, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0709
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17324, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4458
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17325, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17326, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.2576
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17327, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1999
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17328, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17329, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17330, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17331, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4309
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17332, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1539
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17333, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17334, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17335, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1686
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17336, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17337, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5145
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17338, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17339, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17340, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0340
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17341, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17342, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17343, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2715
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17344, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7248
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17345, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1945
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17346, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4165
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17347, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2018
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17348, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5322
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17349, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17350, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17351, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0710
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17352, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17353, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17354, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1522
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17355, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6174
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17356, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2723
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17357, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17358, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6394
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17359, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17360, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17361, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17362, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17363, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17364, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17365, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1149
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17366, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17367, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17368, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17369, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2672
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17370, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17371, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0607
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17372, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2014
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17373, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3905
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17374, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17375, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17376, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8698
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17377, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17378, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.1610
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17379, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17380, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4159
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17381, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5814
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17382, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17383, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17384, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17385, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2419
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17386, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17387, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17388, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17389, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17390, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4182
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17391, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17392, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17393, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17394, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17395, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0727
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17396, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17397, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.3606
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17398, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9642
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17399, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6537
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17400, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17401, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17402, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17403, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17404, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17405, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3280
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17406, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1482
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17407, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17408, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17409, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17410, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17411, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2749
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17412, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0227
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17413, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.2375
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17414, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17415, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3705
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17416, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17417, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1254
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17418, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.2797
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17419, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7859
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17420, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17421, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17422, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17423, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17424, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3337
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17425, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17426, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4255
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17427, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17428, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7100
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17429, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7264
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17430, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1987
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17431, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17432, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4645
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17433, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0711
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17434, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17435, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3992
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17436, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17437, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17438, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17439, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0678
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17440, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17441, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1015
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17442, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1758
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17443, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17444, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17445, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17446, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17447, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6318
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17448, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17449, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17450, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5300
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17451, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4402
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17452, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17453, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3207
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17454, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3222
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17455, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17456, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17457, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3782
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17458, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5290
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17459, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17460, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0571
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17461, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17462, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9588
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17463, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17464, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17465, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6667
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17466, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17467, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17468, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17469, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5371
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17470, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17471, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17472, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3634
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17473, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17474, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17475, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17476, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5009
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17477, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17478, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17479, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17480, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17481, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4234
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17482, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1757
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17483, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.0251
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17484, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17485, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17486, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17487, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6964
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17488, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17489, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17490, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17491, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17492, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1607
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17493, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5312
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17494, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2156
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17495, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2539
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17496, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17497, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17498, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17499, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2026
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17500, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2684
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17501, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17502, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3404
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17503, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4514
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17504, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17505, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8324
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17506, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3430
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17507, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1184
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17508, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17509, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17510, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0761
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17511, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0670
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17512, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7502
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17513, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17514, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0950
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17515, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17516, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17517, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17518, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4161
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17519, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9342
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17520, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17521, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17522, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0233
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17523, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17524, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2013
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17525, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17526, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5611
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17527, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6129
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17528, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0754
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17529, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1148
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17530, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17531, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1728
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17532, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1775
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17533, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17534, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17535, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2832
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17536, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6715
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17537, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4400
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17538, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4488
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17539, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17540, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17541, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7459
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17542, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1569
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17543, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17544, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6241
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17545, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17546, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2626
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17547, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17548, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1557
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17549, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17550, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4266
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17551, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17552, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17553, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17554, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17555, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2546
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17556, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4441
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17557, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7003
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17558, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17559, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5764
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17560, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7279
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17561, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1129
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17562, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1993
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17563, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1419
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17564, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17565, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17566, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17567, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8387
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17568, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7239
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17569, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17570, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0795
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17571, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17572, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17573, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0818
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17574, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17575, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17576, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17577, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1229
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17578, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5941
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17579, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17580, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17581, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0325
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17582, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17583, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17584, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3733
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17585, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17586, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5028
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17587, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8306
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17588, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17589, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17590, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1955
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17591, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5190
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17592, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17593, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17594, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4356
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17595, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2956
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17596, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4399
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17597, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2486
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17598, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17599, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17600, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17601, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17602, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5119
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17603, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17604, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17605, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0579
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17606, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3247
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17607, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17608, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17609, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17610, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1424
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17611, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17612, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2667
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17613, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17614, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17615, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4876
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17616, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4316
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17617, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1990
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17618, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9378
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17619, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17620, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0644
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17621, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4253
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17622, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8762
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17623, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1293
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17624, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0990
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17625, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17626, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17627, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0352
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17628, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3959
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17629, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17630, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17631, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2277
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17632, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5274
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17633, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3661
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17634, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17635, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17636, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17637, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3587
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17638, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2771
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17639, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17640, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7617
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17641, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17642, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3665
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17643, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17644, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1497
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17645, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17646, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2112
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17647, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3205
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17648, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0577
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17649, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7948
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17650, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17651, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17652, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0681
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17653, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2138
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17654, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2842
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17655, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17656, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6541
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17657, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17658, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17659, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17660, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0818
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17661, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17662, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17663, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8203
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17664, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17665, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4370
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17666, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2219
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17667, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17668, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4136
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17669, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0761
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17670, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4379
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17671, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2153
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17672, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17673, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17674, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3962
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17675, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17676, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17677, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17678, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.0216
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17679, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2996
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17680, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3450
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17681, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17682, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1172
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17683, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5924
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17684, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4301
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17685, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17686, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4219
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17687, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0697
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17688, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17689, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17690, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17691, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17692, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1622
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17693, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17694, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1502
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17695, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4006
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17696, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17697, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9757
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17698, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4939
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17699, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17700, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17701, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0766
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17702, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17703, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5249
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17704, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17705, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17706, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0721
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17707, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17708, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17709, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17710, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4132
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17711, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1192
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17712, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17713, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2152
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17714, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17715, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17716, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3452
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17717, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0713
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17718, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17719, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17720, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1741
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17721, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3787
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17722, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17723, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.3466
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17724, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5233
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17725, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17726, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1515
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17727, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4440
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17728, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17729, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17730, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.8718
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17731, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0815
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17732, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.4598
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17733, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2943
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17734, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.9580
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17735, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.7580
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17736, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17737, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17738, num samples collected 8000, FPS 26
  Algorithm: train_loss 1.0679
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17739, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.6908
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17740, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0602
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17741, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17742, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1983
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17743, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0399
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17744, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0750
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17745, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1895
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17746, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5239
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17747, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17748, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2921
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17749, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17750, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5258
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17751, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.1623
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17752, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.5405
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17753, num samples collected 8000, FPS 26
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17754, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4620
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17755, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17756, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17757, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17758, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0590
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17759, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17760, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17761, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4761
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17762, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2134
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17763, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17764, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2440
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17765, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17766, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1179
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17767, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1520
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17768, num samples collected 8000, FPS 25
  Algorithm: train_loss 2.0299
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17769, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17770, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2765
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17771, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17772, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0037
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17773, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.1407
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17774, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17775, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3546
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17776, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17777, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1175
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17778, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4178
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17779, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0292
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17780, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0259
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17781, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5477
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17782, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1646
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17783, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17784, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17785, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17786, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5224
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17787, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3961
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17788, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5253
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17789, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1270
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17790, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6538
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17791, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17792, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17793, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5040
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17794, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0449
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17795, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17796, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17797, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17798, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6019
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17799, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17800, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17801, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2672
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17802, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17803, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17804, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2585
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17805, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17806, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17807, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1467
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17808, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17809, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5154
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17810, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4206
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17811, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17812, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5205
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17813, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2833
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17814, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8718
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17815, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17816, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17817, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1266
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17818, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17819, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2788
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17820, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17821, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17822, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17823, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17824, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7744
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17825, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17826, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2809
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17827, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6612
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17828, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3405
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17829, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17830, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17831, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6621
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17832, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17833, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17834, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1464
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17835, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6009
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17836, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6936
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17837, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1246
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17838, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3824
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17839, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17840, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4785
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17841, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17842, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17843, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17844, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17845, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17846, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17847, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17848, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2232
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17849, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17850, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0569
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17851, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1648
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17852, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17853, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2707
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17854, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4481
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17855, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2799
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17856, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2407
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17857, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17858, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2729
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17859, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17860, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5299
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17861, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1939
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17862, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17863, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8314
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17864, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17865, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17866, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2975
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17867, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7181
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17868, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17869, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3967
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17870, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.2552
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17871, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17872, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4314
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17873, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0785
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17874, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1415
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17875, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17876, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17877, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17878, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3987
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17879, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0587
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17880, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17881, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17882, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17883, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17884, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0421
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17885, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6063
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17886, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6233
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17887, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17888, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6428
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17889, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17890, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4382
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17891, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17892, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1587
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17893, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1193
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17894, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17895, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1390
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17896, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17897, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17898, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0688
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17899, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17900, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0596
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17901, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17902, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17903, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17904, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17905, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17906, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17907, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17908, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3617
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17909, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4467
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17910, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2580
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17911, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17912, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4612
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17913, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17914, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1617
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17915, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0922
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17916, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17917, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7190
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17918, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17919, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17920, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7639
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17921, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17922, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0555
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17923, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17924, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5731
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17925, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9335
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17926, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2270
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17927, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3631
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17928, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3966
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17929, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5140
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17930, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17931, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0784
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17932, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17933, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17934, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17935, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.1975
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17936, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0683
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17937, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17938, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0487
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17939, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17940, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6996
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17941, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17942, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3888
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17943, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4756
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17944, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17945, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17946, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1225
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17947, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0617
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17948, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17949, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17950, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17951, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7035
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17952, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17953, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17954, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17955, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5635
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17956, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17957, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17958, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1100
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17959, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17960, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17961, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17962, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17963, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1009
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17964, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3667
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17965, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17966, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6452
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17967, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17968, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17969, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1185
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17970, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0931
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17971, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4350
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17972, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17973, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17974, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17975, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3427
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17976, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2229
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17977, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0815
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17978, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17979, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4340
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17980, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4012
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17981, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17982, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2670
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17983, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3177
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17984, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17985, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17986, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1210
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17987, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5990
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17988, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3413
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17989, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17990, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17991, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17992, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4846
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17993, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0912
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17994, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.2309
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17995, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17996, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6514
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17997, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17998, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 17999, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18000, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18001, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1801
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18002, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1759
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18003, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18004, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0697
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18005, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18006, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1316
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18007, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18008, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4685
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18009, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18010, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18011, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18012, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18013, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18014, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5903
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18015, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5279
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18016, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18017, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18018, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2957
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18019, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18020, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18021, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18022, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2149
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18023, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3218
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18024, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18025, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6000
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18026, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18027, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18028, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18029, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18030, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18031, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18032, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18033, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18034, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18035, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18036, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18037, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1207
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18038, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8260
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18039, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4637
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18040, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18041, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18042, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18043, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18044, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18045, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8813
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18046, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18047, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18048, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1926
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18049, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18050, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5260
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18051, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18052, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5418
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18053, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18054, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1189
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18055, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8792
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18056, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18057, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3196
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18058, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18059, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18060, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18061, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0734
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18062, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4918
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18063, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18064, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18065, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2122
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18066, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18067, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5410
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18068, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0818
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18069, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2889
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18070, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18071, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18072, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8317
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18073, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18074, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18075, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18076, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3749
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18077, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18078, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4472
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18079, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4429
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18080, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18081, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0629
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18082, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0294
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18083, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1177
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18084, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1995
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18085, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6704
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18086, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18087, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18088, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.7673
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18089, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3893
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18090, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6491
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18091, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18092, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3885
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18093, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8204
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18094, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0892
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18095, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0811
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18096, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6282
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18097, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18098, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1315
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18099, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18100, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18101, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7688
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18102, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4645
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18103, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18104, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18105, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18106, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18107, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18108, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18109, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18110, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18111, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18112, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.1623
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18113, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18114, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1150
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18115, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18116, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1192
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18117, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1238
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18118, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18119, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0607
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18120, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18121, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18122, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0693
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18123, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1552
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18124, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18125, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6272
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18126, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18127, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18128, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18129, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18130, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18131, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18132, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4386
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18133, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18134, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18135, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18136, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18137, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18138, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.1930
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18139, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8746
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18140, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18141, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4654
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18142, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8120
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18143, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18144, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18145, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18146, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18147, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5095
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18148, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18149, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4773
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18150, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8615
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18151, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18152, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18153, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18154, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18155, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0223
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18156, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18157, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1362
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18158, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18159, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2586
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18160, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18161, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18162, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18163, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18164, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18165, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0706
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18166, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0598
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18167, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4645
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18168, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18169, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3899
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18170, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18171, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4935
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18172, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18173, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18174, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18175, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7240
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18176, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5778
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18177, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4475
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18178, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2729
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18179, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6222
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18180, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18181, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1781
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18182, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18183, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.2832
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18184, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18185, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18186, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18187, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1206
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18188, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18189, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18190, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18191, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1614
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18192, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18193, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18194, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4225
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18195, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5513
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18196, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18197, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18198, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1624
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18199, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18200, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18201, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0796
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18202, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18203, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18204, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6126
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18205, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18206, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.3572
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18207, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4053
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18208, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18209, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0663
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18210, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18211, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18212, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18213, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2270
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18214, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18215, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18216, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8776
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18217, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18218, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1845
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18219, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18220, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5266
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18221, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18222, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18223, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4784
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18224, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8932
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18225, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18226, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18227, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18228, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0284
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18229, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0843
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18230, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18231, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18232, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18233, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18234, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1945
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18235, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18236, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18237, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7424
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18238, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18239, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1230
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18240, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1874
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18241, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2038
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18242, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18243, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18244, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2023
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18245, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18246, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18247, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4415
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18248, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0262
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18249, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18250, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5857
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18251, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18252, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18253, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1747
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18254, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0386
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18255, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18256, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4504
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18257, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0620
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18258, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2325
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18259, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0820
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18260, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2011
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18261, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2278
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18262, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2156
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18263, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18264, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18265, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1213
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18266, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18267, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18268, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18269, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18270, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18271, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4404
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18272, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1465
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18273, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2917
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18274, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18275, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18276, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2622
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18277, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18278, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5229
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18279, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5634
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18280, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18281, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18282, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2542
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18283, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18284, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4053
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18285, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6708
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18286, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18287, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1130
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18288, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18289, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7869
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18290, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18291, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18292, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18293, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4230
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18294, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18295, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18296, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18297, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2167
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18298, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4364
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18299, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3906
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18300, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1490
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18301, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1178
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18302, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18303, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1435
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18304, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18305, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5063
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18306, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0350
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18307, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4353
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18308, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18309, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18310, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18311, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1467
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18312, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6357
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18313, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18314, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18315, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18316, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18317, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18318, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4291
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18319, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8931
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18320, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18321, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18322, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18323, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5472
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18324, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2167
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18325, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18326, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2971
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18327, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18328, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18329, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1204
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18330, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18331, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4283
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18332, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18333, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6495
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18334, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18335, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18336, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18337, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6358
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18338, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18339, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18340, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18341, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18342, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18343, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2465
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18344, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18345, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18346, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18347, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18348, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18349, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18350, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18351, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0176
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18352, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6715
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18353, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5308
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18354, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4485
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18355, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18356, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0191
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18357, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1216
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18358, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8292
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18359, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1900
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18360, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0637
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18361, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18362, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4945
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18363, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6013
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18364, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18365, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18366, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0660
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18367, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18368, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18369, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18370, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18371, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0225
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18372, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7291
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18373, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18374, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1580
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18375, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18376, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18377, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18378, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2032
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18379, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0348
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18380, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18381, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18382, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18383, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2869
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18384, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18385, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18386, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1591
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18387, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0237
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18388, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4305
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18389, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18390, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4490
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18391, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5407
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18392, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7799
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18393, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18394, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18395, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5252
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18396, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18397, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2671
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18398, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2045
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18399, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18400, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18401, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18402, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18403, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1548
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18404, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18405, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18406, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2913
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18407, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18408, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8525
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18409, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18410, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18411, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0921
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18412, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18413, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3543
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18414, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4186
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18415, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0675
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18416, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18417, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18418, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5186
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18419, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4398
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18420, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0827
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18421, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5733
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18422, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0691
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18423, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18424, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0905
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18425, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18426, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4945
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18427, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7497
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18428, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2674
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18429, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7151
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18430, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18431, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18432, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18433, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18434, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1902
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18435, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18436, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18437, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5525
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18438, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18439, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2782
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18440, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5703
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18441, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18442, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0856
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18443, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18444, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0882
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18445, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8224
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18446, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3427
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18447, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18448, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18449, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2674
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18450, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18451, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2709
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18452, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18453, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18454, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18455, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18456, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3152
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18457, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18458, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18459, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4639
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18460, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18461, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18462, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5414
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18463, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6851
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18464, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9155
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18465, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18466, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3545
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18467, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1532
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18468, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7258
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18469, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18470, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18471, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18472, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18473, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18474, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18475, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4055
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18476, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18477, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8730
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18478, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8669
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18479, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18480, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4470
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18481, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18482, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4255
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18483, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0271
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18484, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2292
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18485, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18486, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3341
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18487, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1777
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18488, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18489, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18490, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18491, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2572
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18492, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2782
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18493, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0742
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18494, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0433
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18495, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1201
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18496, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5228
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18497, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18498, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18499, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7257
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18500, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18501, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18502, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5470
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18503, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1803
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18504, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18505, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18506, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3644
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18507, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18508, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1042
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18509, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18510, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0961
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18511, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9703
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18512, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18513, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4250
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18514, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18515, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18516, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1799
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18517, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1223
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18518, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1770
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18519, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0273
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18520, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18521, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1943
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18522, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2892
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18523, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4403
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18524, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18525, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2732
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18526, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5837
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18527, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5747
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18528, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18529, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18530, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3635
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18531, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5916
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18532, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18533, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18534, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2942
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18535, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18536, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18537, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0588
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18538, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6909
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18539, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0452
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18540, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8851
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18541, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18542, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18543, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4819
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18544, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2722
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18545, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3657
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18546, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18547, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9249
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18548, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18549, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1800
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18550, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2532
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18551, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0774
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18552, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18553, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6195
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18554, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18555, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18556, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18557, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2077
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18558, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4321
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18559, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18560, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18561, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18562, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8515
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18563, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18564, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18565, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18566, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18567, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18568, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2233
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18569, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0031
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18570, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18571, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18572, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18573, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18574, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18575, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2560
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18576, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18577, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18578, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18579, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1823
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18580, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18581, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18582, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18583, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0406
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18584, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18585, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3297
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18586, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0596
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18587, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4160
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18588, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1199
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18589, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18590, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2019
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18591, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18592, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.3807
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18593, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9714
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18594, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18595, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1492
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18596, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18597, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18598, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7297
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18599, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1020
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18600, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3865
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18601, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4294
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18602, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18603, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2132
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18604, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3994
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18605, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7495
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18606, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8526
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18607, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2646
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18608, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18609, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1339
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18610, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8812
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18611, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4454
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18612, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18613, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18614, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0312
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18615, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18616, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18617, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2435
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18618, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18619, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18620, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2994
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18621, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18622, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4143
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18623, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0671
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18624, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18625, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3835
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18626, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18627, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18628, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18629, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18630, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0824
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18631, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18632, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18633, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18634, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1724
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18635, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7631
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18636, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18637, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18638, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18639, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2224
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18640, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18641, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18642, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5038
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18643, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1274
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18644, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7489
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18645, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7502
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18646, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18647, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18648, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1577
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18649, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18650, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18651, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3339
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18652, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18653, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3065
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18654, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18655, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1609
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18656, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18657, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18658, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0693
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18659, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8242
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18660, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3954
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18661, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18662, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1895
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18663, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18664, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18665, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2589
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18666, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18667, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8723
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18668, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18669, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2370
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18670, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18671, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6417
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18672, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1748
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18673, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18674, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18675, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18676, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18677, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18678, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4484
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18679, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5919
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18680, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8312
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18681, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18682, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18683, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18684, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18685, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6515
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18686, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18687, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3369
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18688, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1981
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18689, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18690, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6715
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18691, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18692, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2982
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18693, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18694, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0835
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18695, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1458
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18696, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0042
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18697, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1908
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18698, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0248
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18699, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18700, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18701, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2912
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18702, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18703, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18704, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18705, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18706, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0610
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18707, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18708, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18709, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1583
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18710, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2144
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18711, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18712, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2887
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18713, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1185
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18714, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3453
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18715, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18716, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18717, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18718, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18719, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5541
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18720, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0747
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18721, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9524
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18722, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18723, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18724, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18725, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0598
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18726, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6955
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18727, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18728, num samples collected 8000, FPS 25
  Algorithm: train_loss 2.5967
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18729, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18730, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18731, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18732, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2262
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18733, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4825
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18734, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18735, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9559
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18736, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5070
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18737, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18738, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18739, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18740, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18741, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18742, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18743, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4108
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18744, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3481
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18745, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2354
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18746, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1602
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18747, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18748, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3394
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18749, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0755
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18750, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3426
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18751, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18752, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9265
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18753, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18754, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2067
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18755, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1999
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18756, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18757, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18758, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1713
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18759, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18760, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18761, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0639
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18762, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5207
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18763, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1347
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18764, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4361
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18765, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18766, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18767, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18768, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1830
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18769, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9302
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18770, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3351
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18771, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18772, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2658
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18773, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18774, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4269
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18775, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18776, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3136
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18777, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1493
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18778, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1236
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18779, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18780, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18781, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18782, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18783, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4386
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18784, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18785, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18786, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1788
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18787, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6497
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18788, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18789, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0674
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18790, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18791, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18792, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0028
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18793, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18794, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4867
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18795, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18796, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3380
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18797, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18798, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1728
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18799, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18800, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8398
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18801, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3183
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18802, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18803, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1512
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18804, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18805, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18806, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0696
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18807, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0293
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18808, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18809, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18810, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18811, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7164
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18812, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5413
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18813, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4383
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18814, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18815, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18816, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18817, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18818, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18819, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18820, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18821, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0319
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18822, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18823, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4409
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18824, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7841
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18825, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0885
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18826, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18827, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18828, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6033
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18829, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18830, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0303
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18831, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18832, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18833, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18834, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4635
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18835, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18836, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0332
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18837, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3387
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18838, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18839, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18840, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1180
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18841, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18842, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4199
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18843, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18844, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18845, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18846, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0638
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18847, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3729
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18848, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18849, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18850, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18851, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18852, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1671
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18853, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1434
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18854, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5948
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18855, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7182
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18856, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.9777
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18857, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18858, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18859, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3908
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18860, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18861, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18862, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.5541
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18863, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2939
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18864, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2309
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18865, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0294
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18866, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0400
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18867, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18868, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3009
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18869, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18870, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18871, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18872, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18873, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3206
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18874, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1898
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18875, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18876, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18877, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18878, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18879, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7016
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18880, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7218
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18881, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5781
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18882, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2576
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18883, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4377
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18884, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1048
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18885, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18886, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5035
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18887, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0282
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18888, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1460
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18889, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18890, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7370
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18891, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4610
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18892, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18893, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2842
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18894, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4128
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18895, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1612
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18896, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9404
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18897, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18898, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0370
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18899, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18900, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18901, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3676
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18902, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2513
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18903, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18904, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18905, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18906, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18907, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4331
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18908, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18909, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2185
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18910, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7821
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18911, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18912, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18913, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3064
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18914, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18915, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0244
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18916, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6498
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18917, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18918, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18919, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18920, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18921, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18922, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18923, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2607
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18924, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2313
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18925, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2066
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18926, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0928
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18927, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18928, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18929, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0414
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18930, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4562
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18931, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7178
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18932, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18933, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18934, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18935, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18936, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6817
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18937, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5808
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18938, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18939, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18940, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4377
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18941, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7439
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18942, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3432
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18943, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18944, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18945, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0612
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18946, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2113
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18947, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2088
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18948, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18949, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4296
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18950, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18951, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1574
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18952, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18953, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3056
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18954, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0693
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18955, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4394
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18956, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18957, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18958, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1377
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18959, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0996
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18960, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4418
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18961, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18962, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18963, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18964, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1368
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18965, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18966, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.0331
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18967, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18968, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18969, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18970, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18971, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7028
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18972, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5255
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18973, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8727
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18974, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18975, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18976, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18977, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6215
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18978, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18979, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18980, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6259
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18981, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18982, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0764
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18983, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2073
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18984, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18985, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6270
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18986, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18987, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18988, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1333
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18989, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18990, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6152
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18991, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18992, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18993, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18994, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0557
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18995, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2615
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18996, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2341
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18997, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18998, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4194
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 18999, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19000, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1837
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19001, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0751
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19002, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3425
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19003, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19004, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6775
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19005, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19006, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4419
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19007, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19008, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1362
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19009, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7093
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19010, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2375
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19011, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19012, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19013, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19014, num samples collected 8000, FPS 25
  Algorithm: train_loss 1.2023
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19015, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1588
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19016, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19017, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0439
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19018, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5262
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19019, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4328
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19020, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19021, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19022, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19023, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19024, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19025, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6705
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19026, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0901
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19027, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19028, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19029, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19030, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2399
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19031, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19032, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1154
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19033, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5825
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19034, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19035, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8980
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19036, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19037, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0230
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19038, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19039, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1049
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19040, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19041, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19042, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5170
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19043, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0411
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19044, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19045, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8352
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19046, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3864
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19047, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.8025
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19048, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19049, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.9160
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19050, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19051, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1287
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19052, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1258
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19053, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1778
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19054, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19055, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1568
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19056, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19057, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3528
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19058, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19059, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19060, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1090
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19061, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19062, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4421
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19063, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5318
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19064, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19065, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19066, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1005
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19067, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.6736
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19068, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19069, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2061
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19070, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4174
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19071, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.7156
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19072, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.5480
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19073, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19074, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.3397
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19075, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0627
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19076, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0405
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19077, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.2413
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19078, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.1882
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19079, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.4221
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19080, num samples collected 8000, FPS 25
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1686.7140, l 200.0000, t 389.9808, TestReward -1647.8561
Update 19081, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2311
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19082, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3596
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19083, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5366
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19084, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19085, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1794
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19086, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19087, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19088, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19089, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3575
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19090, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19091, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0690
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19092, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0372
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19093, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5633
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19094, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19095, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5005
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19096, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19097, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19098, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19099, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19100, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0264
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19101, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0627
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19102, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19103, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3738
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19104, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19105, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19106, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6770
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19107, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2378
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19108, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19109, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1139
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19110, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19111, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19112, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3217
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19113, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4897
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19114, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19115, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19116, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0382
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19117, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5330
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19118, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6833
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19119, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1816
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19120, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19121, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0948
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19122, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19123, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2058
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19124, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1339
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19125, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3333
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19126, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4178
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19127, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1797
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19128, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0757
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19129, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19130, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4311
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19131, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4480
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19132, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19133, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2287
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19134, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4572
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19135, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19136, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19137, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19138, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19139, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3844
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19140, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19141, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3290
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19142, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19143, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19144, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6048
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19145, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3641
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19146, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19147, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19148, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19149, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19150, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19151, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0408
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19152, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1036
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19153, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3624
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19154, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1698
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19155, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19156, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19157, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19158, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19159, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1233
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19160, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7203
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19161, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19162, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19163, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19164, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5364
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19165, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19166, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2768
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19167, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1633
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19168, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19169, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19170, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2438
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19171, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5396
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19172, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2223
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19173, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1357
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19174, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19175, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5313
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19176, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19177, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19178, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2439
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19179, num samples collected 8250, FPS 24
  Algorithm: train_loss 2.5497
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19180, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19181, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19182, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1417
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19183, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19184, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19185, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0484
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19186, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19187, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0247
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19188, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19189, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19190, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19191, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1013
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19192, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4282
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19193, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19194, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2298
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19195, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19196, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19197, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1756
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19198, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0566
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19199, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19200, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19201, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19202, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5433
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19203, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4556
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19204, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0031
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19205, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19206, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19207, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7138
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19208, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2201
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19209, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19210, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19211, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19212, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4517
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19213, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3050
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19214, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19215, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19216, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19217, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19218, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19219, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1057
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19220, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19221, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19222, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2186
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19223, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19224, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19225, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19226, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19227, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19228, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2262
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19229, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5133
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19230, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2724
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19231, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4241
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19232, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19233, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1679
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19234, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3327
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19235, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4528
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19236, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19237, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3568
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19238, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2632
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19239, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0218
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19240, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8298
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19241, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19242, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0235
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19243, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0763
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19244, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19245, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19246, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7241
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19247, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19248, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2251
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19249, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1934
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19250, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0727
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19251, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4403
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19252, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19253, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19254, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4450
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19255, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1250
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19256, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0699
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19257, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19258, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19259, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19260, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19261, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2205
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19262, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4349
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19263, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6954
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19264, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19265, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19266, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19267, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3222
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19268, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19269, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19270, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19271, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2769
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19272, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19273, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19274, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6609
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19275, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2263
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19276, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1983
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19277, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19278, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19279, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1292
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19280, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4416
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19281, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6367
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19282, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4385
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19283, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5421
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19284, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19285, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19286, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2174
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19287, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19288, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19289, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19290, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0736
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19291, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4425
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19292, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19293, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19294, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19295, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19296, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0965
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19297, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6670
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19298, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19299, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19300, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2199
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19301, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0752
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19302, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19303, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2242
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19304, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19305, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1695
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19306, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4296
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19307, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19308, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19309, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3326
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19310, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19311, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19312, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1028
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19313, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9213
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19314, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19315, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19316, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19317, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19318, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3658
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19319, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1493
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19320, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1115
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19321, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19322, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19323, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19324, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0983
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19325, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19326, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4257
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19327, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19328, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19329, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4930
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19330, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19331, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3674
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19332, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19333, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3686
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19334, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19335, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4389
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19336, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19337, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.2940
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19338, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19339, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0368
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19340, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1862
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19341, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1258
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19342, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3756
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19343, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2718
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19344, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19345, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19346, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0970
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19347, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19348, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3803
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19349, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5854
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19350, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5269
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19351, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19352, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19353, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5469
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19354, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1469
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19355, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8766
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19356, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19357, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19358, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19359, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19360, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19361, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19362, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0683
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19363, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19364, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19365, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0767
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19366, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6538
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19367, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19368, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3988
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19369, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3768
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19370, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19371, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5075
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19372, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19373, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19374, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19375, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2391
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19376, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19377, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19378, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19379, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2707
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19380, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19381, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1212
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19382, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19383, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7048
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19384, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19385, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19386, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19387, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9338
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19388, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19389, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1820
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19390, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2840
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19391, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3039
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19392, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4880
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19393, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2123
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19394, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19395, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19396, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19397, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19398, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1170
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19399, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4392
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19400, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0582
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19401, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1472
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19402, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5313
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19403, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9443
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19404, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19405, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0670
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19406, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19407, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19408, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19409, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4601
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19410, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19411, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19412, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19413, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6539
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19414, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19415, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4223
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19416, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19417, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0767
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19418, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19419, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1312
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19420, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9178
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19421, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1774
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19422, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5235
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19423, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19424, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4212
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19425, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4313
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19426, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2296
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19427, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19428, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1767
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19429, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7450
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19430, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19431, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5701
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19432, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0286
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19433, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19434, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1205
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19435, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19436, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0634
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19437, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19438, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4341
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19439, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19440, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5232
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19441, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19442, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19443, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19444, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19445, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19446, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19447, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19448, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2199
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19449, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19450, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2055
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19451, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19452, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0638
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19453, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6372
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19454, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19455, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19456, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0238
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19457, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2677
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19458, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19459, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1830
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19460, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2629
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19461, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19462, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6881
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19463, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6537
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19464, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19465, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19466, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2373
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19467, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5875
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19468, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4479
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19469, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19470, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4309
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19471, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1666
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19472, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19473, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19474, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19475, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2286
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19476, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6182
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19477, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19478, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19479, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19480, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19481, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19482, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19483, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1608
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19484, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19485, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19486, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19487, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19488, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19489, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19490, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19491, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3993
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19492, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1017
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19493, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6199
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19494, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1179
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19495, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1522
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19496, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5604
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19497, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0747
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19498, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19499, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3389
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19500, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6445
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19501, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1676
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19502, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1969
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19503, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19504, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19505, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0933
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19506, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0826
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19507, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19508, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2917
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19509, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19510, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0715
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19511, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4732
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19512, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7236
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19513, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2006
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19514, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0581
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19515, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19516, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2142
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19517, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4654
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19518, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0346
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19519, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1277
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19520, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19521, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2712
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19522, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5723
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19523, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19524, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2437
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19525, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8301
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19526, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2900
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19527, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19528, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2463
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19529, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2214
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19530, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19531, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19532, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19533, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8646
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19534, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19535, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19536, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19537, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1641
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19538, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19539, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19540, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19541, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1546
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19542, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8966
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19543, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5701
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19544, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5224
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19545, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19546, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4601
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19547, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1873
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19548, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0802
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19549, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2834
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19550, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6899
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19551, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0479
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19552, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1173
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19553, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19554, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19555, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19556, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1855
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19557, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2354
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19558, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0639
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19559, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19560, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19561, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19562, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19563, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9495
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19564, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5175
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19565, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2888
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19566, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3427
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19567, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0697
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19568, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19569, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19570, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2125
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19571, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19572, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19573, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19574, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5261
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19575, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19576, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7114
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19577, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4624
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19578, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19579, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19580, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8954
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19581, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19582, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1613
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19583, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5175
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19584, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0680
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19585, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19586, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5438
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19587, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19588, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5899
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19589, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0413
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19590, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2049
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19591, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2721
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19592, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19593, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19594, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19595, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19596, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19597, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1787
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19598, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5459
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19599, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19600, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19601, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19602, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3331
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19603, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19604, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19605, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19606, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19607, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2005
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19608, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19609, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1836
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19610, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19611, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19612, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19613, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1572
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19614, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19615, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7715
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19616, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1606
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19617, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19618, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0040
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19619, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19620, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2525
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19621, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19622, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19623, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19624, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2923
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19625, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5015
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19626, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0658
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19627, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1443
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19628, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3440
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19629, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19630, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0747
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19631, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1028
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19632, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19633, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1348
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19634, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19635, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6294
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19636, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19637, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6479
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19638, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5147
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19639, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3522
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19640, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2366
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19641, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19642, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19643, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19644, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3522
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19645, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9496
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19646, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2264
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19647, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19648, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19649, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1001
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19650, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19651, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6283
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19652, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0980
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19653, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19654, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19655, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1227
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19656, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1219
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19657, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2144
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19658, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19659, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19660, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19661, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19662, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19663, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19664, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4270
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19665, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4666
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19666, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0554
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19667, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19668, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1715
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19669, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1133
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19670, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0933
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19671, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19672, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1460
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19673, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7258
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19674, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19675, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19676, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19677, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2049
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19678, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2963
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19679, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0729
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19680, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7921
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19681, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2508
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19682, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8673
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19683, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19684, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2350
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19685, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19686, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0645
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19687, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3203
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19688, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19689, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19690, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2346
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19691, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19692, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2794
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19693, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2410
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19694, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19695, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19696, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19697, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19698, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5617
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19699, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0257
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19700, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0619
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19701, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0267
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19702, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3235
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19703, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19704, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1307
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19705, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19706, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4201
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19707, num samples collected 8250, FPS 24
  Algorithm: train_loss 2.3090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19708, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19709, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0953
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19710, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1135
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19711, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2246
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19712, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1399
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19713, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3117
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19714, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19715, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19716, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19717, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19718, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19719, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19720, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3295
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19721, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5301
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19722, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0734
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19723, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19724, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7295
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19725, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0461
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19726, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19727, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19728, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19729, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19730, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7197
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19731, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19732, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4538
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19733, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19734, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1012
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19735, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2812
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19736, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3256
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19737, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19738, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0395
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19739, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4400
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19740, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19741, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19742, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19743, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1386
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19744, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0965
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19745, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7176
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19746, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19747, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6285
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19748, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5387
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19749, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19750, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2285
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19751, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1135
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19752, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19753, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7476
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19754, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19755, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1754
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19756, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0688
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19757, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6376
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19758, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0175
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19759, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1591
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19760, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2161
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19761, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19762, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3421
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19763, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19764, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19765, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19766, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0703
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19767, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0933
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19768, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19769, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4951
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19770, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5217
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19771, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19772, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19773, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19774, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1428
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19775, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19776, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0945
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19777, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19778, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19779, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19780, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19781, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1445
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19782, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19783, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19784, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19785, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1248
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19786, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6952
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19787, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19788, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0328
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19789, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19790, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19791, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19792, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4924
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19793, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19794, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0730
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19795, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19796, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7201
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19797, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19798, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5039
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19799, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1911
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19800, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19801, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8909
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19802, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0863
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19803, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19804, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3115
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19805, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19806, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0798
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19807, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2811
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19808, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19809, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19810, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2542
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19811, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19812, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1136
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19813, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0183
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19814, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0906
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19815, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0421
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19816, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1768
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19817, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19818, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3352
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19819, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3926
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19820, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19821, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7208
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19822, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0767
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19823, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2031
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19824, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5358
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19825, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0178
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19826, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19827, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19828, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7306
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19829, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19830, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4861
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19831, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9663
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19832, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19833, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19834, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4691
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19835, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5714
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19836, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2266
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19837, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19838, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2207
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19839, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19840, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19841, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19842, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19843, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19844, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19845, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6367
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19846, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19847, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19848, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19849, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19850, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7027
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19851, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3383
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19852, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7775
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19853, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1300
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19854, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7041
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19855, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19856, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4191
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19857, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19858, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4364
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19859, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0730
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19860, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1032
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19861, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2039
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19862, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19863, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1439
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19864, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19865, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2493
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19866, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19867, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1928
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19868, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19869, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4008
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19870, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6260
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19871, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4552
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19872, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2261
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19873, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3707
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19874, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19875, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5640
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19876, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19877, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1479
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19878, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0277
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19879, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19880, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2796
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19881, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19882, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1669
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19883, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5401
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19884, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4739
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19885, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19886, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19887, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0192
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19888, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2710
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19889, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19890, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19891, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19892, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1400
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19893, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4495
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19894, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19895, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2227
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19896, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6358
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19897, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19898, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2507
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19899, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1179
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19900, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19901, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19902, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9279
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19903, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19904, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19905, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19906, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19907, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19908, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19909, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19910, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19911, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19912, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19913, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4189
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19914, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19915, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1947
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19916, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19917, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1701
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19918, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19919, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2204
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19920, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19921, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19922, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0721
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19923, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2616
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19924, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19925, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19926, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0737
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19927, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19928, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19929, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1835
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19930, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4570
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19931, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2375
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19932, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5912
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19933, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3701
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19934, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2129
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19935, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1959
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19936, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3784
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19937, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19938, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0512
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19939, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4696
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19940, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1062
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19941, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19942, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3537
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19943, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19944, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19945, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5301
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19946, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19947, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1868
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19948, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4339
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19949, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19950, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0135
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19951, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19952, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19953, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19954, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19955, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19956, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8544
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19957, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1346
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19958, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0282
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19959, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9458
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19960, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1444
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19961, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19962, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4182
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19963, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19964, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19965, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4535
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19966, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19967, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19968, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3476
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19969, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19970, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19971, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2774
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19972, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19973, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19974, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1834
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19975, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19976, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19977, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0330
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19978, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19979, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0666
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19980, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19981, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19982, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19983, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19984, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0937
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19985, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19986, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5342
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19987, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0999
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19988, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19989, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19990, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7161
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19991, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1762
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19992, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8635
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19993, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19994, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19995, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1197
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19996, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1794
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19997, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19998, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5049
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 19999, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6550
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20000, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20001, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20002, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20003, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3684
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20004, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2878
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20005, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20006, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1827
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20007, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1997
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20008, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20009, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3528
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20010, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20011, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2380
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20012, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20013, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0716
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20014, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0907
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20015, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20016, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1365
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20017, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0529
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20018, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20019, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20020, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0173
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20021, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3786
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20022, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20023, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6344
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20024, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3261
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20025, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20026, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20027, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20028, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20029, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1314
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20030, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4461
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20031, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1725
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20032, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2245
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20033, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20034, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7095
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20035, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5703
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20036, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20037, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20038, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20039, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5653
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20040, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1673
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20041, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20042, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1500
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20043, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4180
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20044, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20045, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20046, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20047, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.2225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20048, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20049, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20050, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2229
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20051, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20052, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1862
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20053, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20054, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4222
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20055, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20056, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1604
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20057, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20058, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20059, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0724
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20060, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7036
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20061, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20062, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0588
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20063, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20064, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20065, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2369
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20066, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8419
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20067, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20068, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1475
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20069, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20070, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20071, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20072, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20073, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20074, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2633
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20075, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20076, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0700
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20077, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2716
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20078, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20079, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3617
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20080, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20081, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0854
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20082, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20083, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2615
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20084, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20085, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0680
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20086, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6616
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20087, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20088, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4187
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20089, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20090, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5216
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20091, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0182
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20092, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8322
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20093, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0095
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20094, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20095, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20096, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20097, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0331
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20098, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2257
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20099, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1517
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20100, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20101, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20102, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5023
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20103, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8459
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20104, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20105, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20106, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20107, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20108, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1232
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20109, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0538
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20110, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6720
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20111, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0742
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20112, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20113, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20114, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20115, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5320
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20116, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20117, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20118, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20119, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20120, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20121, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1865
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20122, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9154
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20123, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4507
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20124, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4615
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20125, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1848
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20126, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1438
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20127, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2300
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20128, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4995
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20129, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9280
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20130, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20131, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1420
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20132, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0764
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20133, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0714
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20134, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20135, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1812
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20136, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9349
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20137, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6203
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20138, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2234
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20139, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0250
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20140, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1035
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20141, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2451
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20142, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2219
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20143, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20144, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4819
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20145, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3247
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20146, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20147, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6219
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20148, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1789
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20149, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20150, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2969
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20151, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1264
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20152, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20153, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1382
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20154, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20155, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20156, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20157, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20158, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20159, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20160, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20161, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20162, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20163, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0306
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20164, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7912
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20165, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20166, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20167, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20168, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7507
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20169, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20170, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20171, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6907
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20172, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20173, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20174, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4037
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20175, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20176, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20177, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20178, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20179, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1310
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20180, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2000
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20181, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0992
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20182, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20183, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1245
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20184, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0043
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20185, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1970
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20186, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20187, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0711
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20188, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4125
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20189, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9003
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20190, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20191, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2191
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20192, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20193, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20194, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1547
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20195, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20196, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6868
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20197, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2133
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20198, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5298
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20199, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20200, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5159
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20201, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2187
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20202, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20203, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.2230
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20204, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20205, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20206, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20207, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1448
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20208, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2685
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20209, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20210, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7075
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20211, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0822
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20212, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20213, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20214, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3842
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20215, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4486
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20216, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2300
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20217, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20218, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2610
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20219, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0827
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20220, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20221, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20222, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3332
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20223, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0820
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20224, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20225, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20226, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3548
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20227, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2776
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20228, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20229, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20230, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20231, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20232, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20233, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2510
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20234, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20235, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20236, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20237, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20238, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20239, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20240, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1433
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20241, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7720
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20242, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20243, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8274
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20244, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20245, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20246, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0357
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20247, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1911
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20248, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0655
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20249, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20250, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20251, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20252, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0790
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20253, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20254, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4204
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20255, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6518
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20256, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5172
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20257, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20258, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20259, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3215
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20260, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20261, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2474
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20262, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4365
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20263, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20264, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0995
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20265, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20266, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2602
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20267, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1211
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20268, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20269, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3414
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20270, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5277
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20271, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20272, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0267
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20273, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2638
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20274, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20275, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20276, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20277, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2172
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20278, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1789
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20279, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20280, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20281, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20282, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3909
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20283, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20284, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20285, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20286, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20287, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20288, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20289, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3026
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20290, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20291, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20292, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5046
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20293, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6852
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20294, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8815
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20295, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1607
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20296, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2964
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20297, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20298, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0869
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20299, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0209
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20300, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7017
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20301, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2557
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20302, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0472
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20303, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1507
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20304, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20305, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1795
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20306, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2699
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20307, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20308, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4940
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20309, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20310, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20311, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1669
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20312, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0243
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20313, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20314, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2952
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20315, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2458
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20316, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20317, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20318, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0361
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20319, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6573
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20320, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20321, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20322, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20323, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20324, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20325, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0672
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20326, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2175
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20327, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20328, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1452
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20329, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2756
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20330, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9861
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20331, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4302
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20332, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0917
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20333, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4516
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20334, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0831
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20335, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4117
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20336, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7030
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20337, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20338, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20339, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0211
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20340, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1879
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20341, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2631
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20342, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4916
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20343, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0984
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20344, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20345, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20346, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20347, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0648
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20348, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3703
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20349, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20350, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1703
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20351, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20352, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20353, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3218
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20354, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20355, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20356, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3889
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20357, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20358, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20359, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0655
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20360, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9781
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20361, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1376
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20362, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1992
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20363, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6592
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20364, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20365, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1938
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20366, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20367, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.8453
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20368, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0672
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20369, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20370, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5224
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20371, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1619
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20372, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1218
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20373, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7172
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20374, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0287
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20375, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.2297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20376, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0874
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20377, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0801
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20378, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20379, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6727
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20380, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20381, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6596
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20382, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20383, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2123
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20384, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2946
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20385, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2376
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20386, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20387, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20388, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20389, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2815
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20390, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20391, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0415
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20392, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20393, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20394, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20395, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7659
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20396, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1316
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20397, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20398, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20399, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0582
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20400, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20401, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20402, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4452
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20403, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20404, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6829
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20405, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5025
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20406, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20407, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1972
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20408, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20409, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3984
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20410, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20411, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2181
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20412, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20413, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0745
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20414, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5860
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20415, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20416, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20417, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7188
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20418, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20419, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20420, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20421, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20422, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20423, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20424, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1628
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20425, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6236
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20426, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20427, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20428, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1735
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20429, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2356
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20430, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3245
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20431, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1224
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20432, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0869
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20433, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20434, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7108
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20435, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0637
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20436, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9634
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20437, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20438, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7459
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20439, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20440, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4166
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20441, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6300
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20442, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3950
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20443, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20444, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20445, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2757
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20446, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20447, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1308
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20448, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20449, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20450, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0734
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20451, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1815
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20452, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1508
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20453, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20454, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0623
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20455, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2261
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20456, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20457, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0717
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20458, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0509
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20459, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1468
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20460, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20461, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20462, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20463, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2176
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20464, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0196
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20465, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9738
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20466, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0780
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20467, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2768
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20468, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1630
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20469, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6851
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20470, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20471, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1257
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20472, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20473, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20474, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1937
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20475, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0645
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20476, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1570
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20477, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20478, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20479, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3928
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20480, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20481, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20482, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9851
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20483, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20484, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20485, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20486, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7600
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20487, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20488, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1832
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20489, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20490, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4233
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20491, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2524
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20492, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20493, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3705
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20494, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0585
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20495, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5273
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20496, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1030
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20497, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20498, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2697
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20499, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20500, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5996
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20501, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20502, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7001
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20503, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3287
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20504, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20505, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4487
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20506, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20507, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4232
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20508, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4308
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20509, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20510, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20511, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20512, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20513, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20514, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0467
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20515, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0980
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20516, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1180
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20517, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1675
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20518, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20519, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0282
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20520, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0978
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20521, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20522, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20523, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20524, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7863
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20525, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.1835
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20526, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1163
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20527, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20528, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0245
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20529, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1340
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20530, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20531, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20532, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5285
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20533, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20534, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0639
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20535, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7127
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20536, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9357
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20537, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20538, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1480
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20539, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20540, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5244
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20541, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0301
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20542, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2388
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20543, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20544, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0445
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20545, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5378
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20546, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20547, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20548, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20549, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20550, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20551, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2786
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20552, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20553, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20554, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20555, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20556, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4628
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20557, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7239
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20558, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20559, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0551
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20560, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20561, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0651
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20562, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1684
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20563, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6635
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20564, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1951
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20565, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20566, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20567, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20568, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0442
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20569, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20570, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7035
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20571, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6566
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20572, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7270
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20573, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20574, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20575, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0833
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20576, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20577, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20578, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20579, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1880
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20580, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0638
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20581, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20582, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20583, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3441
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20584, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1146
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20585, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0968
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20586, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20587, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20588, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3468
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20589, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2750
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20590, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20591, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1658
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20592, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1327
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20593, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.5527
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20594, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2293
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20595, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1294
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20596, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7258
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20597, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1191
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20598, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8849
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20599, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20600, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20601, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20602, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20603, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2681
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20604, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3217
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20605, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20606, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20607, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4194
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20608, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20609, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5328
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20610, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20611, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2896
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20612, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0925
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20613, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1948
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20614, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0667
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20615, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1367
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20616, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7294
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20617, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0349
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20618, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1142
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20619, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1376
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20620, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6693
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20621, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20622, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20623, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20624, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20625, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4567
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20626, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20627, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6338
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20628, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20629, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3356
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20630, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20631, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20632, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20633, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20634, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1828
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20635, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1285
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20636, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20637, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0971
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20638, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5014
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20639, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4044
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20640, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1262
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20641, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20642, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3931
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20643, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20644, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20645, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1726
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20646, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2595
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20647, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20648, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20649, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5588
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20650, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20651, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1022
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20652, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20653, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2324
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20654, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20655, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0234
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20656, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3159
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20657, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5878
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20658, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20659, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5820
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20660, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3155
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20661, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5380
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20662, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0231
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20663, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2156
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20664, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0034
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20665, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3470
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20666, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20667, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20668, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0417
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20669, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0878
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20670, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20671, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20672, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20673, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2664
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20674, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20675, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0929
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20676, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20677, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1954
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20678, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0282
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20679, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20680, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1853
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20681, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1384
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20682, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2899
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20683, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2128
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20684, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4326
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20685, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2220
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20686, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1130
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20687, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8202
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20688, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20689, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20690, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1846
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20691, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2560
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20692, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4387
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20693, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0544
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20694, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5257
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20695, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7336
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20696, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20697, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20698, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1877
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20699, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20700, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0929
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20701, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5675
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20702, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20703, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20704, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20705, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2195
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20706, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0508
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20707, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0911
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20708, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0440
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20709, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20710, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6774
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20711, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3314
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20712, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1653
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20713, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4289
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20714, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6876
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20715, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20716, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20717, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4275
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20718, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20719, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2148
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20720, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20721, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1450
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20722, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3889
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20723, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20724, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1527
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20725, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2139
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20726, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20727, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8498
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20728, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0686
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20729, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1100
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20730, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1727
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20731, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20732, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0912
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20733, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20734, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3021
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20735, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0712
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20736, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20737, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8199
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20738, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20739, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20740, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20741, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6454
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20742, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5297
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20743, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0922
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20744, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4232
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20745, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7612
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20746, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1581
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20747, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0282
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20748, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20749, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6465
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20750, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0719
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20751, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20752, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2281
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20753, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20754, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20755, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5949
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20756, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5628
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20757, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20758, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0417
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20759, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2144
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20760, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0570
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20761, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1861
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20762, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2003
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20763, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0276
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20764, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20765, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20766, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2249
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20767, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20768, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4310
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20769, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1337
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20770, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0618
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20771, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3278
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20772, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20773, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2470
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20774, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5386
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20775, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0787
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20776, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0659
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20777, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7917
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20778, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20779, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20780, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3568
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20781, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3176
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20782, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2437
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20783, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20784, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4230
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20785, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20786, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4432
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20787, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20788, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2488
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20789, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0304
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20790, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0268
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20791, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20792, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6008
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20793, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20794, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20795, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20796, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0045
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20797, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5113
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20798, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2095
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20799, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1428
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20800, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0571
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20801, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20802, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0205
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20803, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3167
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20804, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0563
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20805, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20806, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3017
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20807, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4441
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20808, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0967
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20809, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2008
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20810, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4428
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20811, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20812, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4184
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20813, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2320
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20814, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20815, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20816, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2361
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20817, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1267
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20818, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1355
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20819, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2376
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20820, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1889
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20821, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20822, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20823, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5637
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20824, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20825, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7167
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20826, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7152
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20827, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0708
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20828, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20829, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5476
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20830, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6149
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20831, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20832, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6668
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20833, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4806
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20834, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1424
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20835, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5171
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20836, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9016
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20837, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20838, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0177
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20839, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0202
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20840, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4525
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20841, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20842, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2458
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20843, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3350
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20844, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4371
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20845, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2467
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20846, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0727
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20847, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20848, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0885
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20849, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1327
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20850, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9148
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20851, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0822
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20852, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20853, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2457
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20854, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0969
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20855, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20856, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20857, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20858, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20859, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20860, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2120
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20861, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20862, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20863, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20864, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0181
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20865, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0846
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20866, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3052
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20867, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20868, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5523
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20869, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1431
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20870, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20871, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20872, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20873, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1791
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20874, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0548
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20875, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1659
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20876, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20877, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4266
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20878, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4319
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20879, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2690
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20880, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1148
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20881, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20882, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20883, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8144
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20884, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20885, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20886, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.0310
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20887, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2844
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20888, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20889, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0240
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20890, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0631
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20891, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4309
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20892, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6162
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20893, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1558
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20894, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5197
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20895, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0298
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20896, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1272
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20897, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0855
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20898, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2071
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20899, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2879
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20900, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9141
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20901, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0809
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20902, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20903, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20904, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1236
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20905, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1993
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20906, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0695
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20907, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2225
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20908, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2037
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20909, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20910, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20911, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20912, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1087
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20913, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1354
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20914, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5295
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20915, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0912
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20916, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0662
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20917, num samples collected 8250, FPS 24
  Algorithm: train_loss 1.3223
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20918, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0490
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20919, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5207
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20920, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1061
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20921, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0249
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20922, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20923, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4272
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20924, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1956
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20925, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1771
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20926, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4348
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20927, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1807
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20928, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20929, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20930, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1822
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20931, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1402
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20932, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6164
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20933, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1418
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20934, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2251
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20935, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0829
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20936, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2248
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20937, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2925
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20938, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3852
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20939, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2611
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20940, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2200
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20941, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0136
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20942, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9784
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20943, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20944, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6609
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20945, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20946, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0493
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20947, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5683
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20948, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5028
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20949, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0187
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20950, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20951, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7258
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20952, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20953, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2851
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20954, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20955, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20956, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0597
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20957, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1195
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20958, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2161
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20959, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20960, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20961, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4287
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20962, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1037
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20963, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20964, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0241
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20965, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3284
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20966, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5251
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20967, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20968, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20969, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4208
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20970, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1107
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20971, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20972, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0896
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20973, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1852
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20974, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7529
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20975, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7229
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20976, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20977, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2750
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20978, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20979, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20980, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20981, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1986
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20982, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20983, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20984, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6184
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20985, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4204
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20986, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1542
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20987, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20988, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4457
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20989, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0712
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20990, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20991, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6132
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20992, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20993, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1810
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20994, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20995, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2872
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20996, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.8206
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20997, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2210
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20998, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4608
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 20999, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21000, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1793
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21001, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5315
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21002, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6063
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21003, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21004, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21005, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2430
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21006, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21007, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4568
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21008, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0516
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21009, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2191
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21010, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21011, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0753
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21012, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3721
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21013, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21014, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21015, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.4985
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21016, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21017, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5029
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21018, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2666
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21019, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1507
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21020, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5213
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21021, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21022, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21023, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1526
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21024, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21025, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1433
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21026, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21027, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21028, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2251
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21029, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0895
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21030, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5761
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21031, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.5647
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21032, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2101
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21033, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0458
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21034, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2015
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21035, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9114
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21036, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21037, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1917
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21038, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21039, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2722
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21040, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0166
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21041, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21042, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21043, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21044, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.3712
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21045, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.1886
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21046, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0224
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21047, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21048, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0156
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21049, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21050, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0696
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21051, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2121
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21052, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.7972
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21053, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0246
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21054, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.9941
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21055, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.6220
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21056, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21057, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21058, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21059, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.2163
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21060, num samples collected 8250, FPS 24
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1714.4011, l 200.0000, t 416.9592, TestReward -1154.5951
Update 21061, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21062, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21063, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4401
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21064, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1477
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21065, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3121
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21066, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21067, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21068, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21069, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21070, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21071, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21072, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0748
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21073, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21074, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21075, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0702
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21076, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0675
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21077, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4367
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21078, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.2211
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21079, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21080, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0736
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21081, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21082, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1308
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21083, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21084, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6671
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21085, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21086, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3847
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21087, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21088, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21089, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21090, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1207
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21091, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7808
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21092, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21093, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21094, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0170
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21095, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5820
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21096, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5005
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21097, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1214
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21098, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21099, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21100, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21101, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21102, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21103, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21104, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0129
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21105, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4452
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21106, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7315
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21107, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2291
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21108, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21109, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21110, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21111, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8577
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21112, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21113, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5928
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21114, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21115, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3294
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21116, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2374
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21117, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21118, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0700
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21119, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5487
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21120, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21121, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1483
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21122, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2141
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21123, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0977
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21124, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21125, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7964
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21126, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0723
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21127, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21128, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0141
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21129, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21130, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4019
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21131, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2386
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21132, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21133, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1045
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21134, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6662
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21135, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21136, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2918
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21137, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1708
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21138, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21139, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0588
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21140, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21141, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21142, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21143, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0954
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21144, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21145, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21146, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2176
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21147, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5856
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21148, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5168
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21149, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21150, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9544
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21151, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21152, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21153, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21154, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9539
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21155, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2284
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21156, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2024
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21157, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3416
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21158, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5328
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21159, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21160, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21161, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21162, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21163, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1437
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21164, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2640
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21165, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0759
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21166, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21167, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5372
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21168, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2451
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21169, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4983
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21170, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21171, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7405
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21172, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3381
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21173, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0227
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21174, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9121
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21175, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21176, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0186
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21177, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2245
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21178, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5415
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21179, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21180, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21181, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21182, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4639
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21183, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21184, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3568
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21185, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2847
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21186, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21187, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21188, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4554
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21189, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1039
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21190, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2311
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21191, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2227
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21192, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21193, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21194, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21195, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21196, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21197, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6655
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21198, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0510
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21199, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1427
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21200, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2220
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21201, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2247
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21202, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4338
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21203, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4231
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21204, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21205, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0783
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21206, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3898
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21207, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6850
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21208, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21209, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2194
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21210, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21211, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0546
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21212, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4915
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21213, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21214, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2897
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21215, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5195
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21216, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0303
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21217, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1349
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21218, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0444
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21219, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0150
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21220, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21221, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21222, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0952
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21223, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3588
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21224, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21225, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21226, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21227, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21228, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21229, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5425
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21230, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0027
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21231, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1804
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21232, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21233, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4426
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21234, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0841
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21235, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21236, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0753
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21237, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7424
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21238, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21239, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21240, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21241, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4029
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21242, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1360
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21243, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21244, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21245, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1134
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21246, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21247, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21248, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21249, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1860
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21250, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21251, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1236
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21252, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3964
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21253, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.2655
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21254, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2313
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21255, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21256, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21257, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9773
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21258, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21259, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2440
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21260, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6013
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21261, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21262, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3907
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21263, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0963
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21264, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5831
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21265, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0426
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21266, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4851
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21267, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21268, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1989
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21269, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21270, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1307
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21271, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21272, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0916
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21273, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21274, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0763
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21275, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1912
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21276, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2801
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21277, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0710
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21278, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0299
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21279, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21280, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21281, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21282, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6339
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21283, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3268
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21284, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0352
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21285, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4349
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21286, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5555
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21287, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1916
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21288, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21289, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1662
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21290, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21291, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21292, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21293, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3220
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21294, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1271
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21295, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21296, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9963
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21297, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21298, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0029
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21299, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21300, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1782
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21301, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1531
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21302, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0438
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21303, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1281
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21304, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2763
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21305, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21306, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5423
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21307, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0595
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21308, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21309, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6455
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21310, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21311, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21312, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1452
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21313, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21314, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6450
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21315, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3392
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21316, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0213
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21317, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21318, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2206
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21319, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21320, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21321, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0656
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21322, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21323, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21324, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21325, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6686
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21326, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5513
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21327, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21328, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1626
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21329, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5343
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21330, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0594
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21331, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21332, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21333, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0494
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21334, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21335, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21336, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4367
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21337, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21338, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0827
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21339, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4786
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21340, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21341, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4256
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21342, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0262
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21343, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6902
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21344, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2926
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21345, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4001
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21346, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3227
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21347, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3539
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21348, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2345
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21349, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21350, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0681
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21351, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21352, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7229
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21353, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21354, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21355, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21356, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21357, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1002
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21358, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2196
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21359, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2249
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21360, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21361, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2813
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21362, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21363, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21364, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21365, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5829
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21366, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0122
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21367, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21368, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21369, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21370, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21371, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21372, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0874
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21373, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21374, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21375, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9488
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21376, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0576
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21377, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21378, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3400
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21379, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6461
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21380, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0707
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21381, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21382, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3887
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21383, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0191
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21384, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21385, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2301
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21386, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5364
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21387, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0530
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21388, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1687
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21389, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21390, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3911
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21391, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1901
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21392, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1292
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21393, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0491
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21394, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21395, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8868
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21396, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4577
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21397, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2491
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21398, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0214
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21399, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1921
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21400, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5919
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21401, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21402, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21403, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1029
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21404, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0199
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21405, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0471
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21406, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3447
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21407, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2223
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21408, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7926
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21409, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21410, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.4415
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21411, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21412, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2894
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21413, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21414, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21415, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1371
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21416, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0162
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21417, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1121
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21418, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2712
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21419, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21420, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21421, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0648
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21422, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4307
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21423, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21424, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0631
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21425, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21426, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21427, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0817
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21428, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1844
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21429, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7325
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21430, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21431, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21432, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2971
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21433, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0320
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21434, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21435, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1376
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21436, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3786
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21437, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0755
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21438, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21439, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2237
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21440, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21441, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1330
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21442, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4375
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21443, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2760
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21444, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5710
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21445, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7376
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21446, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1202
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21447, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21448, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1737
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21449, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21450, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0583
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21451, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21452, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21453, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8307
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21454, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7236
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21455, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0281
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21456, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21457, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21458, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21459, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21460, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0851
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21461, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21462, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0516
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21463, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1635
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21464, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0645
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21465, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21466, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21467, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0668
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21468, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21469, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7166
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21470, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0456
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21471, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21472, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4308
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21473, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4357
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21474, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0702
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21475, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1866
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21476, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21477, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21478, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21479, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5616
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21480, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4451
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21481, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1590
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21482, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4373
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21483, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1971
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21484, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0220
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21485, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2208
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21486, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1389
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21487, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21488, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21489, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4388
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21490, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1740
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21491, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21492, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1101
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21493, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21494, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21495, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5147
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21496, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8669
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21497, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21498, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2249
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21499, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21500, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21501, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1361
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21502, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21503, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3548
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21504, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0697
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21505, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21506, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4904
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21507, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21508, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21509, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7421
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21510, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1335
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21511, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1685
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21512, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21513, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21514, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4362
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21515, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21516, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4511
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21517, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2169
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21518, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1279
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21519, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21520, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1748
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21521, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21522, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21523, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7201
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21524, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2941
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21525, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1261
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21526, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0488
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21527, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21528, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21529, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0260
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21530, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4554
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21531, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21532, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2322
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21533, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7340
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21534, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2158
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21535, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21536, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0180
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21537, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21538, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0861
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21539, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21540, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0595
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21541, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6431
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21542, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1306
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21543, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21544, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21545, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0603
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21546, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21547, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5049
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21548, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2329
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21549, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0528
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21550, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21551, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1897
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21552, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21553, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1180
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21554, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0942
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21555, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21556, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7151
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21557, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7890
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21558, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21559, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4505
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21560, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2811
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21561, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1862
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21562, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9239
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21563, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0727
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21564, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1842
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21565, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21566, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21567, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3574
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21568, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21569, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2582
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21570, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21571, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1639
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21572, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21573, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4926
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21574, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21575, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1370
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21576, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0649
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21577, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21578, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3309
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21579, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4820
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21580, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21581, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21582, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21583, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0662
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21584, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0483
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21585, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21586, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1158
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21587, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21588, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9296
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21589, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5183
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21590, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8024
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21591, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21592, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3712
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21593, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1148
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21594, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0981
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21595, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21596, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21597, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21598, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.3719
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21599, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6884
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21600, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21601, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21602, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21603, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2268
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21604, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21605, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3289
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21606, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21607, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5655
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21608, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21609, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21610, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0936
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21611, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2555
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21612, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21613, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21614, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21615, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21616, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21617, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4167
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21618, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21619, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21620, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2238
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21621, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2203
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21622, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21623, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21624, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21625, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5281
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21626, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0812
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21627, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0157
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21628, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1345
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21629, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21630, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5374
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21631, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4534
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21632, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4183
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21633, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21634, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0768
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21635, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21636, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21637, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2855
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21638, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0196
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21639, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0174
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21640, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4734
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21641, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0670
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21642, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21643, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1814
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21644, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1944
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21645, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21646, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21647, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21648, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0701
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21649, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0534
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21650, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21651, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2779
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21652, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6845
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21653, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1003
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21654, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8443
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21655, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1165
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21656, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2102
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21657, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0972
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21658, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3233
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21659, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0808
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21660, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3206
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21661, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21662, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0455
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21663, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1760
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21664, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2242
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21665, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21666, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21667, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0759
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21668, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3408
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21669, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0775
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21670, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1296
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21671, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21672, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6018
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21673, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5263
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21674, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21675, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9355
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21676, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0295
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21677, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1681
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21678, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1839
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21679, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4494
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21680, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2035
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21681, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21682, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1199
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21683, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21684, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21685, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2559
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21686, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0641
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21687, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3561
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21688, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0708
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21689, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21690, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4032
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21691, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3906
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21692, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21693, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21694, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0573
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21695, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21696, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1236
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21697, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1953
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21698, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3175
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21699, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21700, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21701, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21702, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0784
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21703, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21704, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9001
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21705, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4545
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21706, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21707, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21708, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.2466
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21709, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0165
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21710, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4903
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21711, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21712, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0708
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21713, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21714, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21715, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21716, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1622
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21717, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4690
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21718, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4941
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21719, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4277
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21720, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21721, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0246
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21722, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2266
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21723, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21724, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3175
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21725, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21726, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1731
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21727, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21728, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1849
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21729, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6790
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21730, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21731, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0855
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21732, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2804
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21733, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5869
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21734, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21735, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21736, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21737, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1487
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21738, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1495
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21739, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3432
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21740, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21741, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4493
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21742, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21743, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21744, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21745, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1879
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21746, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2480
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21747, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0930
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21748, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6619
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21749, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4239
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21750, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0654
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21751, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1805
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21752, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8986
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21753, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0015
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21754, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2176
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21755, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21756, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1859
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21757, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21758, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21759, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0842
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21760, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21761, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1753
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21762, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21763, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21764, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21765, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21766, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5650
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21767, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8388
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21768, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0195
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21769, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0327
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21770, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2780
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21771, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21772, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0198
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21773, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0601
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21774, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21775, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0193
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21776, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21777, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21778, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21779, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21780, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21781, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21782, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0669
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21783, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0560
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21784, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7746
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21785, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7570
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21786, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21787, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5800
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21788, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1821
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21789, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0302
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21790, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2304
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21791, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21792, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21793, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21794, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1893
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21795, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2488
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21796, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5561
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21797, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21798, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2203
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21799, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21800, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1027
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21801, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0455
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21802, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0053
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21803, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0443
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21804, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21805, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6744
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21806, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2170
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21807, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21808, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1619
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21809, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21810, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4033
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21811, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7251
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21812, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0398
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21813, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21814, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21815, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21816, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21817, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0768
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21818, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0375
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21819, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21820, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21821, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21822, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0733
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21823, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0125
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21824, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6723
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21825, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2199
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21826, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21827, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21828, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21829, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7439
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21830, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6485
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21831, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8276
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21832, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4154
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21833, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0726
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21834, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6426
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21835, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4269
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21836, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21837, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0717
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21838, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21839, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1275
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21840, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0820
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21841, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21842, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21843, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1856
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21844, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21845, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2767
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21846, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21847, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4947
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21848, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21849, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21850, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21851, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0735
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21852, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21853, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1038
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21854, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21855, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21856, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2415
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21857, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1713
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21858, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1864
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21859, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5502
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21860, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9827
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21861, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21862, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0825
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21863, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21864, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1616
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21865, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21866, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21867, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2304
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21868, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5866
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21869, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21870, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5238
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21871, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0477
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21872, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21873, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21874, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21875, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3982
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21876, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21877, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21878, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2258
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21879, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1638
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21880, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0047
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21881, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6580
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21882, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21883, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1188
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21884, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21885, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4019
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21886, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21887, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2212
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21888, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0682
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21889, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.3199
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21890, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21891, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21892, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0185
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21893, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6482
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21894, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21895, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5968
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21896, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21897, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2216
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21898, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21899, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6762
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21900, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2756
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21901, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0619
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21902, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0691
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21903, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4441
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21904, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21905, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1752
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21906, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21907, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2849
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21908, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4002
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21909, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21910, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21911, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1825
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21912, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21913, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1738
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21914, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1468
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21915, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8668
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21916, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0799
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21917, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2178
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21918, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21919, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21920, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0102
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21921, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21922, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2229
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21923, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0779
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21924, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1438
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21925, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2318
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21926, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21927, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3894
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21928, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0830
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21929, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4380
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21930, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0506
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21931, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5221
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21932, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21933, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1282
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21934, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21935, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21936, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0519
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21937, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21938, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1301
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21939, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21940, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0336
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21941, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21942, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5658
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21943, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5197
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21944, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21945, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21946, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21947, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21948, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21949, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4699
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21950, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1813
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21951, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21952, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2165
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21953, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1524
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21954, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1270
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21955, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21956, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7871
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21957, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5285
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21958, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21959, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5329
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21960, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21961, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5148
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21962, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5146
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21963, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6035
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21964, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1328
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21965, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7240
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21966, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21967, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21968, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1670
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21969, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2404
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21970, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0172
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21971, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0212
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21972, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21973, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21974, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0190
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21975, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8001
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21976, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21977, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2751
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21978, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21979, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7499
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21980, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5307
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21981, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21982, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3869
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21983, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2219
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21984, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1594
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21985, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21986, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1310
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21987, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1145
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21988, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0054
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21989, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21990, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21991, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21992, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8648
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21993, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3928
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21994, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2719
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21995, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21996, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21997, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4252
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21998, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4492
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 21999, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22000, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1629
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22001, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2262
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22002, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2230
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22003, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1858
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22004, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22005, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9253
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22006, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0843
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22007, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0963
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22008, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22009, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2640
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22010, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22011, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1833
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22012, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22013, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4122
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22014, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1892
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22015, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0253
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22016, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1996
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22017, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0795
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22018, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22019, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22020, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7736
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22021, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22022, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22023, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7731
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22024, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4126
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22025, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22026, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2365
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22027, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22028, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22029, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22030, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0580
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22031, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22032, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22033, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2672
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22034, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22035, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22036, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22037, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22038, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3319
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22039, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5163
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22040, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8438
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22041, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22042, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1571
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22043, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1553
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22044, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0725
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22045, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22046, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22047, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0208
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22048, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22049, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22050, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0242
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22051, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6854
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22052, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22053, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22054, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22055, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7726
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22056, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2171
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22057, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1025
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22058, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6543
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22059, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5587
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22060, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22061, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0602
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22062, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2588
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22063, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5648
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22064, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22065, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22066, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1877
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22067, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22068, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22069, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4775
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22070, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1709
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22071, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0568
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22072, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7462
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22073, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0658
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22074, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0940
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22075, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1869
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22076, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5575
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22077, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1946
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22078, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4043
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22079, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22080, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22081, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.3808
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22082, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22083, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1156
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22084, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1838
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22085, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3265
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22086, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0788
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22087, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2263
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22088, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22089, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0447
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22090, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7183
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22091, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0702
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22092, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2157
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22093, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22094, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22095, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22096, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0475
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22097, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0792
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22098, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0394
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22099, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22100, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22101, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22102, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6890
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22103, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22104, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1967
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22105, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0751
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22106, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6044
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22107, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22108, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6523
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22109, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0060
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22110, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22111, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4326
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22112, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1457
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22113, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4432
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22114, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22115, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4366
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22116, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2306
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22117, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22118, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22119, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3395
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22120, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22121, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22122, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5372
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22123, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22124, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22125, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22126, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3245
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22127, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22128, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22129, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3675
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22130, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22131, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22132, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22133, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22134, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4720
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22135, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5586
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22136, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22137, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2529
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22138, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3765
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22139, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1435
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22140, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22141, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22142, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4156
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22143, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0622
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22144, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22145, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22146, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0754
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22147, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0800
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22148, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0286
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22149, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2126
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22150, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3251
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22151, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22152, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22153, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2925
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22154, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0635
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22155, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3404
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22156, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1494
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22157, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0217
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22158, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1340
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22159, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9246
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22160, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0128
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22161, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22162, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5258
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22163, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2594
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22164, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0162
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22165, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22166, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22167, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0634
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22168, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22169, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1203
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22170, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0234
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22171, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5173
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22172, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22173, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22174, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22175, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1654
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22176, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0633
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22177, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22178, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1284
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22179, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22180, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22181, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22182, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22183, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22184, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22185, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5549
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22186, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22187, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0729
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22188, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0059
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22189, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22190, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22191, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22192, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8688
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22193, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0206
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22194, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0961
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22195, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8260
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22196, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1719
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22197, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5293
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22198, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1896
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22199, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1359
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22200, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8562
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22201, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2264
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22202, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22203, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2786
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22204, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6600
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22205, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22206, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5873
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22207, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22208, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0121
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22209, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22210, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2933
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22211, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22212, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22213, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4695
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22214, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1265
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22215, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22216, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0036
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22217, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4970
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22218, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22219, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2355
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22220, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0671
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22221, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22222, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4214
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22223, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1289
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22224, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7399
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22225, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22226, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1802
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22227, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22228, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0411
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22229, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1631
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22230, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22231, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22232, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1700
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22233, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7534
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22234, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22235, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1867
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22236, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22237, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22238, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4232
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22239, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2128
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22240, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2204
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22241, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7176
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22242, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2887
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22243, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1176
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22244, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4587
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22245, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2781
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22246, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1379
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22247, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0179
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22248, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22249, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22250, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22251, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0659
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22252, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3301
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22253, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6569
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22254, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22255, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3461
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22256, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22257, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22258, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7425
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22259, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4777
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22260, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1004
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22261, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22262, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22263, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1663
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22264, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0595
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22265, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0561
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22266, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22267, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6242
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22268, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9758
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22269, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1694
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22270, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22271, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3394
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22272, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4461
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22273, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22274, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5891
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22275, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22276, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0101
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22277, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22278, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22279, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0621
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22280, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1273
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22281, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3370
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22282, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22283, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1519
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22284, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22285, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2287
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22286, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0454
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22287, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0947
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22288, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22289, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22290, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22291, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1817
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22292, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22293, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22294, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9042
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22295, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1694
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22296, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2251
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22297, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22298, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22299, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1808
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22300, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3716
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22301, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0112
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22302, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4175
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22303, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2147
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22304, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0550
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22305, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22306, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5193
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22307, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22308, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5673
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22309, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22310, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1414
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22311, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22312, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1217
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22313, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22314, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22315, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3576
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22316, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22317, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22318, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22319, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1555
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22320, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1526
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22321, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5363
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22322, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6926
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22323, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2177
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22324, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22325, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22326, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0216
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22327, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22328, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0894
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22329, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22330, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22331, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22332, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22333, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2239
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22334, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22335, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2289
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22336, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4552
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22337, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3177
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22338, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0745
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22339, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22340, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2243
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22341, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22342, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22343, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0762
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22344, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1652
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22345, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4151
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22346, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4346
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22347, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1135
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22348, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7272
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22349, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1831
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22350, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22351, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22352, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22353, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6985
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22354, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22355, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5724
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22356, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22357, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2573
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22358, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1018
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22359, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22360, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22361, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4459
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22362, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22363, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1399
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22364, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4324
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22365, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22366, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2876
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22367, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2178
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22368, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0213
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22369, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1692
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22370, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2185
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22371, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22372, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0163
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22373, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22374, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0087
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22375, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4726
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22376, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22377, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0137
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22378, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1977
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22379, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.5582
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22380, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2311
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22381, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1850
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22382, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0207
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22383, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3534
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22384, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22385, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3026
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22386, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22387, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22388, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22389, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9582
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22390, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0116
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22391, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2320
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22392, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2740
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22393, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6501
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22394, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22395, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22396, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6388
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22397, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0171
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22398, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22399, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3344
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22400, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22401, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4475
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22402, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22403, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1256
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22404, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22405, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1829
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22406, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1729
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22407, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22408, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1816
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22409, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22410, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7300
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22411, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1313
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22412, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7260
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22413, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2987
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22414, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3168
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22415, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22416, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22417, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6678
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22418, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1412
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22419, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0132
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22420, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22421, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0649
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22422, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6163
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22423, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22424, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22425, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22426, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0643
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22427, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5211
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22428, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2237
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22429, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4324
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22430, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0615
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22431, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0148
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22432, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22433, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22434, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0696
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22435, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4180
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22436, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6994
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22437, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0044
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22438, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22439, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7523
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22440, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0746
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22441, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4323
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22442, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22443, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3488
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22444, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2872
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22445, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4273
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22446, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0269
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22447, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4238
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22448, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0442
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22449, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0158
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22450, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22451, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22452, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0265
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22453, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0462
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22454, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8592
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22455, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22456, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0974
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22457, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22458, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4402
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22459, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1243
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22460, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22461, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7617
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22462, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0153
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22463, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2906
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22464, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22465, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0131
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22466, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4193
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22467, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22468, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.4388
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22469, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0613
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22470, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0703
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22471, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22472, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22473, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2020
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22474, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2539
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22475, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3439
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22476, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3411
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22477, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2715
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22478, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2372
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22479, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2244
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22480, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4410
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22481, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22482, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22483, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1281
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22484, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5436
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22485, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22486, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2211
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22487, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22488, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22489, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2175
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22490, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2205
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22491, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22492, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22493, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7870
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22494, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0956
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22495, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7997
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22496, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22497, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4573
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22498, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22499, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1891
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22500, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4940
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22501, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4330
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22502, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0304
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22503, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22504, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1447
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22505, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22506, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3774
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22507, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1605
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22508, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0681
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22509, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22510, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22511, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1255
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22512, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5541
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22513, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4634
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22514, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4493
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22515, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7855
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22516, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22517, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22518, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2180
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22519, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22520, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22521, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1751
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22522, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22523, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0161
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22524, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7178
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22525, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0200
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22526, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2659
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22527, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0880
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22528, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22529, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22530, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0662
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22531, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0099
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22532, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22533, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4216
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22534, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6749
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22535, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0046
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22536, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22537, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3381
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22538, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0768
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22539, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2365
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22540, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0689
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22541, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1784
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22542, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0486
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22543, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2906
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22544, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4132
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22545, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4168
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22546, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22547, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22548, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1493
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22549, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6163
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22550, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22551, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0217
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22552, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5352
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22553, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22554, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.1640
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22555, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1181
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22556, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0693
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22557, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3894
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22558, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22559, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0201
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22560, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22561, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2884
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22562, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0792
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22563, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2560
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22564, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0698
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22565, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22566, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22567, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22568, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1839
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22569, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5354
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22570, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2263
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22571, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22572, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22573, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22574, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0822
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22575, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22576, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0048
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22577, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0430
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22578, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22579, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22580, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1317
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22581, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2757
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22582, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1798
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22583, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0776
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22584, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0314
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22585, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22586, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22587, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0068
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22588, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9486
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22589, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22590, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22591, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9245
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22592, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7412
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22593, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22594, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22595, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1288
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22596, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0943
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22597, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0797
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22598, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8368
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22599, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22600, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1786
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22601, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1278
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22602, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2150
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22603, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2235
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22604, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5569
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22605, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22606, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0064
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22607, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22608, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1549
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22609, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3875
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22610, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22611, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4400
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22612, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22613, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2296
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22614, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22615, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2761
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22616, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5363
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22617, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0771
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22618, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22619, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1907
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22620, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1790
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22621, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0078
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22622, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22623, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22624, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22625, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0071
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22626, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0219
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22627, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22628, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4165
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22629, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7764
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22630, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2189
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22631, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4201
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22632, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4431
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22633, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22634, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0733
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22635, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0365
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22636, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2825
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22637, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5212
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22638, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3544
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22639, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22640, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22641, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22642, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2202
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22643, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1308
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22644, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6946
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22645, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1688
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22646, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7284
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22647, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0221
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22648, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3952
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22649, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1291
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22650, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22651, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6937
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22652, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0320
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22653, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22654, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1335
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22655, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22656, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0147
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22657, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0976
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22658, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22659, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0126
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22660, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4171
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22661, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9345
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22662, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22663, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22664, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0169
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22665, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1883
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22666, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0663
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22667, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0572
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22668, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5368
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22669, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22670, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5850
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22671, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0333
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22672, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22673, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1732
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22674, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22675, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1297
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22676, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22677, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2421
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22678, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0575
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22679, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22680, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0424
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22681, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3468
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22682, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0051
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22683, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6406
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22684, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22685, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1338
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22686, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1011
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22687, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22688, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22689, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4879
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22690, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1503
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22691, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.4587
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22692, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.4625
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22693, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2402
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22694, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3704
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22695, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22696, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0368
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22697, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4437
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22698, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22699, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0120
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22700, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22701, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1324
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22702, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22703, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1625
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22704, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2226
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22705, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0111
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22706, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22707, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3987
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22708, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1596
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22709, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2258
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22710, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0874
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22711, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22712, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1248
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22713, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.8448
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22714, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0167
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22715, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1730
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22716, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0146
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22717, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1330
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22718, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6485
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22719, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22720, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0188
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22721, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0719
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22722, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5423
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22723, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22724, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0624
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22725, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5009
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22726, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0118
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22727, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8012
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22728, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0204
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22729, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22730, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2251
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22731, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0600
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22732, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22733, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22734, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0052
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22735, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1327
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22736, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22737, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0916
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22738, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0103
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22739, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22740, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5847
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22741, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22742, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4714
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22743, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.3069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22744, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0035
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22745, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22746, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2030
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22747, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7357
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22748, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22749, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0324
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22750, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22751, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6260
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22752, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22753, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2778
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22754, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0674
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22755, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2606
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22756, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6026
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22757, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22758, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2796
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22759, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3319
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22760, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22761, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0144
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22762, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0872
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22763, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0113
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22764, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1860
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22765, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1098
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22766, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3906
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22767, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0690
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22768, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4286
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22769, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2372
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22770, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0061
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22771, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2787
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22772, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1355
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22773, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22774, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2139
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22775, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4449
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22776, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3287
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22777, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1135
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22778, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22779, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0873
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22780, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4938
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22781, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2875
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22782, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6982
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22783, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0090
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22784, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9301
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22785, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0647
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22786, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22787, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2190
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22788, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22789, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1560
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22790, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4338
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22791, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6044
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22792, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1593
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22793, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2182
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22794, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22795, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0706
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22796, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22797, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22798, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22799, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2112
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22800, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2292
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22801, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0646
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22802, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0968
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22803, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5767
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22804, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22805, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0677
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22806, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22807, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0154
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22808, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1765
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22809, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0119
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22810, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0124
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22811, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22812, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.8760
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22813, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2847
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22814, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3958
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22815, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1665
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22816, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.2902
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22817, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0073
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22818, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1887
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22819, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2329
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22820, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22821, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9051
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22822, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4224
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22823, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3897
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22824, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0110
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22825, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22826, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2378
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22827, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22828, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22829, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22830, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0189
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22831, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0687
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22832, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2301
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22833, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22834, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22835, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2606
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22836, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2991
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22837, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22838, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2821
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22839, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0584
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22840, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5903
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22841, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9760
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22842, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0772
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22843, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4469
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22844, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2363
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22845, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22846, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3839
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22847, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1249
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22848, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4929
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22849, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0130
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22850, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0677
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22851, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22852, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3577
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22853, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22854, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2662
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22855, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22856, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22857, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1460
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22858, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7001
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22859, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0089
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22860, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0065
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22861, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0418
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22862, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0033
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22863, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0722
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22864, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22865, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0228
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22866, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0022
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22867, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2092
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22868, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7040
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22869, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0086
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22870, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0511
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22871, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0197
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22872, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0149
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22873, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4640
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22874, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4629
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22875, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0109
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22876, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22877, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22878, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0155
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22879, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2125
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22880, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6659
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22881, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0692
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22882, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1686
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22883, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2184
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22884, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1620
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22885, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2810
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22886, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5892
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22887, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22888, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4309
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22889, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0077
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22890, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0564
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22891, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22892, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5297
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22893, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0049
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22894, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1335
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22895, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0133
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22896, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22897, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22898, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1023
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22899, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1215
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22900, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4344
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22901, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1247
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22902, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1884
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22903, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0056
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22904, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4427
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22905, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22906, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0465
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22907, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2021
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22908, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5353
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22909, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22910, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0082
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22911, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1334
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22912, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22913, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22914, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22915, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22916, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2269
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22917, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9503
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22918, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0672
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22919, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0093
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22920, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6020
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22921, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0062
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22922, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22923, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0084
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22924, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1634
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22925, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3369
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22926, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2568
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22927, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22928, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0058
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22929, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.9396
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22930, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0055
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22931, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1286
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22932, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0067
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22933, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0431
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22934, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22935, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1542
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22936, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0041
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22937, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1599
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22938, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4161
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22939, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5263
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22940, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7372
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22941, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22942, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22943, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0127
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22944, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0608
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22945, num samples collected 8500, FPS 23
  Algorithm: train_loss 1.0633
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22946, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2258
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22947, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22948, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0069
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22949, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2637
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22950, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0079
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22951, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1344
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22952, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0656
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22953, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5440
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22954, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1691
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22955, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7150
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22956, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2193
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22957, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1421
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22958, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22959, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2022
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22960, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0951
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22961, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7425
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22962, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22963, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1976
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22964, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22965, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22966, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22967, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2470
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22968, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22969, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22970, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3831
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22971, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2802
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22972, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.5107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22973, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6309
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22974, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1280
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22975, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3330
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22976, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0359
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22977, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0096
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22978, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1113
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22979, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0958
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22980, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0604
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22981, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0152
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22982, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2775
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22983, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22984, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22985, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2197
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22986, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3959
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22987, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4536
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22988, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2360
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22989, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.7437
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22990, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6505
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22991, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0873
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22992, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1114
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22993, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0236
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22994, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22995, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0134
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22996, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22997, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0076
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22998, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0050
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 22999, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1290
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23000, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.6094
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23001, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2687
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23002, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.3683
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23003, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.4892
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23004, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1396
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23005, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0070
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23006, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0057
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23007, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1871
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23008, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23009, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.0115
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23010, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.2181
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23011, num samples collected 8500, FPS 23
  Algorithm: train_loss 0.1082
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23012, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.5072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23013, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0614
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23014, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0966
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23015, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23016, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2928
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23017, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0105
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23018, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0117
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23019, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0075
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23020, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0100
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23021, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0567
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23022, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.7901
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23023, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.7102
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23024, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0074
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23025, num samples collected 8500, FPS 22
  Algorithm: train_loss 1.1430
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23026, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0232
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23027, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2728
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23028, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.5160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23029, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0106
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23030, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2158
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23031, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0080
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23032, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0038
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23033, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2376
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23034, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0063
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23035, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.6558
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23036, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4986
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23037, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1854
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23038, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.8783
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23039, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1164
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23040, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.6160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23041, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0987
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23042, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0142
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23043, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0145
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23044, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0143
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23045, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0242
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23046, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1660
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23047, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0104
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23048, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0151
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23049, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.5924
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23050, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23051, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.6503
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23052, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1333
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23053, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0993
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23054, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.5768
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23055, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2388
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23056, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1016
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23057, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1237
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23058, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2155
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23059, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0097
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23060, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0088
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23061, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0095
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23062, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1160
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23063, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1140
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23064, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4016
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23065, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2357
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23066, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.9543
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23067, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2159
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23068, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0138
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23069, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1885
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23070, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4192
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23071, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0091
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23072, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4501
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23073, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0638
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23074, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0081
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23075, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0488
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23076, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0108
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23077, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0460
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23078, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1054
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23079, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0123
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23080, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0168
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23081, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.3665
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23082, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0072
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23083, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2232
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23084, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4962
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23085, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0997
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23086, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0517
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23087, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4018
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23088, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0083
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23089, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0085
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23090, num samples collected 8500, FPS 22
  Algorithm: train_loss 1.2637
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23091, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2107
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23092, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.1147
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23093, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0565
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23094, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.4704
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23095, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0985
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23096, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.7578
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23097, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.2166
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23098, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0574
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23099, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.7284
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
Update 23100, num samples collected 8500, FPS 22
  Algorithm: train_loss 0.0066
  Episodes: TrainReward -1624.9077, l 200.0000, t 443.9286, TestReward -1524.6032
