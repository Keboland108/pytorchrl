{"Algorithm": {}, "train_loss": 0.3531343638896942, "Episodes": {}, "TrainReward": -1622.24903, "l": 200.0, "t": 106.132287, "TestReward": -1303.501015841961, "_runtime": 221, "_timestamp": 1643799008, "_step": 5250}