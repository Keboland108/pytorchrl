{"Algorithm": {}, "train_loss": 0.02839719131588936, "Episodes": {}, "TrainReward": -1233.788307, "l": 200.0, "t": 81.223756, "TestReward": -1126.3244800478376, "_runtime": 142, "_timestamp": 1643801479, "_step": 700}