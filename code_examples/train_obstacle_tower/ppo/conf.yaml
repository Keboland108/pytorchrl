experiment_name: Obstacle_Tower
agent_name: PPO
wandb_key: null
num_env_steps : 1000000000
log_dir: /tmp/obstacle_tower_ppo
gamma: 0.99
save_interval: 10000
max_time: 86400
num_env_processes: 16
num_steps: 800
num_mini_batch: 8
clip_param: 0.15
ppo_epoch: 2
use_gae: True
gae_lambda: 0.95
value_loss_coef: 0.2
recurrent_nets: GRU
reward_shape: True
reduced_action_space: True
use_clipped_value_loss: True
num_actions: 6
entropy_coef: 0.01
eps: 0.00001
lr: 0.0004
nn: Fixup
frame_skip: 2
frame_stack: 4
num_grad_workers: 1
num_col_workers: 1 
com_grad_workers: synchronous
com_col_workers: synchronous
