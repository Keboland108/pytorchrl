experiment_name: Obstacle_Tower
agent_name: PPO
wandb_key: null
num_env_steps : 100_000_000
log_dir: /tmp/ppod_obstacle/
gamma: 0.99
save_interval: 100000
max_time: 86400
num_env_processes: 16
num_steps: 800
num_mini_batch: 8
clip_param: 0.15
ppo_epoch: 2
rho: 0.3
phi: 0.0
gae_lambda: 0.95
value_loss_coef: 0.2
max_grad_norm: 0.5
entropy_coef: 0.01
recurrent_nets: True
reward_shape: False
reduced_action_space: True
use_clipped_value_loss: True
num_actions: 6
min_floor: 20
max_floor: 20
seed_list: [54]
eps: 0.00001
lr: 0.0004
nn: Fixup
frame_skip: 2
frame_stack: 4
num_grad_workers: 1
num_col_workers: 1 
com_grad_workers: synchronous
com_col_workers: synchronous
demos_dir: demos_6_actions/
